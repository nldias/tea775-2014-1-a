\documentclass[12pt]{report} 
\usepackage[a4paper,top=30mm,bottom=30mm,left=25mm,right=25mm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[brazil]{babel}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyphenat}
\usepackage{setspace}
\usepackage{stmaryrd}
\usepackage{upgreek}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{textcomp}
\usepackage{mathrsfs}
\usepackage{enumerate}
\usepackage{ntheorem}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{needspace}
\usepackage[pdftex,colorlinks=true,%
   urlcolor=blue,
   linkcolor=blue,
   citecolor=blue,
   filecolor=blue]{hyperref}


\input{math.tex}
\input{ira.tex}

{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily\small}
 \theoremprework{\needspace{1cm}\bigskip\hrule height1pt\leavevmode}
 \newtheorem{Exe}{Exemplo}[chapter]
}
\newcommand{\skipend}{\vspace*{1ex}\hrule width5cm height1pt}
\newenvironment{Def}{
\abovedisplayskip=18pt plus 3pt minus 9pt
\abovedisplayshortskip=0pt plus 3pt
\belowdisplayskip=9pt plus 3pt minus 0pt
\belowdisplayshortskip=0pt plus 3pt minus 0pt
\vspace*{0.5cm}
  \hrule \vspace*{0.25cm} \noindent\textbf{Definição:}}{\vspace{0.250cm
    plus 0pt minus 0.250cm} \hrule \vspace{0.5cm plus 0pt minus 0.125cm}}
{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily\small}
 \newtheorem{Proj}{Projeto}[chapter]
}
{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily}
 \theoremprework{\needspace{1cm}\bigskip\hrule\leavevmode}
 \theorempostwork{\hrule\bigskip}
 \newtheorem{Teo}{Teorema}[chapter]
}

{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily}
 \theoremprework{\needspace{1cm}\bigskip\hrule\leavevmode}
 \theorempostwork{\hrule\bigskip}
 \newtheorem{Lema}{Lema}[chapter]
}




\title{Lições de Teoria Ergódica, Processos Estocásticos e Sistemas Dinâmicos}
\author{Nelson Luís Dias}
\date{\today}

\begin{document}

\maketitle

\chapter{Introdução}\label{chap:intro}

Em \citeyear{reynolds--b-dynamical}, Osborne Reynolds publicou um artigo sobre
escoamentos turbulentos no qual pela primeira vez aparece o que hoje denominamos
decomposição de Reynolds: o campo de velocidade $\vet{U} = U_i\vet{e}_i$ de um
fluido foi decomposto em $U_i = \tavg{U_i} + u_i$ (``média'' e ``flutuação''), e
equações para as médias $\tavg{U_i}$, e para o segundo momento $\tavg{u_i u_i}/2$,
foram deduzidas a partir de promediações das equações de Navier-Stokes para
$U_i$ (a velocidade do fluido no ponto $\vet{x} = x_i\vet{e}_i$, e no instante
$t$).

Reynolds deu à promediação `$\tavg{\cdot}$' que ele usou o significado de uma
média espacial, num procedimento claramente inspirado pelo trabalho anterior, e
pioneiro, de Maxwell sobre a teoria cinética dos gases
\citep{maxwell--dynamical.theory.gases}.

Logo, percebeu-se que a dedução das equações para os momentos de ordem
1 e 2 (as equações de Reynolds) a partir das equações de Navier-Stokes requeria
um conjunto de postulados, \emph{que não aparece explicitamente no artigo de
\citeyear{reynolds--b-dynamical}}:

\begin{align}
\tavg{u_i} &= 0, \label{eq:pos-rey-zero-mean}\\
\tavg{\tavg{U_i}} &= 0, \label{eq:pos-rey-mean-mean}\\
\tavg{u_i\tavg{U_j}} &= 0, \label{eq:pos-rey-mean-fluct}\\
\tavg{\parder{U_i}{t}} &= \parder{\tavg{U_i}}{t},\label{eq:pos-rey-t-der}\\
\tavg{\parder{U_i}{x_j}} &= \parder{\tavg{U_i}}{x_j}.\label{eq:pos-rey-x-der}
\end{align}

Os ``postulados'' (\ref{eq:pos-rey-zero-mean})--(\ref{eq:pos-rey-x-der})
aparecem, de uma forma ou de outra, em todos os livros-texto importantes de
turbulência. Por exemplo (e a lista não é abrangente): \cite{hinze:turbulence},
\cite{tennekes.lumley--first}, \cite{monin.yaglom:statistical.vol2},
\cite{pope:turbulent}. 

O significado original da promediação de Reynolds não se manteve: a analogia
entre o movimento das moléculas de um gás e o das partículas materiais de um
fluido (debaixo da hipótese do contínuo) é essencialmente insustentável
\cite[][Capítulo 1]{tennekes.lumley--first}.

Curiosamente, em nenhum caso os autores acima (ou quaisquer outros que sejam de
nosso conhecimento) procuram deduzir matematicamente
(\ref{eq:pos-rey-zero-mean})--(\ref{eq:pos-rey-x-der}), com a possível exceção
de \cite{kundu:fluid}, que o faz para um \textit{ensemble}, supostamente finito,
de realizações do escoamento turbulento.

A definição mais comumente encontrada de `$\tavg{\cdot}$', e que formalizaremos
neste texto, é o de uma média probabilística (\textit{ensemble average}), mas
mesmo aqui uma definição precisa não pode ser facilmente encontrada na
literatura de turbulência.

De qualquer forma, a abordagem estatística de sistemas complexos era promissora,
e logo Reynolds recebeu a compania ilustre de
\cite{einstein--uber.molekularkinetischen} (movimento browniano),
\cite{langevin--brownien} (idem), \cite{taylor--statistical-a,
  taylor--statistical-b, taylor--statistical-c, taylor--statistical-d}
(turbulência), e, naturalmente, \cite{kolmogorov--local.russian} (turbulência).

Entretanto, o \emph{significado} de se tomar médias probabilísticas sobre os
resultados de um processo determinístico está longe de ser
óbvio. Intuitivamente, a motivação é que o processo é suficientemente
``complexo'' (as velocidades das moléculas de um gás; um escoamento turbulento;
o movimento browninao; etc.) para que seja mais fácil lidar apenas com médias e
desvios-padrão, ou seja, \emph{estatísticas}, e não com realizações,
trajetórias, moléculas, partículas, etc., \emph{individuais}. Ainda assim, do
ponto de vista experimental, a tomada de médias sobre realizações é fortemente
restrita pela disponibilidade de tais realizações. A saída é supor, debaixo de
hipóteses adicionais tais como estacionariedade (mas que por si só não é
suficiente), que médias tomadas sobre um número pequeno de realizações (tão
pequeno quanto uma única) são capazes de estimar as médias de \emph{ensemble}.
Essa é a \emph{hipótese ergódica}.

De todo modo, os procedimentos adotados pelos pioneiros eram necessariamente
intuitivos, e tiveram que aguardar, como acontece tantas vezes na história da
Física e da Matemática, por formalização posterior.  A própria teoria de
probabilidade só seria definitivamente formalizada por
\citeauthor{kolmogorov--foundations} em \citeyear{kolmogorov--foundations}; o
teorema ergódico é devido a \cite{birkhoff-proof-ergodic}, e a
\cite{neumann--zuroperatorenmethode}.

Finalmente, as conexões entre processos estocásticos e sistemas dinâmicos, que
em última análise justificam o procedimento informal dos pioneiros, parecem ser
ainda mais recentes \cite[ver][]{lebowitz.penrose--modern.ergodic,
  collet--dynsys.valparaiso}.

Neste texto, nós procuramos ao mesmo tempo traçar uma parte da história da
abordagem estatística de sistemas dinâmicos, desde
\cite{maxwell--dynamical.theory.gases} até a atualidade, e prover um nível
intermediário de formalização. 

A formalização aqui não é feita no espírito de ``arte pela arte'', mas sim no de
embasar mais firmemente as análises de caráter probabilístico de sistemas
físicos determinísticos, representados matematicamente por sistemas dinâmicos.



\chapter{2014-02-19: Aditividade finita}\label{chap:add-finite}

\section*{Como conceitualizamos e formalizamos a propabilidade?}

Existem várias abordagens possíveis:
\begin{enumerate}
\item Clássica (teórica ou ``a priori''):

Consideramos um processo aleatório com $n$ resultados igualmente prováveis, e um
evento $A$ que consiste em $m$ desses resultados. A probabilidade desse evento é
então definida por
\[
P(A) \equiv \frac{m}{n}.
\]
Crítica: no termo ``igualmente prováveis'', já há a suposição de que nós
``sabemos'' o que é probabilidade antes de defini-la. Trata-se portanto de um
argumento circular. (COMO PODEMOS MELHORAR ESSE TEXTO?)



\item Empírica (``a posteriori'' ou frequentista):

Supõe-se que um determinado experimento é repetido $n$ vezes ``nas mesmas
condições''. Se $A$ é um evento identificável no experimento, a probabilidade de
$A$ é definida como o limite da razão entre número $m$ de ocorrências de $A$ e o
número de repetições $n$ quando $n \to \infty$:
\[
P(A) \equiv \lim_{n\to\infty} \frac{m}{n}.
\]

\item  Subjetiva:

Aceita-se que podemos atribuir a diversos eventos uma ``probabilidade'' de
ocorrência. Por exemplo, eu \emph{acho} que a probabilidade de que eu encontre
petróleo no terreno de minha casa é (ou deve ser) $10^{-12}$.

\item Axiomática  \citep{kolmogorov--foundations}.

Uma tripla de propabilidade é uma tripla formada por $(\Omega, \mathscr{F},P)$,
sendo $\Omega$ um conjunto não vazio, $\mathscr{F}$ um campo sigma
(uma $\sigma$-álgebra) de subconjuntos de $\Omega$ (PRECISAMOS USAR OS TERMOS CORRETOS), e $P$ uma função, com

\begin{align*}
P :\mathscr{F} &\rightarrow [0,1], \\
A \in \mathscr{F} &\mapsto P(A).
\end{align*}

Axiomas:

\begin{align}
P(A) &\geq 0,\label{eq:posprob}\\
P(\Omega) &=1,\label{eq:omegaprob}\\
P\left( \bigcup_{i=1}^n A_i\right) &= \sum_{i=1}^n P(A_i), \qquad \text{se} \qquad A_i \cap A_j = \emptyset.\label{eq:finite-additivity}
\end{align}

\end{enumerate}

Os axiomas funcionam quando $\Omega$ é finito. Contudo, há conjuntos
maiores/infinitos (?) para os quais a noção de probabilidade não faz
sentido. Assim, uma $\sigma$-álgebra será um subconjunto de $2^\Omega$ com uma
certa estrutura, para o qual deverá fazer sentido especificar probabilidades.

\textbf{Exemplo}: Sabendo que $A_1 \cup A_2 \cup A_3 =(A_1 \cup A_2)\cup A_3$,
prove por indução que o axioma (\ref{eq:finite-additivity}) vale para todo $n$
se ele valer para $n=2$.

Para $n=2$,
\begin{equation}
A_1 \cup A_2 = \emptyset \Rightarrow P(A_1\cup A_2) = \sum_{i=1}^2 P(A_i). \label{eq:ax3n2}
\end{equation}

Suponha agora que (\ref{eq:finite-additivity}) valha para $n$, e que 
\[
A_{n+1} \cap \left[ \bigcup_{i=1}^n A_i\right] = \emptyset, \qquad i = 1,\ldots, n.
\]
Então,
\begin{eqnarray}
P\left(A_1\cup ...\cup A_n\cup A_{n+1}\right)=P(B\cup A_{n+1}),
\end{eqnarray}
fazendo-se
\[
B = \bigcup_{i=1}^n A_i.
\]
A partir de (\ref{eq:ax3n2}),
\begin{equation}
P\left( B \cup A_{n+1}\right) = P(B) + P(A_{n+1}).
\end{equation}
Por sua vez, como supusemos a validade de (\ref{eq:finite-additivity}),
\begin{eqnarray}
P(B)=P\left(\bigcup_{i=1}^n A_i\right)=\sum_{i=1}^n P(A_i).
\end{eqnarray}
Logo,
\begin{equation}
P(A_1\cup ...\cup A_n\cup A_{n+1}) = P(A_{n+1}) + \sum_{i=1}^n P(A_i) =
\sum_{i=1}^{n+1} P(A_i).
\end{equation}


Note entretanto que, para que a prova seja válida, precisamos garantir que 
\[
A_{n+1} \cap \left[ \bigcup_{i=1}^n A_i\right] = \emptyset \Rightarrow
A_{n+1} \cap A_i = \emptyset, \forall i = 1, \ldots, n.
\]
Faça $C = A_{n+1}$, e considere a igualdade:
\begin{equation}
C\cap \left[\bigcup_{i=1}^n A_i\right] = \bigcup\limits_{i=1}^n C\cap A_i. \label{eq:dist-capcup}
\end{equation}
Se ela for verdadeira, então:
\begin{align*}
A_{n+1} \cap \left[ \bigcup_{i=1}^n A_i\right] = \emptyset &\Rightarrow
\bigcup\limits_{i=1}^n C\cap A_i = \emptyset\nonumber \\
&\Rightarrow A_{n+1} \cap A_i = \emptyset, \qquad\forall i = 1,\ldots, n.
\end{align*}
Portanto, se (\ref{eq:dist-capcup}) for verdadeira, a questão está liquidada.

De fato, 
\begin{align*}
x \in C \cap \left[ \bigcup_{i=1}^n A_i \right]&\Rightarrow \left(x \in C \right) \;\text{e}\; \left(x \in \bigcup_{i=1}^n A_i\right), \\
&\Rightarrow \exists j \in \{1,\ldots,n\} \mathop{|} \left( x \in C \right) \;\text{e}\; \left( x \in A_j\right)\\
&\Rightarrow x \in C \cap A_j\\
&\Rightarrow x \in \bigcup_{i=1}^n C \cap A_i.
\end{align*}
Isso significa que 
\[
C\cap \left[\bigcup_{i=1}^n A_i\right] \subseteq \bigcup\limits_{i=1}^n C\cap
A_i.
\] 
Por outro lado,
\begin{align*}
x \in \bigcup_{i=1}^n C \cap A_i &\Rightarrow \exists j\mathop{|} x \in C \cap A_j\\
&\Rightarrow x \in C \cap \bigcup_{i=1}^n A_i.
\end{align*}
Isso significa que
\[
\bigcup\limits_{i=1}^n C\cap
A_i \subseteq C\cap \left[\bigcup_{i=1}^n A_i\right] .
\]
Com isso, (\ref{eq:dist-capcup}) está provada, e chegamos ao fim (desta prova).


%% $\subset$)
%% \begin{eqnarray}
%% x \in C\cap[\mathop{\cup}\limits_{i=1}^n A_i] &\Leftrightarrow&  x \in C \text{ e } x \in \mathop{\cup}\limits_{i=1}^n A_i,  \text{ logo}\\
%% \exists\quad j \in \{1,..,n\} &\mid& x \in A_j, \text{ e}\\
%% x \in C \text{ e } x\in A_j &\Leftrightarrow& x\in C\cap A_j.
%% \end{eqnarray}

%% $\supset$)
%% \begin{eqnarray}
%% x\in \mathop{\cup}\limits_{i=1}^n C\cap A_i &\Leftrightarrow& \exists K \in \{1,...,n\}\mid x\in C\cap A_K, \text{ então}\\
%% x\in C &\text{ e }& x\in A_K, \\
%% x&\in& C\cap\mathop{\cup}\limits_{i=1}^n A_i, \\
%% x\in C &\text{ e }& x\in \mathop{\cup}\limits_{i=1}^n A_i.
%% \end{eqnarray}



\section*{Notas de Aula Professor Paulo Cezar P. de Carvalho - Ailin}

\subsection*{Modelos elementares}

$\Omega = \{\omega_1,...,\omega_n\}$ \textrightarrow espaço amostral

$\mathscr{F} = 2^\Omega$\textrightarrow é o conjunto potência e inclui todos o subconjuntos de $\Omega$, e, em particular, inclui
$\{\omega_1\}$,$\{...\}$,$\{\omega_n\}$, os quais são chamados eventos complementares.

\begin{eqnarray}
P(\{\omega_i\}) = P_i \in [0,1] \mid \sum\limits_{i=1}^n P_i=1
\end{eqnarray}

Caso equiprovável: $P_i = 1/n, \forall i \in \{1,...,n\}$.

\textbf{Exemplo:} 3 moedas são lançadas. Qual a probabilidade de sairem 2 caras?

Como defino $\Omega$? Se considerarmos $\Omega=\{0,1,2,3\}$, as probabilidades são $1/8$ para $0$ e $3$, e $3/8$ para $1$ e $2$. Para
$i=0,1,2,3$, temos

\begin{eqnarray}
P(i)=\left(\frac{1}{8}\right)^i\left(1-\frac{1}{8}\right)^{3-i}{3\choose i},
\end{eqnarray}

\noindent distribuição binomial herdada do modelo equiprovável.

\textbf{Exemplo:} Escolher um número no intervalo $[0,1]$ tal que $P([a,b])=b-a$ para qualquer intervalo $[a,b]\subset[0,1]$.

$\Omega = [0,1]$

A primeira tentativa seria atribuir $P(\{a\})$. Se for equiprovável com $P\neq 0$ já estaria em contradição com a aditividade.

Com um conjunto enumerável (infinito) não é possível ter equiprobabilidade nem
atribuindo probabilidade nula, porque não conseguiremos que a ``soma"das
$P(\{\})$ seja $1$.

\chapter{2014-02-24: Aditividade infinita}\label{chap:sigma-add}

(Ou $\sigma$--Aditividade)

Passamos agora para casos em que o espaço amostral $\Omega$ deixa de ser um
conjunto finito. Um conjunto infinito pode ser enumerável ou não-enumerável. Um
conjunto enumerável é um conjunto cujos elementos possam ser colocados em uma
relação biunívoca com os naturais.  Os racionais são um conjunto enumerável
(Cantor). Os números reais no intervalo fechado $[0,1]$ são um conjunto
não-enumerável. 

Quando $\Omega$ é finito, todos os elementos de $2^\Omega$ são eventos: a todos
e a cada um deles pode ser atribuída uma probabilidade, e os axiomas
(\ref{eq:posprob})--~(\ref{eq:finite-additivity}) se aplicam. 

\begin{Exe}\label{exe:n-moedas}

Antes de seguir para o infinito, considere o exemplo: $n$ lançamentos de uma
moeda, cujos resultados individuais podem ser ``cara'' (0) ou ``coroa'' (1). Os
eventos elementares com os quais podemos construir um espaço amostral são
$n$-uplas do tipo
\[
\begin{array}{c}
(0,0,\ldots,0,0)\\
(0,0,\ldots,0,1)\\
(0,0,\ldots,1,0)\\
\vdots\\
(1,1,\ldots,1,1).
\end{array}
\]
Existem $2^n$ casos. Portanto, o espaço amostral mais ``simples'' que podemos
imaginar aqui é
\[
\Omega = \left\{ \omega_k = (x_1, \ldots, x_n), x_i = \text{0 ou 1}, k = 1,\ldots,2^n\right\}
\]
Observe que 
\[
P\left(\left\{\omega_k\right\}\right) = \frac{1}{2^n}.
\]



Suponha por exemplo que desejemos calcular a probabilidade de que ocorram $k$
caras (e, consequentemente, $n-k$ coroas). Um evento deste tipo (exatamente $k$
caras e $n-k$ coroas) pode ocorrer de $n!$ maneiras.  No entanto, a posição das
$k$ caras é imaterial: todos os $k!$ casos aparecem da mesma forma.  Idem para
os $(n-k)!$ casos de permuta das posições das coroas. Concluímos que há
\[
\binom{n}{k} = \frac{n!}{k!(n-k)!}
\]
possibilidades de ocorrência de $k$ caras.  A sua probabilidade é
\[
\frac{{\binom{n}{k}}}{{2^n}}=\binom{n}{k}\left(\frac{1}{2}\right)^k\left(\frac{1}{2}\right)^{n-k}.
\]
Isso é um caso particular da distribuição binomial. Se 0 tem probabilidade $p$,
e 1 tem probabilidade $1-p$, a probabilidade de $k$ zeros em $n$ lançamentos é
\[
P(k) = \binom{n}{k} p^k (1-p)^{n-k}.
\]

\end{Exe}

\textbf{Exercício:} Mostre que
\[
\sum_{k=0}^n P(k) = 1.
\]
Prova:
\begin{align*}
( p + (1-p))^n & = 1 \\
&= \sum_{k=0}^n \binom{n}{k} p^k (1-p)^{n-k} \\
&= \sum_{k=0}^n P(k).
\end{align*}

Agora, se $\Omega = \{ x_1, x_2, x_3, \ldots \}$ for enumerável, precisamos de
\[
\sum_{i=1}^n P(x_i) = 1
\]
e fica evidente que os $P(x_i)$ não podem ser todos iguais. Entretanto, ainda é
possível aproveitar os $x_i$'s desde que a soma acima funcione.

\textbf{Exemplo}: Em um jogo, dez bolas numeradas de 0 a 9 podem ser sorteadas.
Cada jogador sorteia uma bola, mostra o resultado e retorna a bola. Ganha o
primeiro jogador que sortear um 7. O jogo poderia durar para sempre?

Nossa opção para construção do espaço amostral é 
\[
\Omega = \{ 0, 1, 2, 3, 4, \ldots \}
\]
0 significa que o 7 \emph{nunca} é sorteado; 1 significa que o 7 foi sorteado
na primeira rodada; 2 na segunda; e assim por diante. As probabilidades desses
eventos não são iguais:
\begin{align*}
P(0) &= ?, \\
P(1) &= \frac{1}{10}, \\
P(2) &= \frac{9}{10}\times \frac{1}{10},\\
P(3) &= \frac{9}{10} \times \frac{9}{10} \times \frac{1}{10}, \\
     &\vdotswithin{=} \\
P(n) &= \left( \frac{9}{10}\right)^{n-1} \times \frac{1}{10}
\end{align*}

É elementar verificar que $P(n), \; n \ge 1,$ é uma série geométrica com soma
1. Portanto, o evento ``o 7 nunca é sorteado'', indicado por 0, tem
probabilidade complementar à $P(1) + P(2) + \ldots = 1$, e sua probabilidade é
zero. 

Finalmente, considere o caso em que desejamos atribuir probabilidades dentro do
conjunto não-enumerável $\Omega = [0,1]$. Note que faz sentido atribuir
probabilidade zero a um ponto qualquer:
\[
P(X = a) = 0
\]
e que é muito razoável atribuir probabilidades a intervalos:
\[
P( [a,b] ) = b - a.
\]
O problema é que se $A$ é um evento, o seu complemento $\overline{A}$ também tem
que ser, com $P(\overline{A}) = 1 - P(A)$, pela propriedade de aditividade
finita (\ref{eq:finite-additivity}). Portanto, se $(a,b] \in \mathscr{F}$,
devemos também ter $\overline{(a,b]} \in \mathscr{F}$, onde $\mathscr{F}$ será a
classe dos eventos cujas probabilidades podem ser quantificadas.

Entretanto, o complemento de um único intervalo $(a,b]$ \emph{não} é um único
  intervalo. Desconfiamos que uma criatura desse tipo, $[0,a] \cup (b,1]$,
    precisa ser definida com as mesmas propriedades genéricas de $(a,b]$, de
      forma que ambos pertençam a $\mathscr{F}$. O caminho para $\mathscr{F}$,
      entretanto, é longo.


Uma extensão do que vimos para a binomial é a distribuição multinomial:

\begin{align*}
1 = (p_1 + \ldots + p_n)^n &= \sum_{l_1 + \ldots + l_k = n} 
                              \binom{n}{l_1 \ldots l_k}
                              p_1^{l_1}\ldots p_k^{l_k},\\
\binom{n}{l_1 \ldots l_k} &= \frac{n!}{l_1! \ldots l_k!}.
\end{align*}

\chapter{2014-02-26: Semi-anéis, anéis, e outros bichos}\label{chap:rings}




\textbf{Definição}

Uma classe $\mathscr{S}$ de conjuntos é um \emph{semi-anel} quando:
\begin{align*} 
\emptyset &\in \mathscr{S}, \\
A,B \in \mathscr{S} \Rightarrow A \cap B &\in \mathscr{S},\\
A,B \in \mathscr{S} \Rightarrow 
A - B &= A \cap \overline{B} = \bigsqcup_{i=1}^n E_i,
\end{align*}
onde $E_i \in \mathscr{S}$. O símbolo $\bigsqcup$ significa ``uniões disjuntas''.

Seja $\mathscr{S}$ a classe formada por \emph{intervalos} do tipo
\[
(a,b]  \qquad\text{ou}\qquad \emptyset.
\]

\begin{enumerate}
\item $\emptyset \in \mathscr{S}$?  Sim.
\item A interseção de dois elementos de $\mathscr{S}$ pertence a $\mathscr{S}$?

Sim: as possibilidades para interseção de $(a,b]$ com $(c,d]$ são
\begin{align*}
\emptyset &\in \mathscr{S}, \\
(c,b]     &\in \mathscr{S}, \\
(c,d]     &\in \mathscr{S}, \\
(a,d]     &\in \mathscr{S}, \\
(a,b]     &\in \mathscr{S}.
\end{align*}

Talvez seja possível resumir:
\[
(a,b] \cap (c,d] = (\max(a,c), \min(b,d)) \qquad \text{ou} \qquad\emptyset ?
\]

\item $A - B$ ($A$, $B$ intervalos) é exprimível como uma união finita disjunta
  de intervalos?

Sim:
\begin{align*}
(a,b] \cap \overline{(c,d]} &= (a,b] \cap \big[ (0,c] \cup (d,1] \big] \\
                            &= \underbrace{(a,b] \cap (0,c]}_{\in \mathscr{S}}
                \cup \underbrace{(a,b] \cap (d,1]}_{\in \mathscr{S}}\blob
\end{align*}
\end{enumerate}

Portanto, essa classe $\mathscr{S}$ de intervalos é um semi-anel.

\begin{Def}    $\mathscr{R} \subset 2^{\Omega}$ é um \emph{anel} quando:
\begin{align*}
\emptyset &\in \mathscr{R}, \\
A, B \in \mathscr{R} &\Rightarrow A \cap B \in \mathscr{R},\\
A, B \in \mathscr{R} &\Rightarrow A \mathop{\vartriangle} B \in \mathscr{R}.
\end{align*}
\end{Def}

Lembre-se:
\[
A \mathop{\vartriangle} B \equiv
(A - B) \cup (B - A).
\]

\textbf{Tivemos uma discussão sobre o motivo de se usar a diferença simétrica nessas
definições: alguém gostaria de resumir a discussão em \LaTeX?}


Anéis triviais são:
\[
\{ \emptyset, \Omega \} \qquad \text{e} \qquad
2^{\Omega}.
\]

É possível mostrar as seguintes propriedades de anéis: se $A, B \in
\mathscr{R}$, então:
\begin{align*}
A \cap B &\in \mathscr{R}, \\
A \mathop{\vartriangle} B &\in \mathscr{R}, \\
A \cup B &\in \mathscr{R}, \\
A - B &\in \mathscr{R}, \\
B - A &\in \mathscr{R}, \\
\emptyset &\in \mathscr{R}.
\end{align*}

Mas a última não faz parte da \emph{definição} de $\mathscr{R}$????

Note também que o complemento ainda não apareceu na jogada.

\textbf{Teorema}

A partir de um semi-anel $\mathscr{S}$ é possível construir um anel
$\mathscr{R}$ por meio somente de uniões disjuntas finitas de elementos de
$\mathscr{S}$, ou seja:
\[
\mathscr{R} = \left\{  \bigsqcup_{i=1}^n A_i\right\}, \; A_i \in \mathscr{S}.
\]

\textbf{Definição}

Uma \emph{álgebra} ou um \emph{campo} $\mathscr{A}$ é um anel que contém
$\Omega$. Segue-se imediatamente que
\[
A \in \mathscr{A} \Rightarrow \overline{A} \in \mathscr{A}.
\]

\textbf{Definição}
Um $\sigma$-anel é um anel fechado por uma união enumerável

Comentário: ``fechado'' significa que uniões enumeráveis de elementos do
$\sigma$-$\mathscr{R}$ ainda pertencem a ele.

Segue-se imediatamente que o $\sigma$-$\mathscr{R}$ também é fechado por
interseções enumeráveis.



\textbf{Definição}
Uma $\sigma$-álgebra ou $\sigma$-campo ou campo de Borel é uma álgebra fechada
por uniões enumeráveis.

Segue-se imediatamente que uma $\sigma$-álgebra também é fechada por interseções
enumeráveis. 

\textbf{Definição}
Dada uma classe $\mathscr{C} \subseteq 2^{\Omega}$, uma sequência monótona de
elementos $E_i \in \mathscr{C}, \; i \in \mathbb{N}$, é definida por 
\begin{align*}
E_i \subseteq E_{i+1} \\
\intertext{ou}
E_i \supseteq E_i.
\end{align*}

\textbf{Definição}
Uma classe $\mathscr{M}$ é dita \emph{monótona} quando todas as suas sequências
monótonas atendem a:
\begin{align*}
E_i \subseteq E_{i+1} &\Rightarrow \bigsqcup_{i=1}^n E_i \in \mathscr{M},\\
\intertext{ou}
E_i \supseteq E_{i+1} &\Rightarrow \bigsqcap_{i=1}^n E_i \in \mathscr{M}.
\end{align*}

A questão agora é como construir $\sigma$-álgebras a partir de álgebras, anéis
ou semi-anéis.

\textbf{Teorema}: Para as famílias $\mathscr{R}$, $\mathscr{A}$,
$\sigma$-$\mathscr{R}$, $\sigma$-$\mathscr{A}$, $\mathscr{M}$ de anéis, álgebras,
sigma-anéis, sigma-álgebras, e classes monótonas $\mathscr{M}$, interseções
arbitrárias produzem famílias de mesmo tipo.

Em resumo: se $\mathscr{F}_i, \; i \in I$, são classes de algum dos tipos acima,
então
\[
\bigsqcap_{i\in I} \mathscr{F}_i
\]
também é.

Por exemplo: se
\[
\mathscr{F}_i, \; i \in I
\]
são $\sigma$-álgebras, então 
\[
\bigsqcap_{i\in I} \mathscr{F}_i
\]
também é uma $\sigma$-álgebra.

\section{Geração de $\sigma$-álgebras}

Seja $\mathscr{S}$ um semi-anel que gera o anel $\mathscr{R}$.
A \emph{menor} $\sigma$-álgebra contendo $\mathscr{S}$ ou gerada por
$\mathscr{R}$ é denominada ``$\sigma$-álgebra de Borel'' $\mathscr{B}$.

No caso de $\Omega = [0,1]$, a $\sigma$-álgebra de Borel é a menor
$\sigma$-álgebra que contém os intervalos $(a,b]$.

Para ela, é possível definir uma medida de probabilidade
\begin{align*}
P : \mathscr{B} &\to [0,1], \\
     A \in \mathscr{B} &\mapsto P(A) \in [0,1],
\end{align*}
de tal forma que 
\begin{align*}
P(\emptyset) &= 0, \\
P(\Omega) &= 1,\\
P\left(\bigsqcup_{i=1}^\infty A_i\right) &= \sum_{i=1}^\infty P(A_i).
\end{align*}

\chapter{2014-03-10: O conjunto de Vitali: existe um conjunto não-mensurável em
  $(0,1]$}\label{chap:non-measurable-set}

%\newcommand{\ooplus}{\mathbin{\stackrel{\curvearrowleft}{+}}}
\newcommand{\ooplus}{\xhookleftarrow{+}}

\section{A q-soma e resultados preliminares\label{sec:q-soma}}

Uma nova operação será usada \textit{ad nauseam} nesta lição. Para $x,y \in
(0,1]$:
\begin{equation}
x \boxplus y \equiv 
\begin{cases}
x + y, & x + y \le 1,\\
x + y - 1, & x+ y > 1.
\end{cases}
\end{equation}
Vamos chamar ``$\boxplus$''  de q-soma, para distingui-la da soma usual em $\mathbb{R}$.

O conjunto $(0,1]$ juntamente com a operação $\boxplus$ configura um \emph{grupo
    abeliano}, uma vez que valem as seguintes propriedades:

\begin{enumerate}[1)]
\item Fechamento:
\begin{equation}
   x \boxplus y \in (0,1]. \label{eq:box-fecha}
\end{equation} 
De fato $\boxplus$ configura uma função:
\begin{align*}
   \boxplus : (0,1] \times (0,1] &\rightarrow (0,1], \\
              (x,y)              &\mapsto z = x \boxplus y.
\end{align*}
\item Comutatividade: para $x,y \in (0,1]$, 
\begin{equation}
   x \boxplus y = y \boxplus x.  \label{eq:box-comuta}
\end{equation}
\item Associatividade:
\begin{equation}
 (x \boxplus y) \boxplus z = x \boxplus ( y \boxplus z). \label{eq:box-associa}
\end{equation}
\textbf{Precisamos de um voluntário ou voluntária para provar a associatividade.}
\item Elemento neutro:
\begin{equation}
x \boxplus 1 = 1 \boxplus x = x. \label{eq:box-neutro}
\end{equation}
\item Elemento inverso da soma:
\begin{equation}
\forall x \in (0,1], \exists y  \in (0,1]\;:\; x \boxplus y = 1. \label{eq:box-inverso}
\end{equation}
Vamos usar a notação $(\boxminus x)$ para indicar o inverso da q-soma.
É fácil ver que:
\[
   (\boxminus x) = \begin{cases}
        1, & x = 1, \\
        1- x, & x < 1.
       \end{cases}
\]
O primeiro caso é trivial, pois $1 \boxplus 1 = 1$. No segundo caso,
\[
x \boxplus y = x + y = x + (1 - x) = 1, \;\text{(pois $x + y \le 1$)}\; \; \forall x \in (0,1].
\]
\end{enumerate}

A existência do elemento inverso da soma permite que nós definamos a operação
``q-diferença'', 
$\boxminus$:
\begin{Def}
$x \boxminus y \equiv x \boxplus (\boxminus y)$.
\end{Def}


\begin{Lema}
Para $x,z \in (0,1]$:
\begin{equation}
\exists y \in (0,1]:z = x\boxplus y \Leftrightarrow \exists r \in (-1,1): z =
  x+r. \label{eq:box-rationals}
\end{equation}
\end{Lema}
\textbf{Favor verificar se os limites para o intervalo de $r$ estão corretos.}\\
Prova:
Se $x=1$,
\[
y = z \boxminus x = z \boxminus 1 = z \in (0,1] \qquad \Leftrightarrow \qquad r = y - 1 \in (-1,1).
\]
Se $x < 1$ e $z + 1 - x \le 1$,
\[
y = z \boxminus x = z + 1  - x \qquad \Leftrightarrow \qquad r = y - 1 \in (-1,1).
\]
Se $x < 1$ e $z + 1 - x > 1$,
\[
y = z \boxminus x = z   - x \qquad \Leftrightarrow \qquad r = y \in (-1,1)\blob
\]



Agora, para \emph{qualquer} subconjunto $E$ de $(0,1]$, defina um novo conjunto $E(x)$

\begin{equation}
E(x) \equiv \left\{ x \boxplus y, \; y \in E\right\}.
\end{equation}

$E(x)$ é a \emph{translação} (de uma distância $x$) do conjunto $E$. 

\begin{description}
\item[Dúvida:] $E \subseteq (0,1]$ ou $E \in \mathscr{B}$? 
\item[Dúvida:] ``translação \emph{em} $x$'' me soa estranho, pois todo $y \in E$ é transladado
\emph{de} $x$.
\end{description}

Suponha que exista uma coisa tal como uma medida ``natural'' em $(0,1]$.  Para o
  intervalo $(a,b]$ essa medida é
\begin{equation}
\left| (a,b]\right| \equiv b - a.\label{eq:def-medida}
\end{equation}

Vamos supor, sem entrar em muitos detalhes, que para todo $B \in \mathscr{B}$,
existe uma $|B|$ compatível com (\ref{eq:def-medida}), \textit{i.e.}, redutível
a (\ref{eq:def-medida}) se $B$ for um intervalo.

A notação $E(x)$ é a usada por \cite{taylor--intro.measure.integration}. 

Agora, se $E \in \mathscr{B}$, então,

\begin{equation}
|E(x)| = |E|. \label{eq:medida-mantem-x}
\end{equation}

Agora, como sempre, $\mathbb{Q}$ é o conjunto dos racionais.  Esse conjunto é
enumerável. Consideremos os racionais contidos em $(0,1]$. Esse segundo conjunto
  é
\begin{equation}
Q \equiv \mathbb{Q} \cap (0,1].\label{eq:def-Q-em-zero-um}
\end{equation}
\needspace{2cm}

Valeria a pena provar que
\begin{quote}
Q é enumerável.
\end{quote}

Com essas definições à mão, estudemos então as propriedades dos conjuntos do
tipo $Q(x)$.

\begin{enumerate}
\item 
\begin{equation}
x \in (0,1] \Rightarrow x \in Q(x). \label{eq:x-in-Qx}
\end{equation}
Será verdade? Como provar?
\[
Q(x) = \left\{ x \boxplus y, \; y \in Q \right\}
\]
Se $0$ pertencesse a $Q$, (\ref{eq:x-in-Qx}) seria trivial. Mas é quase, porque
$1 \in Q$.  Faça $y = 1$ acima; então,
\[
x = x + 1 - 1 = x \boxplus 1 \in Q(x)\blob
\]
\item 
\begin{equation}
x \in Q \Rightarrow Q(x) = Q.\label{eq:xinQ-Qx-eq-Q}
\end{equation}
De fato: para começar, $x,y \in Q \Rightarrow x \boxplus y \in Q$. De fato, $x
\boxplus y \in (0,1]$, e tanto $x + y$ quanto $x + y -1$, conforme for o caso,
  são números racionais em $(0,1]$.  Isso basta!, pois, \emph{neste caso},
$Q(x) = \left\{ x \boxplus y, \; y \in Q \right\} = Q\blob$ 
\item
\begin{align}
x_1 - x_2 \not\in \mathbb{Q} &\Rightarrow Q(x_1) \cap Q(x_2) = \emptyset, \label{eq:irraQx1x2}\\
x_1 - x_2 \in     \mathbb{Q} &\Rightarrow Q(x_1) = Q(x_2).\label{eq:raciQx1x2}
\end{align}
Dessa forma, os conjuntos $\left\{ Q(x), \; x \in (0,1]\right\}$ (que constituem
  uma \emph{classe}, ou \emph{família}) particionam o intervalo $(0,1]$ em
    subconjuntos disjuntos cuja união é o próprio $(0,1]$.  Há bastante material
      aqui.  Antes das deduções, vamos escrever formalmente essa última
      observação:
\[
\bigcup_{x \in (0,1]} Q(x) = (0,1].
\]
Note também que os índices na expressão acima são demasiados, devido a (\ref{eq:raciQx1x2}).  Queremos chegar a
uma afirmação mais econômica:
\[
\bigsqcup_{x \in T} Q(x) = (0,1]
\]
(note a disjunção). Na sequência, precisamos provar
(\ref{eq:irraQx1x2})--(\ref{eq:raciQx1x2}) e prosseguir na obtenção do conjunto
$T$. Esse último se revelará um conjunto interessante, e na verdade o ponto
final desta lição: $T$ se revelará um conjunto \emph{não mensurável}.

Para provar (\ref{eq:irraQx1x2}): Vamos tentar \textit{reductio ad absurdum}.
Seja $z \in Q(x_1)$ e $z \in Q(x_2)$: nesse caso, a interseção $Q(x_1) \cap
Q(x_2)$ não seria o conjunto vazio.  Porém, debaixo dessa hipótese:
\begin{align*}
z &= x_1 \boxplus y, \; y \in Q, \\
z &= x_2 \boxplus y, \; y \in Q.
\end{align*}
Agora,  
\begin{align*}
( x_1 \boxplus y ) - ( x_2 \boxplus y) &= x_1 - x_2, \; \text{ou}\\
                                       &= x_1 - x_2 - 1 \; \text{ou}\\
                                       &= x_1 - x_2 + 1.
\end{align*}
Portanto, subtraindo (dessa forma) as duas expressões acima,
\[
(-1 \; \text{ou} \; 0 \; \text{ou} +1) = x_1 - x_2.
\]
mas $(-1,0,+1)$ são racionais, o que contraria a hipótese original sobre $x_1 -
x_2\blob$

Para provar (\ref{eq:raciQx1x2}): Volte acima e escreva a expressão geral:
\[
(x_1 \boxplus y) - (x_2 \boxplus y) = x_1 - x_2 + s,
\]
onde, como vimos, ou $s=0$ ou $s=-1$ ou $s=+1$. Reescreva:
\[
x_1 \boxplus y = x_2 \boxplus y + (x_1 - x_2) + s.
\]
Note agora que é \emph{sempre} possível escrever $x_2 \boxplus y = x_2 + r$
(veja (\ref{eq:box-rationals})),
\emph{onde agora $r$ é racional}, e não necessariamente está em $Q$. Substitua:
\[
x_1 \boxplus y = x_2 + r + s + (x_1 - x_2).
\]
O lado esquerdo é um número em $Q$.  Portanto, o lado direito é um número em
$Q$:
\begin{equation}
x_2 + p \in Q,\label{eq:x2p-in-Q}
\end{equation}
onde $p = (r + s + (x_1 - x_2))$ e portanto $p \in \mathbb{Q}$ (mas não
necessariamente $ p \in Q$).  Agora, utilizando (\ref{eq:box-rationals}), vemos
que é possível escrever o lado direito como $x_2 \boxplus z$, onde $z \in Q$.
Disso se segue que
\[
\left\{ x_1 \boxplus y, \; y \in Q\right\} = 
\left\{ x_2 \boxplus z, \; z \in Q\right\} 
\]
e portanto $Q(x_1) = Q(x_2)\blob$
\end{enumerate}

Relembrando:
\[
x \in Q \Rightarrow Q(x) = Q
\]
significa, por exemplo:
\[
Q(1/2) = Q(1/3) = Q(1).
\]

\[
x_1 - x_2 \in \mathbb{I} \Rightarrow Q(x_1) \cap Q(x_2) = \emptyset
\]
significa, por exemplo:
\[
Q(\sqrt{3}/2) \cap Q(3/2) = \emptyset.
\]

\[
x_1 - x_2 \in \mathbb{Q} \Rightarrow Q(x_1) = Q(x_2) 
\]
significa, por exemplo:
\[
Q(\sqrt{2}/1000 + 1/8) = Q(\sqrt{2}/1000 + 3/8)
\]

Ou seja: as criaturas estão ficando estranhas.

Para fechar esta parte bastante cansativa para a mente:
\[
\bigcup_{x \in (0,1]} Q(x) = (0,1]
\]
pois $x \in Q(x)$.

\section{O axioma da seleção e um conjunto estranho\label{sec:conj-vitali}}

Seja $\mathscr{C}$ a família dos conjuntos $Q(x)$, $x \in (0,1]$. Escolha um
  único ponto em $(0,1]$ pertencente a cada $Q(x)$.  O conjunto dos pontos assim
    escolhidos será chamado $T$, e temos que $T \subset (0,1]$. $T$ é um
      \emph{conjunto de Vitali}.  O que fizemos significa que, \emph{por
        definição}, não há dois pontos em $T$ pertencendentes ao mesmo
      $Q(x)$. Segue-se que
\[
   \bigsqcup_{t \in T} Q(t) = (0,1].
\]

Estudemos as propriedades dos conjuntos $T(r_i), r_i \in Q$.
\begin{enumerate}
\item
\begin{equation}
\bigcup_{i=1}^\infty T(r_i) = (0,1].\label{eq:union-ri}
\end{equation}
Só precisamos provar que, se $x \in (0,1]$, $\exists i \in Q : x \in
  T(r_i)$. Mas, de (\ref{eq:x-in-Qx}), segue-se que $x \in (0,1] \Rightarrow x
    \in Q(x)$. Agora, portanto, se $x \in Q(x)$, escolha $t \in Q(x)$, onde $t$
    é o representante de $Q(x)$: $t \in T$.

Veja:
\begin{align*}
Q(x) &= { x \boxplus y, \; y \in Q }, \\
t \in Q(x) &\Rightarrow t = x \boxplus y \; \text{para algum $y \in Q$}.
\end{align*}
Logo, de (\ref{eq:box-rationals}), existe algum $q \in Q$ tal que $t = x + q$; pelo mesmo motivo agora deve
existir algum $r \in Q$ tal que $x = t + r$. Mas $Q$ é enumerável (não
provamos!), portanto existe um índice $i$ tal que $x = t + r_i$, $i \in
\mathbb{N}$, e $Q = \bigsqcup_{i=1}^\infty r_i$. Logo, $x \in T(r_i)$. A união
dos $T(r_i)$ gera o $(0,1]$.
\item Os $T(r_i)$ são disjuntos. Lembre-se de que $T$ contém um único
  representante de cada $Q(x)$. Se houvesse $r_i \ne r_j$ com $y \in \left[ T(r_i) \cap
  T(r_j)\right]$, então teríamos
\begin{align*}
y &= t_i \boxplus r_i \qquad \text{e}\\
y &= t_j \boxplus r_j.
\end{align*}
``Subtraia'':
\[
0 = (t_i - t_j) + q
\]
onde $q$ é racional (novamente, nós usamos (\ref{eq:box-rationals})). Logo, $t_i
- t_j$ é racional, donde $Q(t_i) = Q(t_j)$ (devido a (\ref{eq:raciQx1x2})).  Mas
isso não é possível, porque $Q(t_i)$ possui um único representante em
$T$. Portanto, a disjunção dos $T(r_i)$'s transforma (\ref{eq:union-ri}) em
\begin{equation}
\bigsqcup_{i=1}^\infty T(r_i) = (0,1].\label{eq:union-disjoint-ri}
\end{equation}
\end{enumerate}
Finalmente: se $T$ fosse mensurável, haveria $|T| = |T(r_i)|$ para todo $i$.
Agora, pela sigma-aditividade:
\[
\sum_{i=1}^\infty |T(r_i)| = |(0,1]| = 1.
\]
Isso, nós também já vimos em outra lição, é impossível. $T$ não pode ser mensurável\blob


\chapter{2014-03-12, 2014-03-17: Teoria de probabilidade e incursões na física e
  em geociências}\label{chap:teoprob}




\section{Variável aleatória}\label{sec:random-var}

\textbf{Este início de seção foi escrito por mim, anteriormente.  Entretanto,
  ele se parece bastante com a exposição da Ailin em 2014-03-17.  Seria bom
  portanto unificar as duas aqui.  Aceito sugestões.}


Em uma visão moderna de probabilidades e estatística, inventada por Kolmogorov, nós
precisamos de:
\begin{enumerate}
   \item um conjunto $\Omega$ --- responsável por ``sorteios'', denominado \emph{Espaço
   Amostral};
   \item Uma função
   \begin{align*}
      X: \Omega &\rightarrow \mathbb{R} \\
	 \omega \in \Omega &\mapsto x = X(\omega)
   \end{align*}
   A função $X$ é denominada ``variável aleatória''.  A função $X$ tem que ser
   \emph{mensurável}, e nós vamos gastar algum tempo com isso ainda mais à frente.
   \item Uma função 
   \begin{align*}
      P:\mathscr{F} &\rightarrow [0,1]\\
      A \in \mathscr{F} &\mapsto P(A)
   \end{align*}
\end{enumerate}

O conjunto $\mathscr{F}$ é uma \emph{classe} (um conjunto de conjuntos).  Como
vimos no capítulo \ref{chap:sigma-add}, $\mathscr{F}$ é uma $\sigma$-álgebra.
Cada \emph{elemento} de $\mathscr{F}$ é um sub-conjunto mensurável $A \in
\Omega$, ao qual nós associamos um número $P(A)$.  Os elementos de $\mathscr{F}$
gozam de algumas propriedades importantes em teoria de probabilidades:
\begin{align}
   A \in \mathscr{F} &\then \overline{A} \in \mathscr{F}\\
   A,B \in \mathscr{F} &\then A \cup B \in \mathscr{F}\\
   A,B \in \mathscr{F} &\then A \cap B \in \mathscr{F}\\
   \emptyset	       &\in \mathscr{F}\\
   \Omega	       &\in \mathscr{F}
\end{align}
Nós podemos reconhecer nestas propriedades, imediatamente, que os sub-conjuntos $A \in \Omega$
são \emph{eventos}.  A função $P$ associa a cada evento uma \emph{probabilidade}.  A função $P$
também deve obedecer a algumas regras. Se $A_1, \ldots, A_n$ são conjuntos \emph{disjuntos},
$A_i \cap A_j = \emptyset, \; i\ne j$, então
\begin{align}
   P(A_i) &\ge 0\\
   P(\Omega) &= 1\\
   P(A_i \cup A_j) &= P(A_i) + P(A_j)
\end{align}
Esta última é um caso particular da $\sigma$-aditividade:
\begin{equation}
P\left(\bigsqcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty A_i. 
\end{equation}
É muito importante enfatizar que o espaço amostral é um conceito \emph{abstrato}: ele ajuda a
conceituar probabilidades e também ajuda a demonstrar alguns resultados, mas na prática tudo o
que vemos no mundo ``real'', ou seja, os únicos objetos que podemos manipular em aplicações de
teoria de probabilidade, são as \emph{realizações} da variável aleatória: $x = X(\omega)$.


Para avaliar a probabilidade de ocorrência de certos níveis de uma variável aleatória nós usamos
eventos do tipo $X(\omega) \le x$, que pode ser entendido com o auxílio da figura
\ref{fig:Xlessthanx}.

\begin{figure}\label{fig:Xlessthanx}\centering
   \resizebox{0.5\textwidth}{!}{\includegraphics{Xlessthanx}}
   \caption{Representação gráfica do evento $X(\omega) \le x$}
\end{figure}
 
Diferentes maneiras de escrever o evento $A$ são:
\begin{align*}
    A &= \left\{ \omega \mathrel{|} X(\omega) \le x \right\},\\
    A &= \left\{ X(\omega) \le x \right\},\\
    A &= \left\{ X \le \omega \right\}.
\end{align*}
Note que na última forma desapareceu qualquer referência explícita ao espaço
amostral.



\section{A conveniência  de definir funções de $\Omega$ em $\mathbb{R}$.}

Em princípio, para cada pergunta que nós podemos formular sobre eventos e
probabilidades, é possível construir um espaço amostral $\Omega$ ``sob medida''
para respondê-la. Junto com esse espaço, é possível, também em princípio,
definir uma medida de probabilidade adequada.  Nesse caso, tudo o que é
necessário, sempre, é a formulação de uma tripla de probabilidade
$(\Omega,\mathscr{F},P)$ que nos permita medir a probabilidade dos eventos $A$
de nosso interesse.

Entretanto, isso não é \emph{prático}. O motivo é que, \emph{sempre}, as
perguntas que podemos formular a partir de uma dada tripla
$(\Omega,\mathscr{F},P)$ inicial, podem ser expressas em termos de
\emph{funções} cujo domínio é $\Omega$. Rapidamente, portanto, nós nos deparamos
com a conveniência, e quase que com a imposição, da definição de funções de
$\Omega$ em $\mathbb{R}$.  Tais funções são denominadas \emph{variáveis
  aleatórias}.

Considere, por exemplo, o lançamento de $n$ moedas do exemplo
\ref{exe:n-moedas}. Se ``caras'' significa $x_i = 0$ e ``coroa'' significa $x_i
= 1$, a pergunta: qual é o número de coroas obtidas em $n$ lançamentos pode ser
respondida com o auxílio da função 
\begin{align*}
X : \Omega &\Rightarrow \mathbb{R}, \\
    \omega = (x_1, \ldots, x_n) &\mapsto \sum_{i=1}^n x_i.
\end{align*}
$X$ é uma função. A imagem de $X$ é 
\[
\text{Im} X = \left\{ 0, 1, \ldots, n\right\} \subset \mathbb{R}.
\]
$X$ não é sobrejetiva.

Perguntas similares podem ser respondidas com outras funções, sem que seja
necessário redefinir uma nova tripla $(\Omega,\mathscr{F},P)$ para cada
pergunta!  Por exemplo, se desejarmos calcular probabilidades associadas ao
número de caras obtidas em $n$ lançamentos, podemos usar:
\begin{align*}
X : \Omega &\Rightarrow \mathbb{R}, \\
    \omega = (x_1, \ldots, x_n) &\mapsto n - \sum_{i=1}^n x_i.
\end{align*}
Ou ainda poderíamos estar interessados no número médio de coroas em $n$
lançamentos (ou ainda no limite dessa quantidade quando $n\to\infty$), quando
então poderíamos usar a função
\begin{align*}
X : \Omega &\rightarrow \mathbb{R}, \\
    \omega = (x_1, \ldots, x_n) &\mapsto \frac{1}{n}\left[\sum_{i=1}^n x_i\right].
\end{align*}

Esses breves exemplos sugerem que é \emph{econômico} e \emph{útil} trabalhar com
funções definidas em $\Omega$, em vez de reformular, do zero, um novo $\Omega$
para cada pergunta relevante que possamos ter sobre eventos relacionados com o
$\Omega$ original. Sob esse ponto de vista, variáveis aleatórias não são, em
absoluto, uma necessidade. Elas são apenas uma forma cômoda de responder
perguntas sobre probabilidades.


A conveniência de trabalhar com variáveis aleatórias, entretanto, cria um novo
conjunto de ``problemas'' técnicos que agora precisam ser resolvidos. Grosso
modo, a questão é a seguinte:
\begin{quote}
Como é que o contradomínio $\mathbb{R}$ ``percebe'' a tripla de probabilidade $(\Omega,\mathscr{F},P)$?
\end{quote}

Sucede que o que faz sentido é calcular probabilidades dos subconjuntos de
$\mathbb{R}$ pertencentes à classe $\mathscr{B}$, onde $\mathscr{B}$ é a
sigma-álgebra de Borel. 

Lembremo-nos de que $\mathscr{B}$ é a menor sigma-álgebra que contém os
intervalos $(a,b]$, $a,b \in \mathbb{R}$, os intervalos $(-\infty,b]$,
    $(a,+\infty)$, e também os intervalos $[a,b]$, $(a,b)$, $[a,b)$ e suas
      uniões e interseções, e todos os conjuntos abertos e fechados.

\textbf{Não sei o que os conjuntos abertos e fechados estão fazendo aqui.  Seria
  bom explicar sua relação com os intervalos.}


Precisamos, portanto, ``ligar'', de alguma forma, $\mathscr{B}$ a $\mathscr{F}$,
esta última a sigma-álgebra da tripla de probabilidade ``original''. No fim, o
que vai funcionar é o seguinte: para qualquer $B \in \mathscr{B}$, vamos definir
a probabilidade de conjuntos mensuráveis em $\mathscr{B}$ como
\begin{equation}
\mathcal{P}(B) \equiv P\bigl(X^{-1}(B)\bigr).\label{eq:P-in-borel}
\end{equation}
É claro que é preciso ``garantir'' que $X^{-1}(B) \in \mathscr{F}$. Pode-se
mostrar que uma condição suficiente para isso é que 
\begin{equation}
X^{-1}\bigl( (-\infty,b]\bigr) \in \mathscr{F}.  \label{eq:X-mensuravel}
\end{equation}
Dizemos que, se $X$ atende (\ref{eq:X-mensuravel}), $X$ é uma função
\emph{mensurável}. Portanto,


\begin{Def}
Dada uma tripla de probabilidade $(\Omega, \mathscr{F}, P)$, uma \emph{variável aleatória} é uma função
\begin{align*}
   X : \Omega &\rightarrow \mathbb{R}, \\
\omega        &\mapsto x = X(\omega),
\end{align*}
tal que 
\[
\forall b \in \mathbb{R}, \; X^{-1}\bigl((-\infty,b]\bigr) \in \mathscr{F}.
\]
\end{Def}

É interessante observar que definição de mensurabilidade de uma função é feita
em termos da relação (não necessariamente uma função) \emph{inversa} $X^{-1}$. 
O motivo é técnico: uniões, interseções e complementos \emph{arbitrários} de
conjuntos $B \in \mathscr{B}$ \emph{permanecem em $\mathscr{B}$}. Da mesma
forma, é preciso garantir que as pré-imagens dessas uniões, interseções e
complementos \emph{permaneçam em $\mathscr{F}$}. Dadas as propriedades de
fechamento de qualquer sigma-álgebra sob essas operações, essa garantia é dada
pelas propriedades sempre válidas (dada uma função $X$ qualquer, não
necessariamente mensurável --- isso é outra parte de nossos requisitos!):
\begin{align*}
X^{-1}\left(A \cup B\right) &= X^{-1}(A) \cup X^{-1}\left(B\right), \\
X^{-1}\left(A \cap B\right) &= X^{-1}(A) \cap X^{-1}\left(B\right), \\
X^{-1}\left(\overline{A}\right) &= \overline{X^{-1}\left(A\right)}. \\
\end{align*}
As duas primeiras relações podem ser estendidas para uniões e
interseções arbitrárias (não necessariamente enumeráveis, embora isso
baste para nossas sigma-álgebras):
\begin{align*}
X^{-1}\left(\bigcup_{\lambda \in \Lambda} A_\lambda\right) &= \bigcup_{\lambda  \in \Lambda} X^{-1}(A_\lambda), \\
X^{-1}\left(\bigcap_{\lambda \in \Lambda} A_\lambda\right) &= \bigcap_{\lambda  \in \Lambda} X^{-1}(A_\lambda).
\end{align*}
A necessidade de definir mensurabilidade usando $X^{-1}$ decorre do
fato de que \emph{é falso que}:
\begin{align*}
X\left(A \cap B\right) &= X(A) \cap X\left(B\right), \\
X\left(\overline{A}\right) &= \overline{X\left(A\right)}. \\
\end{align*}
Para isso, bastam dois contra-exemplos.
\begin{Exe}
Sejam $A = (-\infty,0)$ e $B=[0,+\infty)$.  Então, $\overline{A} = B$
  e $\overline{B} = A$.  Dada a função
\begin{align*}
   f: \mathbb{R} &\rightarrow \mathbb{R}, \\
               x &\mapsto 1,
\end{align*}
Temos:
\[
A \cap B = \emptyset, \qquad f(A) = f(B) = \{ 1\},
\]
e
\[
f(A) \cap f(B) = \{ 1\} \ne \emptyset = f(A \cap B).
\]

\skipend

\end{Exe}
\begin{Exe}
Sejam $A = (-\infty,0)$ e $B=[0,+\infty)$.  Então, $\overline{A} = B$
  e $\overline{B} = A$.  Dada a função
\begin{align*}
   f: \mathbb{R} &\rightarrow \mathbb{R}, \\
               x &\mapsto x^2,
\end{align*}
Temos: 
\[
f(\overline{A}) = f(B) = [0,\infty) = B \ne [0,-\infty) = \overline{f(A)}.
\]

\skipend

\end{Exe}


Uma função mensurável em $\Omega$ tem o papel de transferir a estrutura
$(\Omega,\mathscr{F},P)$ para uma tripla equivalente
$(\mathbb{R},\mathscr{B},\mathcal{P})$. A probabilidade de sub-conjuntos de
$\mathbb{R}$ que ``fazem sentido'' está bem definida por (\ref{eq:P-in-borel})
(na verdade, nos sub-conjuntos que pertencem a $\mathscr{B}$ (a sigma-álgebra de
Borel) e também possivelmente mais alguns, que pertencem a $\mathscr{L}$ (a
sigma-álgebra de Lebesgue) --- mas a diferença entre ambos consiste em conjuntos
de medida zero).
Seguem-se
\begin{align*}
\mathcal{P}(\mathbb{R}) &= 1, \\
0 &\le \mathcal{P}(B) \le 1, \\
\mathcal{P}\left[ \bigsqcup_{i=1}^\infty B_i\right] &= \sum_{i=1}^\infty \mathcal{P}(B_i)\qquad\text{$\sigma$-aditividade}
\end{align*}

Cabe observar que nem toda função de $\Omega$ em $\mathbb{R}$ é uma variável
aleatória.
Considere por exemplo a função
\begin{align*}
\mathbbm{1}_{\overline{T}} : (0,1] &\rightarrow \mathbb{R}, \\
                             \omega &\mapsto \begin{cases} 1, & \omega \in
                               \overline{T}\cap(0,1], \\
                               0, & \omega \in T.\end{cases}
\end{align*}
onde $T$ é o conjunto de Vitali definido na seção \ref{sec:conj-vitali}. Sabemos
que $T$ é não-mensurável: $T \not\in \mathscr{F}$.  Segue-se que a função
$\mathbbm{1}_{\overline{T}}$ não é mensurável:
\begin{align*}
\mathbbm{1}_{\overline{T}}^{-1}\bigl( \left(-\infty,1/2\right]\bigr)
   &= \bigl\{ \omega \in (0,1] : \mathbbm{1}_{\overline{T}}(\omega) \in \left(-\infty,1/2\right]\bigr\}\\
   &= \bigl\{ \omega: \mathbbm{1}_{\overline{T}}(\omega) = 0\bigr\}\\
   &= T \not\in\mathscr{F}\blob
\end{align*}

\section{2014-03-19: Propriedades de variáveis aleatórias\label{sec:propva}}

Exemplos de variáveis aleatórias construídas a partir de outras:
\begin{enumerate}
\item Se $A \in \mathscr{F}$,
\begin{align*}
\mathbbm{1}_{A} : \Omega &\rightarrow \mathbb{R}, \\
                             \omega &\mapsto \begin{cases} 1, & \omega \in A, \\
                               0, & \omega \not\in A.
                               \end{cases}
\end{align*}
é uma variável aleatória em $(\Omega,\mathscr{F},P)$.
\item Se $X$,$Y$ são duas variáveis aleatórias em $(\Omega,\mathscr{F},P)$, então
      \begin{enumerate}[a)]
         \item $X + Y$ é uma variável aleatória;
         \item $cX$ é uma variável aleatória;
         \item $X + c$ é uma variável aleatória;
         \item $X^2$ é uma variável aleatória;
         \item $XY$ é uma variável aleatória.
      \end{enumerate}
\item Se $(X_1, X_2, \ldots, X_n, \ldots)$ é uma sequência de variáveis aleatórias e $\lim_{x\to\infty}X_n(\omega)$ existe para cada $\omega$, então:
\begin{align*}
   X : \Omega &\rightarrow \mathbb{R}, \\
       \omega &\mapsto \lim_{n\to\infty} X_n(\omega)
\end{align*}
satisfaz 
\[
X^{-1}\bigl( (-\infty,b]\bigr) \in \mathscr{F}.
\]
A prova é complicada!  Rosenthal:
\[
X^{-1}\bigl( (-\infty,b]\bigr) = 
\bigcap_{m=1}^\infty \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty X_k^{-1}\left(-\infty, x + \frac{1}{m}\right].
\]
\item $\max(X,Y)$, $\min(X,Y)$ e $|X|$ são variáveis aleatórias.
Notando que
\begin{align*}
\max(X,Y) &= \frac{1}{2}\left[ X + Y + |X-Y|\right], \\
\min(X,Y) &= (X+Y) - \max(X,Y), 
\end{align*}
basta provar para o $|X|$.
\item $\sup_n X_n$, $\inf_n X_n$ são variáveis aleatórias, desde que bem definidos. Vale lembrar que
\[
\sup_{n\in\mathbb{N}} r_n = 
\begin{cases}
\min\left\{ r: r_n \le r, \forall n \in \mathbb{N}\right\}, \\
+\infty, & \text{se a sequência não for limitada}.
\end{cases}
\]
\item $\limsup_n X_n$ e $\liminf_n X_n$ são variáveis aleatórias. 

Forme:
\[
Y_n \equiv \sup_{N\ge n} X_N. \qquad \text{\textbf{Confirmar índices!!!}}
\]
Note que $Y_n(\omega)$ é uma função monótona (não-crescente) de $n$, para cada $\omega$. Portanto,
\[
\exists \lim_{n\to\infty} Y_n \equiv \limsup_{n\to\infty} X_n.
\]

Forme:
\[
Z_n \equiv \inf_{N\ge n} X_N. \qquad \text{\textbf{Confirmar índices!!!}}
\]
Note que $Z_n(\omega)$ é uma função monótona (não-decrescente) de $n$, para cada $\omega$. Portanto,
\[
\exists \lim_{n\to\infty} Z_n \equiv \liminf_{n\to\infty} X_n.
\]

\item Qualquer função contínua $X: \Omega \rightarrow \mathbb{R}$ é uma variável
  aleatória. Nota: para que o conceito de função contínua faça sentido, é
  preciso que, no domínio, $\mathscr{F}$ contenha os conjuntos abertos de
  $\Omega$, ou seja, que $\mathscr{F}$ seja uma $\sigma$-álgebra de Borel em
  $\Omega$.

\item Se:
\begin{align*}
X : (\Omega,\mathscr{F},P) &\rightarrow (\mathbb{R},\mathscr{B},\mathcal{P}),\\
\omega &\mapsto x = X(\omega),
\end{align*}
e
\begin{align*}
f: (\mathbb{R},\mathscr{B},|\cdot|) &\rightarrow
(\mathbb{R},\mathscr{B},|\cdot|),\\
x &\mapsto y = f(x)
\end{align*}
(ou seja: $f$ é mensurável), então $f\circ X$ é uma variável aleatória.

\end{enumerate}

Finalmente, temos uma anotação um pouco solta que precisa ser esclarecida:
$B \in \mathscr{B}$, $|B|=0$, $D \subset B$, $D$ não necessariamente em
$\mathscr{B}$, $D\in\mathscr{L}$, a qual é a $\sigma$-álgebra de Lebesgue, que é
o completamento, por $|\cdot|$, da $\sigma$-álgebra de Borel.


\section{A FDA}

Nós agora vamos definir a função distribuição acumulada (FDA) de probabilidade de uma variável
aleatória $X$:
\begin{equation}
   F_X(x) \equiv P(\{ X \le x\}).\label{eq:def-fda}
\end{equation}
A notação da equação \eqref{eq:def-fda} é normalmente simplificada para $F_X(x) \equiv P\{X \le
x\}$. A FDA nos permite calcular facilmente probabilidade relacionadas a $X$.  Por exemplo,
para obter a probabilidade de que $X$ ocorra em um intervalo $[a,b]$:
\begin{align}
   P\{ a \le X \le b \} &= P\{ X \le b\} - P\{ X \le a\}\\
		        &= F(b) - F(a).
\end{align}
As propriedades da função distribuição acumulada são:
\begin{align}
   F(-\infty) &= 0,\\
   F(+\infty) &= 1,\\
F(b) - F(a)   &\ge 0, \;\;\text{para}\;\; a < b.
\end{align}

A função densidade de probabilidade (FDP), $f_X$, é
\begin{equation}
   f_X(x) \equiv \deriva{F_X}{x},
\end{equation}
com $f_X(x) \ge 0$ e 
\begin{equation}
   \int_{-\infty}^{+\infty} f_X(x)\,\md{x} = 1.
\end{equation}

\section{Média e momentos}

A média de uma variável aleatória, ou valor esperado de uma variável aleatória, é
\begin{equation}
   \tavg{X} \equiv \int_{-\infty}^{+\infty} xf_X(x)\,\md{x}.
\end{equation}

De maneira mais geral, seja $y = q(x)$ uma função de $x$; então para cada sorteio de $X$
corresponderá um $Y = q(X)$, ou seja: $Y$ será (também) uma variável aleatória.  A média de $Y$
será dada por
\begin{equation}
   \tavg{Y} = \tavg{q(X)} = \int_{-\infty}^{+\infty} q(x)f_X(x)\,\md{x}.
\end{equation}


Momentos centrais desempenham um papel importante em Teoria de Probabilidade. A
definição do momento central de ordem $n$ é
\begin{equation}
c_{Xn} \equiv \tavg{\left( x - \tavg{X}\right)^n} 
= \int_{-\infty}^{+\infty} \left( x - \tavg{X}\right)^n\, f_X(x)\,\md{x}.\label{eq:def-cxn}
\end{equation}

\section{Distribuições conjuntas}

Para definirmos distribuições conjuntas de probabilidade, precisamos estender as
definições da seções \ref{sec:random-var}.

No $\mathbb{R}^2$, uma variável aleatória é uma função $\vet{X} = (X,Y)$ função
de $\omega \in \Omega$:
\begin{align*}
\vet{X} : \Omega \rightarrow \mathbb{R}^2, \\
        \omega   \mapsto     \vet{x} = \vet{X}(\omega).
\end{align*}

A função densidade acumulada conjunta será 
\begin{equation}
F_{X,Y}(x,y) \equiv P\left\{ X \le x \wedge Y \le y\right\},\label{eq:defFXY}
\end{equation}
e a função densidade de probabilidade será
\begin{equation}
f_{X,Y}(x,y) \equiv \parpar{F_{X,y}}{x}{y} = \parpar{F_{X,y}}{y}{x}.
\end{equation}

As funções densidade de probabilidade  \emph{marginais} são
\begin{align}
f_X(x) \equiv \int_{y=-\infty}^{+\infty} f_{X,Y}(x,y)\,\md{y}, \\
f_Y(y) \equiv \int_{x=-\infty}^{+\infty} f_{X,Y}(x,y)\,\md{x}.
\end{align}
Naturalmente,
\begin{equation}
\iint_{x,y} f_{X,Y}(x,y)\,\md{x}\,\md{y} = 1.
\end{equation}

O \emph{valor esperado} de uma função de $X$ e $Y$ é
\begin{equation}
\tavg{g(X,Y)} = \iint_{x,y} g(x,y)f_{X,Y}(x,y)\,\md{x}\,\md{y}.
\end{equation}

Com os resultados acima, nós podemos agora deduzir o seguinte fato: se $X$ e $Y$
são duas variáveis aleatórias quaisquer,
\begin{equation}
\tavg{X+Y} = \tavg{X} + \tavg{Y}.
\end{equation}

\begin{enumerate}[a)]
\item \textit{Insight} com matemática finita: seja $(x_i,y_i), \; i =
  0,\ldots,n-1$ uma amostra qualquer de $n$ pares de observações.  Então, a
  \emph{média amostral} da soma é
\begin{align*}
\overline{x+y} &= \frac{1}{n}\sum_{i=0}^{n-1} \left( x_i + y_i\right) \\
               &= \frac{1}{n}\sum_{i=0}^{n-1} x_i + \frac{1}{n}\sum_{i=0}^{n-1}y_i\\
               &= \overline{x} + \overline{y}.
\end{align*}
Note como não foi necessária nenhuma hipótese adicional sobre a natureza dos
$x$'s e $y$'s ou sobre qualquer relação entre eles.
\item com Teoria de Probabilidade.  Seja $g(x,y) = x+y$. Então,
\begin{align*}
\tavg{g(X,Y)} = \tavg{X + Y} &= \iint_{x,y} (x+y)f_{X,Y}(x,y)\,\md{y}\,\md{x} \\ 
&= \iint_{x,y} x f_{X,Y}(x,y)\,\md{y}\,\md{x} + \iint_{x,y} y f_{X,Y}(x,y)\,\md{y}\,\md{x} \\
&= \iint_{x,y} x \underbrace{\left[f_{X,Y}(x,y)\,\md{y}\right]}_{f_X(x)}\,\md{x} +
   \iint_{x,y} y \underbrace{\left[f_{X,Y}(x,y)\,\md{x}\right]}_{f_Y(y)}\,\md{y}\\
&= \int_{-\infty}^{+\infty} xf_X(x)\,\md{x} + \int_{-\infty}^{+\infty} y f_Y(y)\,\md{y}\\
&= \tavg{X} + \tavg{Y}.
\end{align*}
\end{enumerate}



Já que estamos falando de distribuições conjuntas, devemos tocar no conceito
fundamental de independência/dependência. Dados dois eventos $A$ e $B$, a
probabilidade de $B$ condicionada a $A$ é
\begin{equation}
   P(B|A) \equiv \frac{P(A \cap B)}{P(A)}\label{eq:def-probcond}
\end{equation}

\textbf{Definição:} $B$ e $A$ são independentes quando
\begin{equation} 
P(B|A) = P(B).
\end{equation}
\textbf{Corolário:} Se $A$ e $B$ são independentes,
\begin{equation}
P(B|A) = \frac{P(A \cap B)}{P(A)} = P(B) \Rightarrow P(A \cap B) = P(A)P(B).
\end{equation}

Isso nos leva imediatamente à definição de independenência de variáveis
aleatórias: $X$ e $Y$ são independentes quando os \emph{eventos}
\[
A = \left\{ \omega | X(\omega) \le x\right\} \; \text{e} \;
B = \left\{ \omega | Y(\omega) \le y\right\} 
\]
são independentes, ou seja:
\begin{align*}
P(A \cap B) &= P(A)P(B), \\
P\left( X(\omega) \le x  \wedge Y(\omega) \le y\right) &= P\left( X(\omega) \le x \right)P\left( Y(\omega) \le y\right),\\
F_{X,Y}(x,y) &= F_X(x)F_Y(y).
\end{align*}

Portanto, se $X$ e $Y$ são independentes, então a FDA conjunto é igual ao
produto das FDA's marginais. Fazendo a 2\ira\ derivada cruzada,
\begin{align*}
f_{X,Y}(x,y) &= \parpar{F_{X,Y}(x,y)}{y}{x} \\
             &= \parpar{F_{X}(x) F_{Y}(y)}{y}{x} \\
             &= \parder{}{y}\left[ \parder{F_X}{x} F_Y(y)\right]\\
             &= f_X(x)\parder{F_Y}{y}\\
             &= f_X(x)f_Y(x).
\end{align*}

A  próxima definição é a densidade de probabilidade de $y$ \emph{condicionada} à
ocorrência de $x$:
\begin{equation}
   f_{Y|x}(y) \equiv \frac{f_{X,Y}(x,y)}{f_X(x)}.\label{eq:dens-cond}
\end{equation}
Embora deva ser possível deduzir rigorosamente (\ref{eq:dens-cond}) a partir de
(\ref{eq:def-probcond}), não vou fazê-lo (ainda).  Em vez disto, vou procurar um caso particular
muito interessante.  Primeiramente, note que, por definição, a densidade marginal de $y$ é dada
por
\begin{align}
   f_Y(y) &= \int_{x=-\infty}^{+\infty} f_{X,Y}(x,y)\,\md{x} \nonumber \\
          &= \int_{x=-\infty}^{+\infty} f_{Y|x}(y)f_X(x)\,\md{x} \label{eq:y-dens-marg}.
\end{align}
Considere agora o caso  em que $y = g(x)$, ou seja: em que $Y$ está
deterministicamente determinado a partir da observação de $x$.  A função densidade de
probabilidade condicionada é então, simplesmente, 
\begin{equation}
   f_{Y|x}(y) = \delta(g(x)-y),\label{eq:delta-y-gx}
\end{equation}
ou seja: dado $x$, a probabilidade de que $Y = g(x)$ é 1 (note as letras maiúscula e
minúscula). Note também que (\ref{eq:delta-y-gx}) é uma densidade de probabilidade legítima, já
que sua integral em $y$ é igual a 1.  O primeiro resultado que vamos obter a partir daqui é uma
fórmula para $f_Y(y)$:
\begin{align}
   f_{Y}(y) &= \int_{x = -\infty}^{+\infty} f_{Y|x}(y)f_X(x)\,\md{x} \nonumber \\
            &= \int_{x = -\infty}^{+\infty} \delta(g(x)-y)f_X(x)\,\md{x}. \label{eq:gx-marginal}
\end{align}
Essa é uma equação totalmente geral, que permite o cálculo da densidade de
probabilidade de \emph{qualquer} variável aleatória definida por uma função, $Y
= g(X)$, independentemente de ela ser biunívoca ou não!  A equação
(\ref{eq:gx-marginal}) pode ser prontamente generalizada para funções de várias
variáveis.  Em particular, se $Z = g(X,Y)$, tem-se
\begin{equation}
   f_Z(z) = \int_{x = -\infty}^{+\infty}
               \int_{y = -\infty}^{+\infty}
                  \delta(g(x,y)-z) f_{X,Y}(x,y)\,\md{y}\md{x}. \label{eq:gxy-marginal}
\end{equation}

Considere agora o seguinte exemplo: $y = x^2, \; -1 \le X \le +1$, com $f_X(x) =
1/2$. Essa função \emph{não} é biunívoca.  A densidade de probabilidade de $y$ é
\begin{align}
   f_Y(y) = \int_{-1}^{+1} \delta(x^2-y)\frac{1}{2} \,\md{x}. \label{eq:first-integral}
\end{align}
Para calcular a integral acima, é preciso um pouco de cuidado.  Primeiramente, note que 
\begin{equation}
   y = x^2 \Rightarrow x = \pm \sqrt{y}:
\end{equation}
existem duas raízes, e isto precisa ser levado em consideração pelo ser humano que está
resolvendo o problema: a fórmula (\ref{eq:gx-marginal}) \emph{em si} não vai dizer isso para
você! 
O caminho mais rápido, aparentemente, é recorrer à seguinte propriedade da delta \citep[Cap. 6,
  p. 231]{butkov:fisica}:
\begin{equation}
   \delta(x^2 - a^2) = (1/2a)\left[ \delta(x+a) + \delta(x-a)\right] \qquad (a>0);
\end{equation}
então,
\begin{equation}
   f_Y(y) = \int_{-1}^{+1} \frac{1}{2\sqrt{y}}
   \left[ \delta(x+\sqrt{y}) + \delta(x-\sqrt{y})\right]\frac{1}{2}\,\md{x} 
   = \frac{1}{4\sqrt{y}}\left[ 1 + 1\right] 
   = \frac{1}{2\sqrt{y}}\blob
\end{equation}

Esse é um exemplo simples, porém muito rico.  O valor esperado de $Y$, para o qual nós vamos
usar a notação $\tavg{Y}$, agora é facilmente obtido:
\begin{equation}
\tavg{Y} = \int_0^1 yf_Y(y)\,\md{y} = \int_0^1 y \frac{1}{2\sqrt{y}}\,\md{y} = 
\int_0^1 \frac{\sqrt{y}}{2}\,\md{y} = \frac{1}{3},
\end{equation}
enquanto que, devido à simetria de $f_X(x)$, $\tavg{X} = 0$.


Mais interessante ainda é a seguinte questão: se $X$ é a variável aleatória com distribuição
uniforme entre $-1/2$ e $+1/2$, como acima, e $Y = X^2$, qual é a covariância entre $X$ e $Y$?
Por definição, a covariância entre duas variáveis aleatórias é
\begin{equation}
\Cov\{X,Y\} = 
\int_{x\in \mathbb{R}}\int_{y \in \mathbb{R}} (x - \tavg{X})(y - \tavg{Y})f_{X,Y}(x,y)\,\md{y}\md{x}.
\end{equation}


Quando duas variáveis aleatórias são independentes, sua covariância é nula:
\begin{align*}
\Cov\{X,Y\} &= \iint_{x\in \mathbb{R}, y \in \mathbb{R}}(x - \tavg{X})(y - \tavg{Y})f_{X,Y}(x,y)\,\md{y}\md{x}\\
            &= \iint_{x\in \mathbb{R}, y \in \mathbb{R}}(x - \tavg{X})(y - \tavg{Y}) f_X(x)f_Y(y)\,\md{y}\md{x}\\
            &= \left[
                  \int_{x\in\mathbb{R}}(x - \tavg{X})f_X(x)\,\md{x}
               \right]
               \left[
                  \int_{y\in\mathbb{R}}(y-\tavg{Y})f_Y(y)\,\md{y}
               \right]\\
             &= 0.
\end{align*}



No nosso caso particular, $y=x^2$, a covariância é
\begin{align}
\Cov\{X,Y\} &=
\int_{x=-1}^{1} \int_{y=0}^{1}
   x(y - \frac{1}{3})\delta(x^2 - y)f_X(x)\,\md{y}\md{x} \nonumber \\
&= \int_{x=-1}^{1} \int_{y=0}^{1}
   x(x^2 - \frac{1}{3})\delta(x^2 - y)\frac{1}{2}\,\md{y}\md{x} \nonumber \\
&= \int_{x=-1}^{1} x(x^2 - \frac{1}{3})\int_{y=0}^{1}
   \delta(x^2 - y)\frac{1}{2}\,\md{y}\md{x} \nonumber \\
&= \frac{1}{2}\int_{x=-1}^{1} x(x^2 - \frac{1}{3})
    \underbrace{\int_{y=0}^{1}\left[ \delta(x^2 - y)\,\md{y}\right]}_{=1}\md{x} \nonumber \\
&= \frac{1}{2}\int_{x=-1}^{1} x(x^2 - \frac{1}{3})\,\md{x} = 0.\label{eq:covxy-nula}
\end{align}


Na linha acima de (\ref{eq:covxy-nula}), note a utilização simultânea de duas propriedades da delta:
\begin{align}
   \int_{-\infty}^{+\infty} \delta(x-a)\,\md{x} &= 1,\\
   \delta(x) &= \delta(-x).
\end{align}
O resultado (\ref{eq:covxy-nula}) é admirável: ele mostra que, mesmo que a dependência entre
duas variáveis aleatórias seja \emph{total}; mesmo que $Y$ seja \emph{totalmente} dependente de
$X$ na forma $Y = g(X)$, é possível que $\Cov\{X,Y\} = 0$.  Moral da história: a covariância é
uma medida de dependência \emph{linear}, e \emph{não} uma medida universal de dependência.

Além da covariância, é usual encontrar o coeficiente de correlação,
\[
\varrho_{XY} = \frac{\Cov\{X,Y\}}{\left[ \Var\{X\}\Var\{Y\}\right]^{1/2}}.
\]
Com a desigualdade de Schwarz,
\[
-1 \le \varrho_{XY} \le +1
\]


Considere agora o cálculo da função densidade de probabilidade da variável aleatória $Z = X +
Y$, \emph{soma} de duas variáveis aleatórias $X$ e $Y$ cuja distribuição conjunta de
probabilidade, $f_{X,Y}(x,y)$, é conhecida.  A função densidade de probabilidade de $Z$ dada a
ocorrência de $x,y$ é
\begin{equation}
   f_{Z|x,y} = \frac{f_{Z,X,Y}(z,x,y)}{f_{X,Y}(x,y)} = \delta(z - [x+y])
\end{equation}
Segue-se que a função densidade de probabilidade marginal de $Z$ é
\begin{align}
   f_{Z}(z) &= \int_{x=-\infty}^{+\infty}\int_{y=-\infty}^{+\infty}f_{Z,X,Y}(z,x,y)\,\md{y}\,\md{x}
   \nonumber \\
            &= \int_{x=-\infty}^{+\infty}\int_{y=-\infty}^{+\infty}\delta(z - x - y)f_{X,Y}(x,y)\,\md{y}\,\md{x}
\end{align}
Lembrando das propriedades da Delta de Dirac,
\begin{align}
   \int_{-\infty}^{+\infty} \delta(y-a)f(y)\,\md{y} &= f(a),\\
   \delta(y-a) &= \delta(a-y),
\end{align}
tem-se
\begin{equation}
f_{Z}(z) = \int_{x=-\infty}^{+\infty}
            f_{X,Y}(x,z-x)\,\md{x} = \int_{y=-\infty}^{+\infty} f_{X,Y}(z-y,y)\,\md{y}\blob
\end{equation}
Finalmente, no caso de variáveis aleatórias $X$ e $Y$ independentes, as integrais acima
tornam-se integrais de convolução:
\begin{equation}
f_{Z}(z) = \int_{x=-\infty}^{+\infty} f_X(x)f_Y(z-x)\,\md{x}.
\end{equation}

Note que esta é uma convolução no sentido da Teoria de Transformadas de Fourier, e não no
sentido da Teoria de Transformadas de Laplace.

Quando, por outro lado, a relação $Y=g(X)$ é biunívoca, as coisas ficam mais
fáceis:
\begin{align*}
P\left\{ Y \le y \right\} & P\left\{ X \le x \right\}, \\
P\left\{ Y \le g(x) \right\} & P\left\{ X \le x \right\}, \\
F_Y(g(x)) &= F_X(x),\\
\mderiva{}{x} F_Y(g(x)) &= \mderiva{}{x} F_X(x), \\
\mderiva{}{y} F_Y(g(x))\mderiva{g}{x} &= f_X(x),\\
f_Y(y)\mderiva{g}{x} &= f_X(x).
\end{align*}
Mudando ligeiramente a notação, $y = y(x)$ produz
\[
f_Y(y)\md{y} = f_X(x)\md{x}
\]
cuja interpretação gráfica é óbvia.

Um caso particularmente útil e interessante é o de geração de uma variável
aleatória no computador com uma distribuição dada. A resposta é o uso da própria
FDA $F_X(x)$ no lugar de $g(x)$. Seja $U = F_X(X)$ a variável aleatória assim
gerada. Nesse caso,
\begin{align*}
f_U(u)\md{u} &= f_X(x) \md{x}, \\
f_U(u)\mderiva{u}{x} &= f_X(x).
\end{align*}
mas
\[
\mderiva{u}{x} = \mderiva{F_X(x)}{x} = f_X(x);
\]
portanto,
\begin{equation}
f_U(u) = 1, \qquad 0 \le u \le 1.
\end{equation}

A ``receita'' para gerar uma variável aleatória com FDA $F_x(x)$ é a seguinte:
\begin{enumerate}[a)]
\item gere uma variável $u$ uniforme em $[0,1]$.
\item calcule $x = F_X^{-1}(u)$.
\end{enumerate}

Quando existe uma dependência linear, do tipo $Y = aX + b$, a \emph{forma} da
distribuição não muda:
\begin{align*}
x &= \frac{y-b}{a}, \\
\mderiva{y}{x} &= a,\\
f_Y(y) \md{y} &= f_X(x)\md{x},\\
f_Y(y) \mderiva{y}{x} &= f_X(x), \\
f_Y(y) a &= f_X(x),\\
f_Y(y) &= \frac{1}{a}f_X\left( \frac{y-b}{a}\right).
\end{align*}




Seja $Y$ o estimador de uma variável cujo valor verdadeiro (de população) é $y$.  No
caso mais geral,
\begin{equation}
\tavg{Y} = y' \ne y.
\end{equation}
A diferença entre o valor médio previsto pelo modelo ($y'$) e o valor verdadeiro ($y$) é
denominada o \emph{viés} do modelo.

A figura \ref{fig:duasfdps} dá uma visão dessas relações.

\begin{figure}\centering
\includegraphics[width=0.6\textwidth]{duasfdps}
\caption{Relação entre as distribuições de probabilidade de $X$ e $Y$ quando a
  relação entre ambos é biunívoca.\label{fig:duasfdps}}
\end{figure}

\textbf{Exemplo: soma de exponenciais}

Sejam
\begin{align*}
f_X(x) = \frac{1}{\beta}\exp\left(-\frac{x}{\beta}\right),\\
f_Y(y) = \frac{1}{\beta}\exp\left(-\frac{y}{\beta}\right),
\end{align*}
ou seja: duas variáveis aleatórias $X$ e $Y$ independentes e igualmente
distribuídas com distribuição exponencial. Se $Z = X+Y$,
\begin{align*}
P\{ Z \le z \} &= P\{ X + Y \le z\}\\
               &= P\{ (X,Y) \in \mathscr{D}\}\\
               &= P(\mathscr{D}).
\end{align*}
Veja a figura \ref{fig:duasexps}

\begin{figure}\centering
\includegraphics[width=0.5\textwidth]{duasexps}
\caption{Região de integração para cálculo da distribuição da soma de duas
  variáveis aleatórias exponenciais.\label{fig:duasexps}}
\end{figure}

Agora,
\begin{align*}
P\{ X + Y \le z\} &= \int_{x=0}^z\int_{y=0}^{z-x}
\frac{1}{\beta}\exp\left(-\frac{x}{\beta}\right)
\frac{1}{\beta}\exp\left(-\frac{y}{\beta}\right)\,\md{y}\md{x} \\
&= \int_{x=0}^z \exp\left(-\frac{x}{\beta}\right)
\left[
\int_{y=0}^{z-x} \exp\left(-\frac{y}{\beta}\right)\,\md{\left(\frac{y}{\beta}\right)}
\right]
\md\left( \frac{x}{\beta}\right)\\
&= \int_{x=0}^z \exp\left(-\frac{x}{\beta}\right)\left[ 1 -
  \exp\left(-\frac{z-x}{\beta}\right)\right]\md\left( \frac{x}{\beta}\right)\\
&= \int_0^z \left( \me^{-x/\beta} - \me^{-z/\beta}\right)\md{\frac{x}{\beta}}\\
&= 1 - \me^{-z/\beta} - \frac{z}{\beta}\me^{-z/\beta}.
\end{align*}
Portanto,
\begin{align*}
F_Z(z) &= 1 - \me^{-z/\beta} - \frac{z}{\beta}\me^{-z/\beta},\\
f_Z(z) &= \frac{z}{\beta^2}\me^{-z/\beta}.
\end{align*}
A fdp tem a forma de distribuição gama, cuja fórmula geral é
\begin{equation}
f_X(x) = \frac{1}{\beta\Gamma(\alpha)}\left(\frac{x}{\beta}\right)^{\alpha-1}\me^{-\frac{x}{\beta}}.
\end{equation}
Para $\alpha=2$, $\Gamma(\alpha) = 1$, e a fórmula coincide. Esse é uma caso
particular do seguinte resultado, mais geral:
\[
X_1, \ldots X_n \sim \text{EXP}(\beta) \Rightarrow Z = \sum_{i=1}^n X_i \sim
\text{GAMA}(n,\beta).
\]

\chapter{Modelos e erros}


\begin{Exe}\label{exe:modtemp}
Seja $M$ um modelo de previsão da temperatura da água de um rio.  O modelo funciona de acordo com
o seguinte esquema:
\[
   \begin{bmatrix}
     x_1 \\
     x_2 \\
     \vdots \\
     x_n
   \end{bmatrix} \longrightarrow \fbox{$\displaystyle M(\vet{x}; \vet{\theta})$} \longrightarrow y' \ne y.
\]
Aqui, o vetor $\vet{x} = (x_1, x_2, \ldots, x_n)$ representa os \emph{dados de entrada}; eles
podem ser, por exemplo, a radiação solar incidente, a vazão do rio, a temperatura do ar, etc..
O modelo $M$ em si é composto de elementos tais como a geometria rio (largura, profundidade,
comprimento), pelas as equações utilizadas para calcular ou estimar a temperatura $y$, etc..  A
\emph{natureza} de M pode ser qualquer.  Por exemplo, M pode ser simplesmente uma regressão
linear múltipla
\begin{equation}
    y = a_0 + a_1x_1 + a_2x_2 + \ldots + a_nx_n\label{eq:Maix}
\end{equation}
mas também pode ser um modelo físico de balanço de entalpia cuja incógnita seja a temperatura da
água \citep{dias:obtencao.sol,dias.gobbi.ea:formulacao}.  Finalmente note que existe um vetor de
\emph{parâmetros} $\veg{\theta}$ de $M$.  No caso da regressão múltipla (\ref{eq:Maix}), os
parâmetros são $a_0, a_1, \ldots, a_n$.
\skipend
\end{Exe}

A partir do esquema geral representado pelo Exemplo \ref{exe:modtemp}, é fácil identificar que
numerosos erros podem ocorrer no processo de modelagem.  Em geral, nós classificamos os erros em
3 tipos
\begin{enumerate}[A)]
   \item Erro dos dados: os dados de entrada do modelo geralmente contêm erros. Só isto já faz
     com que os dados de entrada devam ser considerados como variáveis aleatórias $X_1, X_2,
     \ldots, X_n$ e consequentemente a saída do modelo, $Y$, também.
   \item Erro do modelo: todo modelo contém imperfeições e limitações, e muitas vezes é
     extremamente difícil até mesmo identificar inequivocamente um único modelo (por exemplo, é
     comum que diversas distribuições diferentes de probabilidade representem ``igualmente bem''
     um determinado conjunto de observações). 
   \item Erro dos parâmetros.  Mesmo que o modelo seja perfeito, a aleatoriedade seja dos dados
     de entrada seja das próprias observações $y$ nas quais nos baseamos para ``calibrar'' $M$
     --- o processo de estimativa dos parâmetros $\veg{\theta}$ --- faz com que estes últimos
     também carreguem incerteza.  
\end{enumerate}

Algumas estatísticas básicas de erros são definidas a seguir.

O víes do modelo é 
\begin{equation}
v \equiv \tavg{Y} - y = y' - y.  \label{eq:def-vies}
\end{equation}

O erro médio quadrático do modelo é
\begin{equation}
\EMQ\{Y\} \equiv \tavg{(Y - y)^2}
\end{equation}
e sua raiz quadrada, que tem as mesmas dimensões de $Y$, é
\begin{equation}
   \REMQ\{Y\} = \sqrt{\EMQ\{Y\}}.
\end{equation}

A variância de $Y$ é
\begin{equation}
\Var\{Y\} = \tavg{(Y - \tavg{Y})^2}.
\end{equation}

Muito importante: como em geral $\tavg{Y} \ne y$, $\EMQ\{Y\} \ne \Var\{Y\}$.  A relação entre
ambas as estatísticas pode ser obtida muito facilmente:
\begin{align}
\EMQ\{Y\} &= \tavg{(Y - y)^2} \nonumber \\
          &= \tavg{ [ (Y - y') + (y' - y) ]^2} \nonumber \\
          &= \tavg{ (Y - y')^2 + 2(Y- y')(y'-y) + (y'- y)^2} \nonumber \\
          &= \tavg{ (Y - y')^2}  + 2(y'-y)\underbrace{\tavg{(Y- y')}}_{=0} + \tavg{(y'- y)^2}
\nonumber \\
          &= \Var\{Y\} + v^2\blob
\end{align}

Um bom modelo deve combinar duas virtudes:
\begin{itemize}
   \item ser acurado: $v \rightarrow 0$;
   \item ser preciso: $\Var\{Y\} \rightarrow 0$.
\end{itemize}



\chapter{A difusão de um ponto de vista probabilístico}




\section{Um passeio aleatório}\label{sec:passeio}

Na figura \ref{fig:passale}, uma partícula move-se a partir da origem (com certeza) em passos de tempo $n$, dando ``saltos''
de 1 unidade a cada tempo.  A posição da partícula no tempo $n$ é $X(n)$.   A
\emph{probabilidade} de a partícula estar na posição $k$ no instante $n$ é
\begin{equation}
p_k(n) \equiv P\{ X(n) = k \}.\label{eq:pkn}
\end{equation}
Suponha que uma transição para cima ou para baixo seja igualmente provável, e
\emph{independente} do estado atual $X(n)$:
\begin{align}
P\{ X(n+1) = X(n) + 1\} &= 1/2, \\
P\{X(n+1) = X(n) -1 \} &= 1/2.
\end{align}
Então o estado $k$ só pode ser alcançado a partir de $k+1$ ou de $k-1$, e
\begin{equation}
p_k(n+1) = \frac{1}{2}p_{k+1}(n) + \frac{1}{2}p_{k-1}(n).\label{eq:midpk}
\end{equation}


\begin{figure}\centering
   \includegraphics[width=0.6\textwidth]{passale}
   \caption{Um passeio aleatório simples, começando sempre em $X = 0$.\label{fig:passale}}
\end{figure}

\begin{figure}\centering
   \includegraphics[width=0.6\textwidth]{derivadasnum}
   \caption{Derivadas numéricas de ordem 1 e 2.\label{fig:derivadasnum}}
\end{figure}

Para prosseguirmos, nós vamos necessitar de derivadas numéricas. Veja a figura
\ref{fig:derivadasnum}: as derivadas numéricas \emph{centradas} em $x = (i+1/2)\Delta x$, e $x =
(i-1/2)\Delta x$ são
\begin{align}
f'_{i+1/2} &\approx \frac{f_{i+1} - f_i}{\Delta x}, \\
f'_{i-1/2} &\approx \frac{f_i - f_{i-1}}{\Delta x}.
\end{align}
A derivada numérica é o coeficiente angular da secante entre 2 pontos; a derivada \emph{exata} é
o coeficiente angular da tangente geométrica.  Na figura \ref{fig:derivadasnum}, ambas são
mostradas: se você possuir uma vista suficientemente boa, procure identificar visualmente a
diferença entre elas.


A derivada segunda é a derivada da derivada:
\begin{align}
f''_i &\approx \frac{f'_{i+1/2} - f'_{i-1/2}}{\Delta x} \nonumber \\
      &= \frac{\frac{f_{i+1} - f_i}{\Delta x} - \frac{f_i - f_{i-1}}{\Delta x}}{\Delta
  x}\nonumber \\
      &= \frac{f_{i+1} - 2f_i + f_{i-1}}{\Delta x^2}.
\end{align}
Com isto, nós podemos agora manipular a equação (\ref{eq:midpk}):
\begin{align}
p_k(n+1) &= \frac{1}{2}\,\left( p_{k+1}(n) + p_{k-1}(n) \right) \nonumber \\
2p_k(n+1) &=   p_{k+1}(n) + p_{k-1}(n) \nonumber \\
2(p_k(n+1) - p_k(n)) &=   p_{k+1}(n) -2 p_k(n) + p_{k-1}(n)  \nonumber \\
\frac{p_k(n+1) - p_k(n)}{\Delta x^2} &= \frac{1}{2} \,\frac{p_{k+1}(n) -2 p_k(n) +
  p_{k-1}(n)}{\Delta x^2}\nonumber \\
\frac{p_k(n+1) - p_k(n)}{\Delta t} &= \frac{\Delta x^2}{2\Delta t}\, \frac{p_{k+1}(n) -2 p_k(n) +
  p_{k-1}(n)}{\Delta x^2}\label{eq:era-pkn}
\end{align}
Faça agora 
\[
p_k(n) = p(k\Delta x, n\Delta t) = p(x,t)
\]
e mantenha
\begin{equation}
\mathscr{D} = \frac{\Delta x^2}{2\Delta t} \label{eq:Dconst}
\end{equation}
constante, enquanto $\Delta x \to 0$. (\ref{eq:era-pkn}) torna-se
\begin{align}
\frac{p(x,t+\Delta t) - p(x,t)}{\Delta t} &= \mathscr{D}\, \frac{p(x+\Delta x,t) - 2p(x,t) +
  p(x-\Delta x,t)}{\Delta x^2} \nonumber \; \to \\
\parder{p}{t} &= \mathscr{D}\,\parn{p}{x}{2}.\label{eq:governing-pt}
\end{align}
Esta é a mesma equação de difusão que nós resolvemos no capítulo \ref{cap:edp}! Isto significa
que nós podemos dar à concentração de uma substância uma interpretação \emph{probabilística}:
ela é (também) a probabilidade de encontrarmos em $(x,t)$ uma partícula emitida em uma certa
posição (digamos, $\xi$) no instante $t = 0$.  Mas será $\mathscr{D} = \Delta x^2/(2\Delta t)$
realmente constante?  Esta pergunta possui uma resposta \emph{estatística}, encontrada por
Albert Einstein em 1905

\section{A solução de Einstein para o movimento Browniano}\label{sec:brown-einstein}

Suponha que existem partículas movendo-se aleatoriamente dentro de um fluido de viscosidade
dinâmica $\mu$ e com temperatura termodinâmica $T$.  A força de resistência ao movimento de uma
partícula é dada pela lei de Stokes:
\begin{equation}
F_R = -6\pi \mu a \deriva{X}{t},\label{eq:fr-stokes}
\end{equation}
onde $X$ é a posição aleatória da partícula, e $a$ é o seu raio.  Em (\ref{eq:fr-stokes}), note
que $X$ é um escalar: nossa abordagem aqui será \emph{unidimensional}, porque isto é mais fácil
algebricamente. Quando fazemos isto, perdemos um pouco do realismo da situação, e muitas pessoas
têm dificuldade em raciocinar com situações que, embora matematicamente mais simples, não
possuem uma representação concreta no mundo real.  Entretanto, esta é uma \emph{excelente}
maneira de abordar aquele mundo real: aos poucos, introduzindo as dificuldades matemáticas
apenas quando não é mais possível escamoteá-las.

As velocidades das partículas, $V$, dependem da temperatura do fluido (e delas mesmas), segundo
a Mecânica Estatística, via
\begin{equation}
\tavg{\frac{mV^2}{2}} = \frac{1}{2} k T,
\end{equation}
onde $k$ é a constante de Boltzmann.

Além de $F_R$, as partículas sofrem a ação de forças aleatórias $F$, que são produzidas pelos
choques com as moléculas do fluido.  A equação de movimento (unidimensional, é claro) de um
partícula é
\begin{equation}
m\mdern{X}{t}{2} = - 6\pi \mu a \deriva{X}{t} + F. \label{eq:eq-mov-brown}
\end{equation}
Volte agora ao coeficiente de difusão dado por (\ref{eq:Dconst}): se partirmos de $x=0$, $t=0$,
teremos (para cada partícula)
\[
X^2 = 2\mathscr{D}t.
\]
Suponha que esta relação seja válida na média de todas as partículas; então,
\begin{align}
\tavg{X^2} &= 2\mathscr{D}t,\label{eq:difu-media-1}\\
\deriva{}{t}\tavg{X^2} &= 2\mathscr{D},\label{eq:difu-media-2}\\
\mdern{}{t}{2}\tavg{X^2} &= 0.\label{eq:difu-media-3}
\end{align}
Lembre-se de que por enquanto (\ref{eq:difu-media-1}) é apenas uma suposição, que nós devemos
ser capazes de provar.  Agora,
\begin{align}
\deriva{}{t}\tavg{X^2} &= \tavg{\deriva{}{t} X^2} =
\tavg{2X\deriva{X}{t}}, \label{eq:so-first}\\
\mdern{}{t}{2}\tavg{X^2} &= 2\left[ \tavg{\deriva{X}{t}}^2 + \tavg{X\mdern{X}{t}{2}}\right].
\end{align}
Invocando agora (\ref{eq:difu-media-3}) (que ainda é apenas uma hipótese que precisa ser
provada), 
\begin{equation}
\tavg{X\mdern{X}{t}{2}} = - \tavg{\deriva{X}{t}}^2.\label{eq:just-fit-difu}
\end{equation}
A equação (\ref{eq:just-fit-difu}) será útil em (\ref{eq:eq-mov-brown}); multiplicando esta
última por $X$ e utilizando (\ref{eq:just-fit-difu}):
\begin{align}
   m\tavg{X\mdern{X}{t}{2}} &= -6\pi a \mu \tavg{X\deriva{X}{t}} + \tavg{XF}, \nonumber \\
 -m\tavg{\deriva{X}{t}}^2  &= -6\pi a \mu \tavg{X\deriva{X}{t}} + \tavg{XF}.
\end{align}
Raciocine agora probabilisticamente: $X$ é a posição de uma partícula qualquer, com
$\tavg{X}=0$.  $F$ é a força aleatória sobre uma partícula, com $\tavg{F} = 0$.  $X$ e $F$
\emph{devem} ser variáveis aleatórias independentes:
\begin{equation}
\Cov\{X,F\} = 
\tavg{(X - \tavg{X})(F- \tavg{F})} = \tavg{XF} = 0.
\end{equation}
Segue-se que
\begin{align}
6\pi a \mu \tavg{X\deriva{X}{t}} &= m\tavg{\deriva{X}{t}^2} = kT, \nonumber \\
6\pi a \mu \tavg{2X\deriva{X}{t}} &= 2kT, \nonumber \\
6\pi a \mu \deriva{}{t}\tavg{X^2} &= 2kT, \nonumber \\
\deriva{}{t}\tavg{X^2} &= \frac{kT}{3\pi a \mu} = 2\mathscr{D}, \label{eq:eunaodisse} \\
\mathscr{D} &= \frac{kT}{6\pi a \mu}.
\end{align}
Observe que (\ref{eq:eunaodisse}) é a mesma que (\ref{eq:difu-media-2}): a hipótese
(\ref{eq:difu-media-1}) é \emph{consistente} com o resultado que obtivemos, e o justifica
\textit{a posteriori}.

A relação entre $k$, o número de Avogadro $N_A$, e a constante universal dos gases pode ser
encontrada nos bons livros do ramo: $R = kN_A$, ou seja:
\begin{equation}
\deriva{}{t}\tavg{X^2} = \frac{RT}{3\pi a \mu N_A};
\end{equation}
esta é uma forma de determinar experimentalmente o número de Avogadro \textcolor{red}{\maltese You should
  re-read Abraham Pais}!

Uma maneira mais formal de deduzir que $\mdern{}{t}{2}\tavg{X^2} = 0$ é a seguinte.  Suponha que
$X$ seja um processo estocástico com incrementos estacionários:
\begin{align}
\deriva{}{t}\tavg{ \left( X(t) - X(s)\right)^2} &= 0, \qquad \forall t,s, \; t > s, \nonumber \\
\deriva{}{t}\tavg{ \frac{\left( X(t) - X(s)\right)^2}{t-s} } &= 0, \nonumber \\
\deriva{}{t}\tavg{ \frac{(\Delta X)^2}{\Delta t}} &= 0, \nonumber \\
\tavg{ \frac{(\Delta X)^2}{\Delta t}} &= 2\mathscr{D}.
\end{align}

Como vimos, o distribuição de probabilidade da posição de uma partícula no passeio aleatório
descrito na seção \ref{sec:passeio} possui equação governante (\ref{eq:governing-pt}),
com
\begin{align}
   p(x,0) &= \delta(x), \label{eq:always-from-zero}\\
   \int_{-\infty}^{+\infty} p(x,t)\,\md{x} &= 1, \; \forall t.\label{eq:normalized-p}
\end{align}
É fácil interpretar estas duas últimas equações.  (\ref{eq:always-from-zero}) nos informa que
$X(0) = 0$ \emph{com probabilidade 1}: a partícula \emph{sempre} sai de $x = 0$.
(\ref{eq:normalized-p}) requer que a densidade de probabilidade possua integral unitária, o que
é óbvio. Note que (\ref{eq:governing-pt}) juntamente com as condições
(\ref{eq:always-from-zero})--(\ref{eq:normalized-p}) é um problema clássico \emph{que nós já
  resolvemos}, utilizando transformada de Fourier.  A solução que obtivemos é
\begin{equation}
p(x,t) = \frac{1}{\sqrt{4\pi D t}}\exp\left[ - \frac{x^2}{4DT}\right].\label{eq:is-p-a-sol}
\end{equation}
Se fizermos, de acordo com a teoria do movimento Browniano de Einstein da seção \ref{sec:brown-einstein} 
\begin{equation}
\sigma^2 \equiv \tavg{X^2} = 2\mathscr{D}t \label{eq:sigma-enters-scene}
\end{equation}
e substituirmos em (\ref{eq:is-p-a-sol}), teremos
\begin{equation}
p(x,t) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left[ -\frac{1}{2}\left(\frac{x}{\sigma}\right)^2\right].
\end{equation}
Esta é uma velha conhecida nossa: trata-se da distribuição normal, ou gaussiana, de
probabilidade.  Neste contexto, o \emph{desvio-padrão} da posição da partícula, $\sigma$, cresce
com a raiz quadrada do tempo $t$.

Equações do tipo (\ref{eq:sigma-enters-scene}) aparecem com frequência em problemas de difusão,
e seu surgimento agora deve estar mais claro para você.


\section{Uma introdução informal a processos estocásticos}



%% Em seguida, vamos definir o conceito, importantíssimo, de \emph{escala integral}.  De forma
%% muito grosseira, mas certamente evocativa, \emph{a escala integral é a metade do tempo que um
%% processo estocástico leva para se esquecer de si mesmo}. 
%% Na verdade ainda não definimos o que é um \emph{processo estocástico}, mas tenha
%% calma. 

Primeiro, alguns exemplos: as condições de tempo (tempo bom --- sol, ou tempo ruim ---
chuva), o total de milímetros de chuva precipitados a cada 24 horas, e a vazão em um rio a cada
dia, são todos exemplos de fenômenos que podem ser \emph{modelados} como processos estocásticos.

Note o cuidado com as palavras: estes fenômenos podem ser \emph{modelados} como processos estocásticos;
eles não \emph{são} processos estocásticos. Tanto quanto sabemos, a natureza não ``sabe'' o que
ela mesma é; somos nós que lhe atribuímos certas propriedades, e a ``enfeitamos'' com hipóteses
e modelos.  

{\itshape  De fato, é totalmente irrelevante o que a natureza realmente ``é'': tudo o que
  devemos nos perguntar é se os modelos que utilizamos são uma boa descrição daqueles aspectos
  da natureza que consideramos importante modelar, para efeito de compreensão e de previsão}

De volta aos fenômenos que identificamos como passíveis de serem modelados como processos
estocásticos, observe que
\begin{enumerate}
\item O tempo amanhã é muito parecido com o tempo hoje: se hoje o tempo está bom, é grande a
  chance de o tempo também estar bom amanhã.  Uma boa variável para testar isto é a pressão
  atmosférica.
\item Uma coisa semelhante acontece --- não por coincidência, é claro --- com a chuva: se hoje
  está chovendo, é grande a chance de ainda estar chovendo amanhã. 
\item Idem para a vazão de um rio --- de novo você deve notar que estes 3 fenômenos estão
  intimamente ligados --- se hoje a vazão de um rio está baixa (porque não chove na bacia há
  muitos dias), então é grande a chance de que ela continue baixa amanhã.
\end{enumerate}
Por outro lado, a relação entre o tempo (ou a chuva, ou a vazão) hoje e daqui a 3 meses é
praticamente nula: a persistência destes fenômenos não dura --- normalmente --- mais do alguns
dias.  Figurativamente, depois de um certo número de dias a natureza ``se esquece'' de si
mesma. A idéia aqui é que muitos fenômenos possuem uma memória ``finita''.  Nosso trabalho agora
é obter uma caracterização matemática razoável do que são processos estocásticos, e do que é a
sua ``memória''.

\begin{Def}
Um processo estocástico $X(t,\omega)$ é uma função que leva cada $\omega \in \Omega$ de um
\emph{espaço} amostral em uma função $x(t) = X(t,\omega)$.
\end{Def}


\begin{figure}
   \includegraphics[width=0.9\textwidth]{procest}
   \caption{Ilustração de um processo estocástico.\label{fig:procest}}
\end{figure}

Uma figura vale mais do que mil palavras.  A figura \ref{fig:procest} ilustra a definição de
processo estocástico.  Nesta figura, 3 valores diferentes de $\omega$ geram 3 funções $x(t)$
distintas. Mas não se engane!  A \emph{estocasticidade} --- isto é, a aleatoriedade --- do
processo está no sorteio dos $\omega$'s, e não na aparência ``aleatória'' de $x(t)$!  De fato,
cada um dos 3 gráficos de $X(t,\omega)$ na figura \ref{fig:procest} poderia ser uma função
perfeitamente suave, e ainda assim o ``processo'' seria estocástico.  A aparência de
aleatoriedade de cada um dos gráficos está ligada a propriedades \emph{adicionais} --- e muito
úteis na prática --- de alguns processos estocásticos.  Estas propriedades são a memória finita,
e a ergodicidade.  Nós agora passamos a descrevê-las.

\begin{Def} A função de autocovariância de um processo estocástico $X(t)$ é
\begin{equation}
C(r,s) \equiv \tavg{ (X(r)-\tavg{X(r)})(X(s)-\tavg{X(s)}) }\label{eq:def-crs}
\end{equation}
\end{Def}
Quando $X(t)$ é estacionário, (\ref{eq:def-crs}) simplifica-se consideravelmente. Em processos
estacionários, estatísticas calculadas em um instante $t$ qualquer não dependem do mesmo. Então,
\begin{align}
\tavg{X(r)} &= \tavg{X(s)} = \mu_X,\label{eq:mu-x-cte}\\
\tavg{(X(t)-\mu_X)^2} &= \sigma_X^2\label{eq:sigma-x-cte},
\end{align}
sendo que $\mu_X$ e $\sigma_X^2$ são \emph{constantes} ao longo do tempo.

Em segundo lugar, se $X(t)$ é estacionário, estatísticas que dependem de \emph{mais de um
  instante} permanecem inalteradas sob uma translação no tempo.  Então,
\begin{equation}
C(r,s) = C(r-s,0).\label{eq:crs0}
\end{equation}
Em outras palavras, \emph{a função de autocovariância de um processo estocástico estacionário
  depende apenas da diferença entre os instantes $r$ e $s$}.
Isto nos dá, agora, uma definição mais simples (porém também mais restrita, porque só vale para
processos estocásticos estacionários) para a função de autocovariância:
\begin{equation}
C(\tau) = \tavg{ (X(t) - \mu_X)(X(t + \tau) - \mu_X)}.\label{eq:ctau}
\end{equation}
Com $C(\tau)$ é possível definir uma 

Vamos seguir agora para uma introdução informal à Teoria de Difusão Turbulenta de Taylor.  Não
custa repetir, nossa versão é unidimensional (e portanto demasiadamente simplificada para
algumas aplicações).  


Vamos agora começar a descrição de uma outra teoria de difusão, que deve muito à de Einstein, e
que tentar analisar a difusão turbulenta sob um ponto de vista lagrangeano, ou seja: sob o ponto
de vista do passeio aleatório de uma partícula em um fluido em escoamento turbulento.

Da mesma maneira que na seção \ref{sec:brown-einstein}, nós vamos estudar o problema em uma
dimensão, para simplificar a matemática.

Em primeiro lugar, note que a posição $X$ de uma partícula no instante $t$ pode ser interpretada
como uma soma de incrementos, como se segue:
\begin{equation}
X(t) = \int_0^t U(\tau)\,d\tau \nonumber = \lim_{\Delta \tau \to 0} \sum_k U(\tau_k)\Delta \tau.\label{eq:XisSum}
\end{equation}
Em (\ref{eq:XisSum}), $U$ é a velocidade da partícula em cada instante, e a integral foi
re-interpretada como (o limite de) uma soma de Riemman.  É muito razoável agora supor que todos
os $U(\tau_k)$'s são indenticamente distribuídos, e invocar o Teorema Central do Limite. Nós
concluímos então, imediatamente, que $X$ é distribuído normalmente.


Nosso ponto de partida --- que já foi dado --- é a integral
(\ref{eq:XisSum}).  Vamos supor que o campo de velocidade $U$ que transporta a partícula possui
média zero: $\tavg{U} = 0$.  Segue-se de (\ref{eq:XisSum}) que 
\begin{equation}
\tavg{X(t)} = \tavg{\int_0^t U(\tau)\,d\tau} = \int_0^t \tavg{U(\tau)}\,d\tau = 0.
\end{equation}
A função de autocovariância simplifica-se ainda mais:
\[
C(\tau) = \tavg{X(t)X(t+\tau)}.\label{eq:ctau0}
\]


\begin{Proj}
Um processo estocástico ``clássico'' é o modelo AR-2 dado por
\begin{equation}
X_{n} = a_1X_{n-1} + a_2X_{n-2} + E
\end{equation}
onde $E$ é um ruído branco de média zero e variância $\sigma^2$. Os parâmetros $a_1$ e
$a_2$ devem obedecer a \citep[eq. 2.54]{bras-rodriguez-iturbe--random}:
\begin{align*}
   a_1 + a_2 &< 1,\\
   a_2 - a_1 &< 1,\\
-1 < a_2 &< 1.
\end{align*}
Por exemplo, podemos ter $a_1 = 0{,}8$, e $a_2 = -0{,}2$.
\end{Proj}



\bibliography{all}
\bibliographystyle{belllike}

\end{document}
