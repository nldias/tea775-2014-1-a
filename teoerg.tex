\documentclass[12pt]{report} 
\usepackage[a4paper,top=30mm,bottom=30mm,left=25mm,right=25mm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[brazil]{babel}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{hyphenat}
\usepackage{setspace}
\usepackage{stmaryrd}
\usepackage{upgreek}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{textcomp}
\usepackage{mathrsfs}
\usepackage{enumerate}
\usepackage{ntheorem}
\usepackage{natbib}
\usepackage{bbm}
\usepackage{needspace}
\usepackage[pdftex,colorlinks=true,%
   urlcolor=blue,
   linkcolor=blue,
   citecolor=blue,
   filecolor=blue]{hyperref}


\input{math.tex}
\input{ira.tex}

{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily\small}
 \theoremprework{\needspace{1cm}\bigskip\hrule height1pt\leavevmode}
 \newtheorem{Exe}{Exemplo}[chapter]
}


\newcommand{\skipsol}{\vspace*{0.1cm}
%\hrule
\vspace*{0.1cm}
\noindent SOLUÇÃO
}


\newcommand{\skipend}{\vspace*{1ex}\hrule width5cm height1pt}
\newenvironment{Def}{
\abovedisplayskip=18pt plus 3pt minus 9pt
\abovedisplayshortskip=0pt plus 3pt
\belowdisplayskip=9pt plus 3pt minus 0pt
\belowdisplayshortskip=0pt plus 3pt minus 0pt
\vspace*{0.5cm}
  \hrule \vspace*{0.25cm} \noindent\textbf{Definição:}}{\vspace{0.250cm
    plus 0pt minus 0.250cm} \hrule \vspace{0.5cm plus 0pt minus 0.125cm}}
{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily\small}
 \newtheorem{Proj}{Projeto}[chapter]
}
{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily}
 \theoremprework{\needspace{1cm}\bigskip\hrule\leavevmode}
 \theorempostwork{\hrule\bigskip}
 \newtheorem{Teo}{Teorema}[chapter]
}

{\theoremheaderfont{\bfseries}
 \theorembodyfont{\rmfamily}
 \theoremprework{\needspace{1cm}\bigskip\hrule\leavevmode}
 \theorempostwork{\hrule\bigskip}
 \newtheorem{Lema}{Lema}[chapter]
}




\title{Lições de Teoria Ergódica, Processos Estocásticos e Sistemas Dinâmicos}
\author{Ailín Ruiz de Zárate\\Nelson Luís Dias}
\date{\today}

\begin{document}

\maketitle

\chapter{Introdução}\label{chap:intro}

Em \citeyear{reynolds--b-dynamical}, Osborne Reynolds publicou um artigo sobre
escoamentos turbulentos no qual pela primeira vez aparece o que hoje denominamos
decomposição de Reynolds: o campo de velocidade $\vet{U} = U_i\vet{e}_i$ de um
fluido foi decomposto em $U_i = \tavg{U_i} + u_i$ (``média'' e ``flutuação''), e
equações para as médias $\tavg{U_i}$, e para o segundo momento $\tavg{u_i u_i}/2$,
foram deduzidas a partir de promediações das equações de Navier-Stokes para
$U_i$ (a velocidade do fluido no ponto $\vet{x} = x_i\vet{e}_i$, e no instante
$t$).

Reynolds deu à promediação `$\tavg{\cdot}$' que ele usou o significado de uma
média espacial, num procedimento claramente inspirado pelo trabalho anterior, e
pioneiro, de Maxwell sobre a teoria cinética dos gases
\citep{maxwell--dynamical.theory.gases}.

Logo, percebeu-se que a dedução das equações para os momentos de ordem
1 e 2 (as equações de Reynolds) a partir das equações de Navier-Stokes requeria
um conjunto de postulados, \emph{que não aparece explicitamente no artigo de
\citeyear{reynolds--b-dynamical}}:

\begin{align}
\tavg{u_i} &= 0, \label{eq:pos-rey-zero-mean}\\
\tavg{\tavg{U_i}} &= 0, \label{eq:pos-rey-mean-mean}\\
\tavg{u_i\tavg{U_j}} &= 0, \label{eq:pos-rey-mean-fluct}\\
\tavg{\parder{U_i}{t}} &= \parder{\tavg{U_i}}{t},\label{eq:pos-rey-t-der}\\
\tavg{\parder{U_i}{x_j}} &= \parder{\tavg{U_i}}{x_j}.\label{eq:pos-rey-x-der}
\end{align}

Os ``postulados'' (\ref{eq:pos-rey-zero-mean})--(\ref{eq:pos-rey-x-der})
aparecem, de uma forma ou de outra, em todos os livros-texto importantes de
turbulência. Por exemplo (e a lista não é abrangente): \cite{hinze:turbulence},
\cite{tennekes.lumley--first}, \cite{monin.yaglom:statistical.vol2},
\cite{pope:turbulent}. 

O significado original da promediação de Reynolds não se manteve: a analogia
entre o movimento das moléculas de um gás e o das partículas materiais de um
fluido (debaixo da hipótese do contínuo) é essencialmente insustentável
\cite[][Capítulo 1]{tennekes.lumley--first}.

Curiosamente, em nenhum caso os autores acima (ou quaisquer outros que sejam de
nosso conhecimento) procuram deduzir matematicamente
(\ref{eq:pos-rey-zero-mean})--(\ref{eq:pos-rey-x-der}), com a possível exceção
de \cite{kundu:fluid}, que o faz para um \textit{ensemble}, supostamente finito,
de realizações do escoamento turbulento.

A definição mais comumente encontrada de `$\tavg{\cdot}$', e que formalizaremos
neste texto, é o de uma média probabilística (\textit{ensemble average}), mas
mesmo aqui uma definição precisa não pode ser facilmente encontrada na
literatura de turbulência.

De qualquer forma, a abordagem estatística de sistemas complexos era promissora,
e logo Reynolds recebeu a compania ilustre de
\cite{einstein--uber.molekularkinetischen} (movimento browniano),
\cite{langevin--brownien} (idem), \cite{taylor--statistical-a,
  taylor--statistical-b, taylor--statistical-c, taylor--statistical-d}
(turbulência), e, naturalmente, \cite{kolmogorov--local.russian} (turbulência).

Entretanto, o \emph{significado} de se tomar médias probabilísticas sobre os
resultados de um processo determinístico está longe de ser
óbvio. Intuitivamente, a motivação é que o processo é suficientemente
``complexo'' (as velocidades das moléculas de um gás; um escoamento turbulento;
o movimento browninao; etc.) para que seja mais fácil lidar apenas com médias e
desvios-padrão, ou seja, \emph{estatísticas}, e não com realizações,
trajetórias, moléculas, partículas, etc., \emph{individuais}. Ainda assim, do
ponto de vista experimental, a tomada de médias sobre realizações é fortemente
restrita pela disponibilidade de tais realizações. A saída é supor, debaixo de
hipóteses adicionais tais como estacionariedade (mas que por si só não é
suficiente), que médias tomadas sobre um número pequeno de realizações (tão
pequeno quanto uma única) são capazes de estimar as médias de \emph{ensemble}.
Essa é a \emph{hipótese ergódica}.

De todo modo, os procedimentos adotados pelos pioneiros eram necessariamente
intuitivos, e tiveram que aguardar, como acontece tantas vezes na história da
Física e da Matemática, por formalização posterior.  A própria teoria de
probabilidade só seria definitivamente formalizada por
\citeauthor{kolmogorov--foundations} em \citeyear{kolmogorov--foundations}; o
teorema ergódico é devido a \cite{birkhoff-proof-ergodic}, e a
\cite{neumann--zuroperatorenmethode}.

Finalmente, as conexões entre processos estocásticos e sistemas dinâmicos, que
em última análise justificam o procedimento informal dos pioneiros, parecem ser
ainda mais recentes \cite[ver][]{lebowitz.penrose--modern.ergodic,
  collet--dynsys.valparaiso}.

Neste texto, nós procuramos ao mesmo tempo traçar uma parte da história da
abordagem estatística de sistemas dinâmicos, desde
\cite{maxwell--dynamical.theory.gases} até a atualidade, e prover um nível
intermediário de formalização. 

A formalização aqui não é feita no espírito de ``arte pela arte'', mas sim no de
embasar mais firmemente as análises de caráter probabilístico de sistemas
físicos determinísticos, representados matematicamente por sistemas dinâmicos.



\chapter{2014-02-19: Aditividade finita}\label{chap:add-finite}

\section*{Como conceitualizamos e formalizamos a propabilidade?}

Existem várias abordagens possíveis:
\begin{enumerate}
\item Clássica (teórica ou ``a priori''):

Consideramos um processo aleatório com $n$ resultados igualmente prováveis, e um
evento $A$ que consiste em $m$ desses resultados. A probabilidade desse evento é
então definida por
\[
P(A) \equiv \frac{m}{n}.
\]
Crítica: no termo ``igualmente prováveis'', já há a suposição de que nós
``sabemos'' o que é probabilidade antes de defini-la. Trata-se portanto de um
argumento circular. (COMO PODEMOS MELHORAR ESSE TEXTO?)



\item Empírica (``a posteriori'' ou frequentista):

Supõe-se que um determinado experimento é repetido $n$ vezes ``nas mesmas
condições''. Se $A$ é um evento identificável no experimento, a probabilidade de
$A$ é definida como o limite da razão entre número $m$ de ocorrências de $A$ e o
número de repetições $n$ quando $n \to \infty$:
\[
P(A) \equiv \lim_{n\to\infty} \frac{m}{n}.
\]

\item  Subjetiva:

Aceita-se que podemos atribuir a diversos eventos uma ``probabilidade'' de
ocorrência. Por exemplo, eu \emph{acho} que a probabilidade de que eu encontre
petróleo no terreno de minha casa é (ou deve ser) $10^{-12}$.

\item Axiomática  \citep{kolmogorov--foundations}.

Uma tripla de propabilidade é uma tripla formada por $(\Omega, \mathscr{F},P)$,
sendo $\Omega$ um conjunto não vazio, $\mathscr{F}$ um campo sigma
(uma $\sigma$-álgebra) de subconjuntos de $\Omega$ (PRECISAMOS USAR OS TERMOS CORRETOS), e $P$ uma função, com

\begin{align*}
P :\mathscr{F} &\rightarrow [0,1], \\
A \in \mathscr{F} &\mapsto P(A).
\end{align*}

Axiomas:

\begin{align}
P(A) &\geq 0,\label{eq:posprob}\\
P(\Omega) &=1,\label{eq:omegaprob}\\
P\left( \bigcup_{i=1}^n A_i\right) &= \sum_{i=1}^n P(A_i), \qquad \text{se} \qquad A_i \cap A_j = \emptyset.\label{eq:finite-additivity}
\end{align}

\end{enumerate}

Os axiomas funcionam quando $\Omega$ é finito. Contudo, há conjuntos
maiores/infinitos (?) para os quais a noção de probabilidade não faz
sentido. Assim, uma $\sigma$-álgebra será um subconjunto de $2^\Omega$ com uma
certa estrutura, para o qual deverá fazer sentido especificar probabilidades.

\textbf{Exemplo}: Sabendo que $A_1 \cup A_2 \cup A_3 =(A_1 \cup A_2)\cup A_3$,
prove por indução que o axioma (\ref{eq:finite-additivity}) vale para todo $n$
se ele valer para $n=2$.

Para $n=2$,
\begin{equation}
A_1 \cup A_2 = \emptyset \Rightarrow P(A_1\cup A_2) = \sum_{i=1}^2 P(A_i). \label{eq:ax3n2}
\end{equation}

Suponha agora que (\ref{eq:finite-additivity}) valha para $n$, e que 
\[
A_{n+1} \cap \left[ \bigcup_{i=1}^n A_i\right] = \emptyset, \qquad i = 1,\ldots, n.
\]
Então,
\begin{eqnarray}
P\left(A_1\cup ...\cup A_n\cup A_{n+1}\right)=P(B\cup A_{n+1}),
\end{eqnarray}
fazendo-se
\[
B = \bigcup_{i=1}^n A_i.
\]
A partir de (\ref{eq:ax3n2}),
\begin{equation}
P\left( B \cup A_{n+1}\right) = P(B) + P(A_{n+1}).
\end{equation}
Por sua vez, como supusemos a validade de (\ref{eq:finite-additivity}),
\begin{eqnarray}
P(B)=P\left(\bigcup_{i=1}^n A_i\right)=\sum_{i=1}^n P(A_i).
\end{eqnarray}
Logo,
\begin{equation}
P(A_1\cup ...\cup A_n\cup A_{n+1}) = P(A_{n+1}) + \sum_{i=1}^n P(A_i) =
\sum_{i=1}^{n+1} P(A_i).
\end{equation}


Note entretanto que, para que a prova seja válida, precisamos garantir que 
\[
A_{n+1} \cap \left[ \bigcup_{i=1}^n A_i\right] = \emptyset \Rightarrow
A_{n+1} \cap A_i = \emptyset, \forall i = 1, \ldots, n.
\]
Faça $C = A_{n+1}$, e considere a igualdade:
\begin{equation}
C\cap \left[\bigcup_{i=1}^n A_i\right] = \bigcup\limits_{i=1}^n C\cap A_i. \label{eq:dist-capcup}
\end{equation}
Se ela for verdadeira, então:
\begin{align*}
A_{n+1} \cap \left[ \bigcup_{i=1}^n A_i\right] = \emptyset &\Rightarrow
\bigcup\limits_{i=1}^n C\cap A_i = \emptyset\nonumber \\
&\Rightarrow A_{n+1} \cap A_i = \emptyset, \qquad\forall i = 1,\ldots, n.
\end{align*}
Portanto, se (\ref{eq:dist-capcup}) for verdadeira, a questão está liquidada.

De fato, 
\begin{align*}
x \in C \cap \left[ \bigcup_{i=1}^n A_i \right]&\Rightarrow \left(x \in C \right) \;\text{e}\; \left(x \in \bigcup_{i=1}^n A_i\right), \\
&\Rightarrow \exists j \in \{1,\ldots,n\} \mathop{|} \left( x \in C \right) \;\text{e}\; \left( x \in A_j\right)\\
&\Rightarrow x \in C \cap A_j\\
&\Rightarrow x \in \bigcup_{i=1}^n C \cap A_i.
\end{align*}
Isso significa que 
\[
C\cap \left[\bigcup_{i=1}^n A_i\right] \subseteq \bigcup\limits_{i=1}^n C\cap
A_i.
\] 
Por outro lado,
\begin{align*}
x \in \bigcup_{i=1}^n C \cap A_i &\Rightarrow \exists j\mathop{|} x \in C \cap A_j\\
&\Rightarrow x \in C \cap \bigcup_{i=1}^n A_i.
\end{align*}
Isso significa que
\[
\bigcup\limits_{i=1}^n C\cap
A_i \subseteq C\cap \left[\bigcup_{i=1}^n A_i\right] .
\]
Com isso, (\ref{eq:dist-capcup}) está provada, e chegamos ao fim (desta prova).


%% $\subset$)
%% \begin{eqnarray}
%% x \in C\cap[\mathop{\cup}\limits_{i=1}^n A_i] &\Leftrightarrow&  x \in C \text{ e } x \in \mathop{\cup}\limits_{i=1}^n A_i,  \text{ logo}\\
%% \exists\quad j \in \{1,..,n\} &\mid& x \in A_j, \text{ e}\\
%% x \in C \text{ e } x\in A_j &\Leftrightarrow& x\in C\cap A_j.
%% \end{eqnarray}

%% $\supset$)
%% \begin{eqnarray}
%% x\in \mathop{\cup}\limits_{i=1}^n C\cap A_i &\Leftrightarrow& \exists K \in \{1,...,n\}\mid x\in C\cap A_K, \text{ então}\\
%% x\in C &\text{ e }& x\in A_K, \\
%% x&\in& C\cap\mathop{\cup}\limits_{i=1}^n A_i, \\
%% x\in C &\text{ e }& x\in \mathop{\cup}\limits_{i=1}^n A_i.
%% \end{eqnarray}



\section*{Rename me!}

\subsection*{Modelos elementares}

$\Omega = \{\omega_1,...,\omega_n\}$ \textrightarrow espaço amostral

$\mathscr{F} = 2^\Omega$\textrightarrow é o conjunto potência e inclui todos o subconjuntos de $\Omega$, e, em particular, inclui
$\{\omega_1\}$,$\{...\}$,$\{\omega_n\}$, os quais são chamados eventos complementares.

\begin{eqnarray}
P(\{\omega_i\}) = P_i \in [0,1] \mid \sum\limits_{i=1}^n P_i=1
\end{eqnarray}

Caso equiprovável: $P_i = 1/n, \forall i \in \{1,...,n\}$.

\textbf{Exemplo:} 3 moedas são lançadas. Qual a probabilidade de sairem 2 caras?

Como defino $\Omega$? Se considerarmos $\Omega=\{0,1,2,3\}$, as probabilidades são $1/8$ para $0$ e $3$, e $3/8$ para $1$ e $2$. Para
$i=0,1,2,3$, temos

\begin{eqnarray}
P(i)=\left(\frac{1}{8}\right)^i\left(1-\frac{1}{8}\right)^{3-i}{3\choose i},
\end{eqnarray}

\noindent distribuição binomial herdada do modelo equiprovável.

\textbf{Exemplo:} Escolher um número no intervalo $[0,1]$ tal que $P([a,b])=b-a$ para qualquer intervalo $[a,b]\subset[0,1]$.

$\Omega = [0,1]$

A primeira tentativa seria atribuir $P(\{a\})$. Se for equiprovável com $P\neq 0$ já estaria em contradição com a aditividade.

Com um conjunto enumerável (infinito) não é possível ter equiprobabilidade nem
atribuindo probabilidade nula, porque não conseguiremos que a ``soma"das
$P(\{\})$ seja $1$.

\chapter{2014-02-24: Aditividade infinita}\label{chap:sigma-add}

(Ou $\sigma$--Aditividade)

Passamos agora para casos em que o espaço amostral $\Omega$ deixa de ser um
conjunto finito. Um conjunto infinito pode ser enumerável ou não-enumerável. Um
conjunto enumerável é um conjunto cujos elementos possam ser colocados em uma
relação biunívoca com os naturais.  Os racionais são um conjunto enumerável
(Cantor). Os números reais no intervalo fechado $[0,1]$ são um conjunto
não-enumerável. 

Quando $\Omega$ é finito, todos os elementos de $2^\Omega$ são eventos: a todos
e a cada um deles pode ser atribuída uma probabilidade, e os axiomas
(\ref{eq:posprob})--~(\ref{eq:finite-additivity}) se aplicam. 

\begin{Exe}\label{exe:n-moedas}

Antes de seguir para o infinito, considere o exemplo: $n$ lançamentos de uma
moeda, cujos resultados individuais podem ser ``cara'' (0) ou ``coroa'' (1). Os
eventos elementares com os quais podemos construir um espaço amostral são
$n$-uplas do tipo
\[
\begin{array}{c}
(0,0,\ldots,0,0)\\
(0,0,\ldots,0,1)\\
(0,0,\ldots,1,0)\\
\vdots\\
(1,1,\ldots,1,1).
\end{array}
\]
Existem $2^n$ casos. Portanto, o espaço amostral mais ``simples'' que podemos
imaginar aqui é
\[
\Omega = \left\{ \omega_k = (x_1, \ldots, x_n), x_i = \text{0 ou 1}, k = 1,\ldots,2^n\right\}
\]
Observe que 
\[
P\left(\left\{\omega_k\right\}\right) = \frac{1}{2^n}.
\]



Suponha por exemplo que desejemos calcular a probabilidade de que ocorram $k$
caras (e, consequentemente, $n-k$ coroas). Um evento deste tipo (exatamente $k$
caras e $n-k$ coroas) pode ocorrer de $n!$ maneiras.  No entanto, a posição das
$k$ caras é imaterial: todos os $k!$ casos aparecem da mesma forma.  Idem para
os $(n-k)!$ casos de permuta das posições das coroas. Concluímos que há
\[
\binom{n}{k} = \frac{n!}{k!(n-k)!}
\]
possibilidades de ocorrência de $k$ caras.  A sua probabilidade é
\[
\frac{{\binom{n}{k}}}{{2^n}}=\binom{n}{k}\left(\frac{1}{2}\right)^k\left(\frac{1}{2}\right)^{n-k}.
\]
Isso é um caso particular da distribuição binomial. Se 0 tem probabilidade $p$,
e 1 tem probabilidade $1-p$, a probabilidade de $k$ zeros em $n$ lançamentos é
\[
P(k) = \binom{n}{k} p^k (1-p)^{n-k}.
\]

\end{Exe}

\textbf{Exercício:} Mostre que
\[
\sum_{k=0}^n P(k) = 1.
\]
Prova:
\begin{align*}
( p + (1-p))^n & = 1 \\
&= \sum_{k=0}^n \binom{n}{k} p^k (1-p)^{n-k} \\
&= \sum_{k=0}^n P(k).
\end{align*}

Agora, se $\Omega = \{ x_1, x_2, x_3, \ldots \}$ for enumerável, precisamos de
\[
\sum_{i=1}^n P(x_i) = 1
\]
e fica evidente que os $P(x_i)$ não podem ser todos iguais. Entretanto, ainda é
possível aproveitar os $x_i$'s desde que a soma acima funcione.

\textbf{Exemplo}: Em um jogo, dez bolas numeradas de 0 a 9 podem ser sorteadas.
Cada jogador sorteia uma bola, mostra o resultado e retorna a bola. Ganha o
primeiro jogador que sortear um 7. O jogo poderia durar para sempre?

Nossa opção para construção do espaço amostral é 
\[
\Omega = \{ 0, 1, 2, 3, 4, \ldots \}
\]
0 significa que o 7 \emph{nunca} é sorteado; 1 significa que o 7 foi sorteado
na primeira rodada; 2 na segunda; e assim por diante. As probabilidades desses
eventos não são iguais:
\begin{align*}
P(0) &= ?, \\
P(1) &= \frac{1}{10}, \\
P(2) &= \frac{9}{10}\times \frac{1}{10},\\
P(3) &= \frac{9}{10} \times \frac{9}{10} \times \frac{1}{10}, \\
     &\vdotswithin{=} \\
P(n) &= \left( \frac{9}{10}\right)^{n-1} \times \frac{1}{10}
\end{align*}

É elementar verificar que $P(n), \; n \ge 1,$ é uma série geométrica com soma
1. Portanto, o evento ``o 7 nunca é sorteado'', indicado por 0, tem
probabilidade complementar à $P(1) + P(2) + \ldots = 1$, e sua probabilidade é
zero. 

Finalmente, considere o caso em que desejamos atribuir probabilidades dentro do
conjunto não-enumerável $\Omega = [0,1]$. Note que faz sentido atribuir
probabilidade zero a um ponto qualquer:
\[
P(X = a) = 0
\]
e que é muito razoável atribuir probabilidades a intervalos:
\[
P( [a,b] ) = b - a.
\]
O problema é que se $A$ é um evento, o seu complemento $\overline{A}$ também tem
que ser, com $P(\overline{A}) = 1 - P(A)$, pela propriedade de aditividade
finita (\ref{eq:finite-additivity}). Portanto, se $(a,b] \in \mathscr{F}$,
devemos também ter $\overline{(a,b]} \in \mathscr{F}$, onde $\mathscr{F}$ será a
classe dos eventos cujas probabilidades podem ser quantificadas.

Entretanto, o complemento de um único intervalo $(a,b]$ \emph{não} é um único
  intervalo. Desconfiamos que uma criatura desse tipo, $[0,a] \cup (b,1]$,
    precisa ser definida com as mesmas propriedades genéricas de $(a,b]$, de
      forma que ambos pertençam a $\mathscr{F}$. O caminho para $\mathscr{F}$,
      entretanto, é longo.


Uma extensão do que vimos para a binomial é a distribuição multinomial:

\begin{align*}
1 = (p_1 + \ldots + p_n)^n &= \sum_{l_1 + \ldots + l_k = n} 
                              \binom{n}{l_1 \ldots l_k}
                              p_1^{l_1}\ldots p_k^{l_k},\\
\binom{n}{l_1 \ldots l_k} &= \frac{n!}{l_1! \ldots l_k!}.
\end{align*}

\chapter{2014-02-26: Semi-anéis, anéis, e outros bichos}\label{chap:rings}




\textbf{Definição}

Uma classe $\mathscr{S}$ de conjuntos é um \emph{semi-anel} quando:
\begin{align*} 
\emptyset &\in \mathscr{S}, \\
A,B \in \mathscr{S} \Rightarrow A \cap B &\in \mathscr{S},\\
A,B \in \mathscr{S} \Rightarrow 
A - B &= A \cap \overline{B} = \bigsqcup_{i=1}^n E_i,
\end{align*}
onde $E_i \in \mathscr{S}$. O símbolo $\bigsqcup$ significa ``uniões disjuntas''.

Seja $\mathscr{S}$ a classe formada por \emph{intervalos} do tipo
\[
(a,b]  \qquad\text{ou}\qquad \emptyset.
\]

\begin{enumerate}
\item $\emptyset \in \mathscr{S}$?  Sim.
\item A interseção de dois elementos de $\mathscr{S}$ pertence a $\mathscr{S}$?

Sim: as possibilidades para interseção de $(a,b]$ com $(c,d]$ são
\begin{align*}
\emptyset &\in \mathscr{S}, \\
(c,b]     &\in \mathscr{S}, \\
(c,d]     &\in \mathscr{S}, \\
(a,d]     &\in \mathscr{S}, \\
(a,b]     &\in \mathscr{S}.
\end{align*}

Talvez seja possível resumir:
\[
(a,b] \cap (c,d] = (\max(a,c), \min(b,d)) \qquad \text{ou} \qquad\emptyset ?
\]

\item $A - B$ ($A$, $B$ intervalos) é exprimível como uma união finita disjunta
  de intervalos?

Sim:
\begin{align*}
(a,b] \cap \overline{(c,d]} &= (a,b] \cap \big[ (0,c] \cup (d,1] \big] \\
                            &= \underbrace{(a,b] \cap (0,c]}_{\in \mathscr{S}}
                \cup \underbrace{(a,b] \cap (d,1]}_{\in \mathscr{S}}\blob
\end{align*}
\end{enumerate}

Portanto, essa classe $\mathscr{S}$ de intervalos é um semi-anel.

\begin{Def}    $\mathscr{R} \subset 2^{\Omega}$ é um \emph{anel} quando:
\begin{align*}
\emptyset &\in \mathscr{R}, \\
A, B \in \mathscr{R} &\Rightarrow A \cap B \in \mathscr{R},\\
A, B \in \mathscr{R} &\Rightarrow A \mathop{\vartriangle} B \in \mathscr{R}.
\end{align*}
\end{Def}

Lembre-se:
\[
A \mathop{\vartriangle} B \equiv
(A - B) \cup (B - A).
\]

\textbf{Tivemos uma discussão sobre o motivo de se usar a diferença simétrica nessas
definições: alguém gostaria de resumir a discussão em \LaTeX?}


Anéis triviais são:
\[
\{ \emptyset, \Omega \} \qquad \text{e} \qquad
2^{\Omega}.
\]

É possível mostrar as seguintes propriedades de anéis: se $A, B \in
\mathscr{R}$, então:
\begin{align*}
A \cap B &\in \mathscr{R}, \\
A \mathop{\vartriangle} B &\in \mathscr{R}, \\
A \cup B &\in \mathscr{R}, \\
A - B &\in \mathscr{R}, \\
B - A &\in \mathscr{R}, \\
\emptyset &\in \mathscr{R}.
\end{align*}

Mas a última não faz parte da \emph{definição} de $\mathscr{R}$????

Note também que o complemento ainda não apareceu na jogada.

\textbf{Teorema}

A partir de um semi-anel $\mathscr{S}$ é possível construir um anel
$\mathscr{R}$ por meio somente de uniões disjuntas finitas de elementos de
$\mathscr{S}$, ou seja:
\[
\mathscr{R} = \left\{  \bigsqcup_{i=1}^n A_i\right\}, \; A_i \in \mathscr{S}.
\]

\textbf{Definição}

Uma \emph{álgebra} ou um \emph{campo} $\mathscr{A}$ é um anel que contém
$\Omega$. Segue-se imediatamente que
\[
A \in \mathscr{A} \Rightarrow \overline{A} \in \mathscr{A}.
\]

\textbf{Definição}
Um $\sigma$-anel é um anel fechado por uma união enumerável

Comentário: ``fechado'' significa que uniões enumeráveis de elementos do
$\sigma$-$\mathscr{R}$ ainda pertencem a ele.

Segue-se imediatamente que o $\sigma$-$\mathscr{R}$ também é fechado por
interseções enumeráveis.



\textbf{Definição}
Uma $\sigma$-álgebra ou $\sigma$-campo ou campo de Borel é uma álgebra fechada
por uniões enumeráveis.

Segue-se imediatamente que uma $\sigma$-álgebra também é fechada por interseções
enumeráveis. 

\textbf{Definição}
Dada uma classe $\mathscr{C} \subseteq 2^{\Omega}$, uma sequência monótona de
elementos $E_i \in \mathscr{C}, \; i \in \mathbb{N}$, é definida por 
\begin{align*}
E_i \subseteq E_{i+1} \\
\intertext{ou}
E_i \supseteq E_i.
\end{align*}

\textbf{Definição}
Uma classe $\mathscr{M}$ é dita \emph{monótona} quando todas as suas sequências
monótonas atendem a:
\begin{align*}
E_i \subseteq E_{i+1} &\Rightarrow \bigsqcup_{i=1}^n E_i \in \mathscr{M},\\
\intertext{ou}
E_i \supseteq E_{i+1} &\Rightarrow \bigsqcap_{i=1}^n E_i \in \mathscr{M}.
\end{align*}

A questão agora é como construir $\sigma$-álgebras a partir de álgebras, anéis
ou semi-anéis.

\textbf{Teorema}: Para as famílias $\mathscr{R}$, $\mathscr{A}$,
$\sigma$-$\mathscr{R}$, $\sigma$-$\mathscr{A}$, $\mathscr{M}$ de anéis, álgebras,
sigma-anéis, sigma-álgebras, e classes monótonas $\mathscr{M}$, interseções
arbitrárias produzem famílias de mesmo tipo.

Em resumo: se $\mathscr{F}_i, \; i \in I$, são classes de algum dos tipos acima,
então
\[
\bigsqcap_{i\in I} \mathscr{F}_i
\]
também é.

Por exemplo: se
\[
\mathscr{F}_i, \; i \in I
\]
são $\sigma$-álgebras, então 
\[
\bigsqcap_{i\in I} \mathscr{F}_i
\]
também é uma $\sigma$-álgebra.

\section{Geração de $\sigma$-álgebras}

Seja $\mathscr{S}$ um semi-anel que gera o anel $\mathscr{R}$.
A \emph{menor} $\sigma$-álgebra contendo $\mathscr{S}$ ou gerada por
$\mathscr{R}$ é denominada ``$\sigma$-álgebra de Borel'' $\mathscr{B}$.

No caso de $\Omega = [0,1]$, a $\sigma$-álgebra de Borel é a menor
$\sigma$-álgebra que contém os intervalos $(a,b]$.

Para ela, é possível definir uma medida de probabilidade
\begin{align*}
P : \mathscr{B} &\to [0,1], \\
     A \in \mathscr{B} &\mapsto P(A) \in [0,1],
\end{align*}
de tal forma que 
\begin{align*}
P(\emptyset) &= 0, \\
P(\Omega) &= 1,\\
P\left(\bigsqcup_{i=1}^\infty A_i\right) &= \sum_{i=1}^\infty P(A_i).
\end{align*}

\chapter{2014-03-10: O conjunto de Vitali: existe um conjunto não-mensurável em
  $(0,1]$}\label{chap:non-measurable-set}

%\newcommand{\ooplus}{\mathbin{\stackrel{\curvearrowleft}{+}}}
\newcommand{\ooplus}{\xhookleftarrow{+}}

\section{A q-soma e resultados preliminares\label{sec:q-soma}}

Uma nova operação será usada \textit{ad nauseam} nesta lição. Para $x,y \in
(0,1]$:
\begin{equation}
x \boxplus y \equiv 
\begin{cases}
x + y, & x + y \le 1,\\
x + y - 1, & x+ y > 1.
\end{cases}
\end{equation}
Vamos chamar ``$\boxplus$''  de q-soma, para distingui-la da soma usual em $\mathbb{R}$.

O conjunto $(0,1]$ juntamente com a operação $\boxplus$ constitui um \emph{grupo
    abeliano}, uma vez que valem as seguintes propriedades:

\begin{enumerate}[1)]
\item Fechamento:
\begin{equation}
   x \boxplus y \in (0,1]. \label{eq:box-fecha}
\end{equation} 
De fato $\boxplus$ configura uma função:
\begin{align*}
   \boxplus : (0,1] \times (0,1] &\rightarrow (0,1], \\
              (x,y)              &\mapsto z = x \boxplus y.
\end{align*}
\item Comutatividade: para $x,y \in (0,1]$, 
\begin{equation}
   x \boxplus y = y \boxplus x.  \label{eq:box-comuta}
\end{equation}
\item Associatividade:
\begin{equation}
 (x \boxplus y) \boxplus z = x \boxplus ( y \boxplus z). \label{eq:box-associa}
\end{equation}
Uma vez verificada a propriedade associativa, podemos dispensar os parênteses, e
escrever $x \boxplus y \boxplus z$.


\textbf{Precisamos de um voluntário ou voluntária para provar a associatividade.}
\item Elemento neutro:
\begin{equation}
x \boxplus 1 = 1 \boxplus x = x. \label{eq:box-neutro}
\end{equation}
\item Elemento inverso da soma:
\begin{equation}
\forall x \in (0,1], \exists y  \in (0,1]\;:\; x \boxplus y = 1. \label{eq:box-inverso}
\end{equation}
Vamos usar a notação $(\boxminus x)$ para indicar o inverso da q-soma.
É fácil ver que:
\[
   (\boxminus x) = \begin{cases}
        1, & x = 1, \\
        1- x, & x < 1.
       \end{cases}
\]
O primeiro caso é trivial, pois $1 \boxplus 1 = 1$. No segundo caso,
\[
x \boxplus y = x + y = x + (1 - x) = 1, \;\text{(pois $x + y \le 1$)}\; \; \forall x \in (0,1].
\]
\end{enumerate}

A existência do elemento inverso da soma permite que nós definamos a operação
``q-diferença'', 
$\boxminus$:
\begin{Def}
$x \boxminus y \equiv x \boxplus (\boxminus y)$.
\end{Def}


\begin{Lema}
Para $x,z \in (0,1]$:
\begin{equation}
\exists y \in (0,1]:z = x\boxplus y \Leftrightarrow \exists r \in (-1,1): z =
  x+r. \label{eq:box-rationals}
\end{equation}
\end{Lema}
\textbf{Favor verificar se os limites para o intervalo de $r$ estão corretos.}\\
Prova:
Se $x=1$,
\[
y = z \boxminus x = z \boxminus 1 = z \in (0,1] \qquad \Leftrightarrow \qquad r = y - 1 \in (-1,1).
\]
Se $x < 1$ e $z + 1 - x \le 1$,
\[
y = z \boxminus x = z + 1  - x \qquad \Leftrightarrow \qquad r = y - 1 \in (-1,1).
\]
Se $x < 1$ e $z + 1 - x > 1$,
\[
y = z \boxminus x = z   - x \qquad \Leftrightarrow \qquad r = y \in (-1,1)\blob
\]



Agora, para \emph{qualquer} subconjunto $E$ de $(0,1]$, defina um novo conjunto $E(x)$

\begin{equation}
E(x) \equiv \left\{ x \boxplus y, \; y \in E\right\}.
\end{equation}

$E(x)$ é a \emph{translação} (de uma distância $x$) do conjunto $E$. 

\begin{description}
\item[Dúvida:] $E \subseteq (0,1]$ ou $E \in \mathscr{B}$? 
\item[Dúvida:] ``translação \emph{em} $x$'' me soa estranho, pois todo $y \in E$ é transladado
\emph{de} $x$.
\end{description}

Suponha que exista uma coisa tal como uma medida ``natural'' em $(0,1]$.  Para o
  intervalo $(a,b]$ essa medida é
\begin{equation}
\left| (a,b]\right| \equiv b - a.\label{eq:def-medida}
\end{equation}

Vamos supor, sem entrar em muitos detalhes, que para todo $B \in \mathscr{B}$,
existe uma $|B|$ compatível com (\ref{eq:def-medida}), \textit{i.e.}, redutível
a (\ref{eq:def-medida}) se $B$ for um intervalo.

A notação $E(x)$ é a usada por \cite{taylor--intro.measure.integration}. 

Agora, se $E \in \mathscr{B}$, então,

\begin{equation}
|E(x)| = |E|. \label{eq:medida-mantem-x}
\end{equation}

Agora, como sempre, $\mathbb{Q}$ é o conjunto dos racionais.  Esse conjunto é
enumerável. Consideremos os racionais contidos em $(0,1]$. Esse segundo conjunto
  é
\begin{equation}
Q \equiv \mathbb{Q} \cap (0,1].\label{eq:def-Q-em-zero-um}
\end{equation}
\needspace{2cm}

Valeria a pena provar que
\begin{quote}
Q é enumerável.
\end{quote}

Com essas definições à mão, estudemos então as propriedades dos conjuntos do
tipo $Q(x)$.

\begin{enumerate}
\item 
\begin{equation}
x \in (0,1] \Rightarrow x \in Q(x). \label{eq:x-in-Qx}
\end{equation}
Será verdade? Como provar?
\[
Q(x) = \left\{ x \boxplus y, \; y \in Q \right\}
\]
Se $0$ pertencesse a $Q$, (\ref{eq:x-in-Qx}) seria trivial. Mas é quase, porque
$1 \in Q$.  Faça $y = 1$ acima; então,
\[
x = x + 1 - 1 = x \boxplus 1 \in Q(x)\blob
\]
\item 
\begin{equation}
x \in Q \Rightarrow Q(x) = Q.\label{eq:xinQ-Qx-eq-Q}
\end{equation}
De fato: para começar, $x,y \in Q \Rightarrow x \boxplus y \in Q$. De fato, $x
\boxplus y \in (0,1]$, e tanto $x + y$ quanto $x + y -1$, conforme for o caso,
  são números racionais em $(0,1]$.  Isso basta!, pois, \emph{neste caso},
$Q(x) = \left\{ x \boxplus y, \; y \in Q \right\} = Q\blob$ 
\item
\begin{align}
x_1 - x_2 \not\in \mathbb{Q} &\Rightarrow Q(x_1) \cap Q(x_2) = \emptyset, \label{eq:irraQx1x2}\\
x_1 - x_2 \in     \mathbb{Q} &\Rightarrow Q(x_1) = Q(x_2).\label{eq:raciQx1x2}
\end{align}
Dessa forma, os conjuntos $\left\{ Q(x), \; x \in (0,1]\right\}$ (que constituem
  uma \emph{classe}, ou \emph{família}) particionam o intervalo $(0,1]$ em
    subconjuntos disjuntos cuja união é o próprio $(0,1]$.  Há bastante material
      aqui.  Antes das deduções, vamos escrever formalmente essa última
      observação:
\[
\bigcup_{x \in (0,1]} Q(x) = (0,1].
\]
Note também que os índices na expressão acima são demasiados, devido a (\ref{eq:raciQx1x2}).  Queremos chegar a
uma afirmação mais econômica:
\[
\bigsqcup_{x \in T} Q(x) = (0,1]
\]
(note a disjunção). Na sequência, precisamos provar
(\ref{eq:irraQx1x2})--(\ref{eq:raciQx1x2}) e prosseguir na obtenção do conjunto
$T$. Esse último se revelará um conjunto interessante, e na verdade o ponto
final desta lição: $T$ se revelará um conjunto \emph{não mensurável}.

Para provar (\ref{eq:irraQx1x2}): Vamos tentar \textit{reductio ad absurdum}.
Seja $z \in Q(x_1)$ e $z \in Q(x_2)$: nesse caso, a interseção $Q(x_1) \cap
Q(x_2)$ não seria o conjunto vazio.  Porém, debaixo dessa hipótese:
\begin{align*}
z &= x_1 \boxplus y, \; y \in Q, \\
z &= x_2 \boxplus y, \; y \in Q.
\end{align*}
Agora,  
\begin{align*}
( x_1 \boxplus y ) - ( x_2 \boxplus y) &= x_1 - x_2, \; \text{ou}\\
                                       &= x_1 - x_2 - 1 \; \text{ou}\\
                                       &= x_1 - x_2 + 1.
\end{align*}
Portanto, subtraindo (dessa forma) as duas expressões acima,
\[
(-1 \; \text{ou} \; 0 \; \text{ou} +1) = x_1 - x_2.
\]
mas $(-1,0,+1)$ são racionais, o que contraria a hipótese original sobre $x_1 -
x_2\blob$

Para provar (\ref{eq:raciQx1x2}): Volte acima e escreva a expressão geral:
\[
(x_1 \boxplus y) - (x_2 \boxplus y) = x_1 - x_2 + s,
\]
onde, como vimos, ou $s=0$ ou $s=-1$ ou $s=+1$. Reescreva:
\[
x_1 \boxplus y = x_2 \boxplus y + (x_1 - x_2) + s.
\]
Note agora que é \emph{sempre} possível escrever $x_2 \boxplus y = x_2 + r$
(veja (\ref{eq:box-rationals})),
\emph{onde agora $r$ é racional}, e não necessariamente está em $Q$. Substitua:
\[
x_1 \boxplus y = x_2 + r + s + (x_1 - x_2).
\]
O lado esquerdo é um número em $Q$.  Portanto, o lado direito é um número em
$Q$:
\begin{equation}
x_2 + p \in Q,\label{eq:x2p-in-Q}
\end{equation}
onde $p = (r + s + (x_1 - x_2))$ e portanto $p \in \mathbb{Q}$ (mas não
necessariamente $ p \in Q$).  Agora, utilizando (\ref{eq:box-rationals}), vemos
que é possível escrever o lado direito como $x_2 \boxplus z$, onde $z \in Q$.
Disso se segue que
\[
\left\{ x_1 \boxplus y, \; y \in Q\right\} = 
\left\{ x_2 \boxplus z, \; z \in Q\right\} 
\]
e portanto $Q(x_1) = Q(x_2)\blob$
\end{enumerate}

Relembrando:
\[
x \in Q \Rightarrow Q(x) = Q
\]
significa, por exemplo:
\[
Q(1/2) = Q(1/3) = Q(1).
\]

\[
x_1 - x_2 \in \mathbb{I} \Rightarrow Q(x_1) \cap Q(x_2) = \emptyset
\]
significa, por exemplo:
\[
Q(\sqrt{3}/2) \cap Q(3/2) = \emptyset.
\]

\[
x_1 - x_2 \in \mathbb{Q} \Rightarrow Q(x_1) = Q(x_2) 
\]
significa, por exemplo:
\[
Q(\sqrt{2}/1000 + 1/8) = Q(\sqrt{2}/1000 + 3/8)
\]

Ou seja: as criaturas estão ficando estranhas.

Para fechar esta parte bastante cansativa para a mente:
\[
\bigcup_{x \in (0,1]} Q(x) = (0,1]
\]
pois $x \in Q(x)$.

\section{O axioma da seleção e um conjunto estranho\label{sec:conj-vitali}}

Seja $\mathscr{C}$ a família dos conjuntos $Q(x)$, $x \in (0,1]$. Escolha um
  único ponto em $(0,1]$ pertencente a cada $Q(x)$.  O conjunto dos pontos assim
    escolhidos será chamado $T$, e temos que $T \subset (0,1]$. $T$ é um
      \emph{conjunto de Vitali}.  O que fizemos significa que, \emph{por
        definição}, não há dois pontos em $T$ pertencendentes ao mesmo
      $Q(x)$. Segue-se que
\[
   \bigsqcup_{t \in T} Q(t) = (0,1].
\]

Estudemos as propriedades dos conjuntos $T(r_i), r_i \in Q$.
\begin{enumerate}
\item
\begin{equation}
\bigcup_{i=1}^\infty T(r_i) = (0,1].\label{eq:union-ri}
\end{equation}
Só precisamos provar que, se $x \in (0,1]$, $\exists i \in Q : x \in
  T(r_i)$. Mas, de (\ref{eq:x-in-Qx}), segue-se que $x \in (0,1] \Rightarrow x
    \in Q(x)$. Agora, portanto, se $x \in Q(x)$, escolha $t \in Q(x)$, onde $t$
    é o representante de $Q(x)$: $t \in T$.

Veja:
\begin{align*}
Q(x) &= { x \boxplus y, \; y \in Q }, \\
t \in Q(x) &\Rightarrow t = x \boxplus y \; \text{para algum $y \in Q$}.
\end{align*}
Logo, de (\ref{eq:box-rationals}), existe algum $q \in Q$ tal que $t = x + q$; pelo mesmo motivo agora deve
existir algum $r \in Q$ tal que $x = t + r$. Mas $Q$ é enumerável (não
provamos!), portanto existe um índice $i$ tal que $x = t + r_i$, $i \in
\mathbb{N}$, e $Q = \bigsqcup_{i=1}^\infty r_i$. Logo, $x \in T(r_i)$. A união
dos $T(r_i)$ gera o $(0,1]$.
\item Os $T(r_i)$ são disjuntos. Lembre-se de que $T$ contém um único
  representante de cada $Q(x)$. Se houvesse $r_i \ne r_j$ com $y \in \left[ T(r_i) \cap
  T(r_j)\right]$, então teríamos
\begin{align*}
y &= t_i \boxplus r_i \qquad \text{e}\\
y &= t_j \boxplus r_j.
\end{align*}
``Subtraia'':
\[
0 = (t_i - t_j) + q
\]
onde $q$ é racional (novamente, nós usamos (\ref{eq:box-rationals})). Logo, $t_i
- t_j$ é racional, donde $Q(t_i) = Q(t_j)$ (devido a (\ref{eq:raciQx1x2})).  Mas
isso não é possível, porque $Q(t_i)$ possui um único representante em
$T$. Portanto, a disjunção dos $T(r_i)$'s transforma (\ref{eq:union-ri}) em
\begin{equation}
\bigsqcup_{i=1}^\infty T(r_i) = (0,1].\label{eq:union-disjoint-ri}
\end{equation}
\end{enumerate}
Finalmente: se $T$ fosse mensurável, haveria $|T| = |T(r_i)|$ para todo $i$.
Agora, pela sigma-aditividade:
\[
\sum_{i=1}^\infty |T(r_i)| = |(0,1]| = 1.
\]
Isso, nós também já vimos em outra lição, é impossível. $T$ não pode ser mensurável\blob


\chapter{2014-03-12, 2014-03-17: Teoria de probabilidade e incursões na física e
  em geociências}\label{chap:teoprob}




\section{Variável aleatória}\label{sec:random-var}

\textbf{Este início de seção foi escrito por mim, anteriormente.  Entretanto,
  ele se parece bastante com a exposição da Ailin em 2014-03-17.  Seria bom
  portanto unificar as duas aqui.  Aceito sugestões.}


Em uma visão moderna de probabilidades e estatística, inventada por Kolmogorov, nós
precisamos de:
\begin{enumerate}
   \item um conjunto $\Omega$ --- responsável por ``sorteios'', denominado \emph{Espaço
   Amostral};
   \item Uma função
   \begin{align*}
      X: \Omega &\rightarrow \mathbb{R} \\
	 \omega \in \Omega &\mapsto x = X(\omega)
   \end{align*}
   A função $X$ é denominada ``variável aleatória''.  A função $X$ tem que ser
   \emph{mensurável}, e nós vamos gastar algum tempo com isso ainda mais à frente.
   \item Uma função 
   \begin{align*}
      P:\mathscr{F} &\rightarrow [0,1]\\
      A \in \mathscr{F} &\mapsto P(A)
   \end{align*}
\end{enumerate}

O conjunto $\mathscr{F}$ é uma \emph{classe} (um conjunto de conjuntos).  Como
vimos no capítulo \ref{chap:sigma-add}, $\mathscr{F}$ é uma $\sigma$-álgebra.
Cada \emph{elemento} de $\mathscr{F}$ é um sub-conjunto mensurável $A \in
\Omega$, ao qual nós associamos um número $P(A)$.  Os elementos de $\mathscr{F}$
gozam de algumas propriedades importantes em teoria de probabilidades:
\begin{align}
   A \in \mathscr{F} &\then \overline{A} \in \mathscr{F}\\
   A,B \in \mathscr{F} &\then A \cup B \in \mathscr{F}\\
   A,B \in \mathscr{F} &\then A \cap B \in \mathscr{F}\\
   \emptyset	       &\in \mathscr{F}\\
   \Omega	       &\in \mathscr{F}
\end{align}
Nós podemos reconhecer nestas propriedades, imediatamente, que os sub-conjuntos $A \in \Omega$
são \emph{eventos}.  A função $P$ associa a cada evento uma \emph{probabilidade}.  A função $P$
também deve obedecer a algumas regras. Se $A_1, \ldots, A_n$ são conjuntos \emph{disjuntos},
$A_i \cap A_j = \emptyset, \; i\ne j$, então
\begin{align}
   P(A_i) &\ge 0\\
   P(\Omega) &= 1\\
   P(A_i \cup A_j) &= P(A_i) + P(A_j)
\end{align}
Esta última é um caso particular da $\sigma$-aditividade:
\begin{equation}
P\left(\bigsqcup_{i=1}^\infty A_i\right) = \sum_{i=1}^\infty A_i. 
\end{equation}
É muito importante enfatizar que o espaço amostral é um conceito \emph{abstrato}: ele ajuda a
conceituar probabilidades e também ajuda a demonstrar alguns resultados, mas na prática tudo o
que vemos no mundo ``real'', ou seja, os únicos objetos que podemos manipular em aplicações de
teoria de probabilidade, são as \emph{realizações} da variável aleatória: $x = X(\omega)$.


Para avaliar a probabilidade de ocorrência de certos níveis de uma variável aleatória nós usamos
eventos do tipo $X(\omega) \le x$, que pode ser entendido com o auxílio da figura
\ref{fig:Xlessthanx}.

\begin{figure}\label{fig:Xlessthanx}\centering
   \resizebox{0.5\textwidth}{!}{\includegraphics{Xlessthanx}}
   \caption{Representação gráfica do evento $X(\omega) \le x$}
\end{figure}
 
Diferentes maneiras de escrever o evento $A$ são:
\begin{align*}
    A &= \left\{ \omega \mathrel{|} X(\omega) \le x \right\},\\
    A &= \left\{ X(\omega) \le x \right\},\\
    A &= \left\{ X \le \omega \right\}.
\end{align*}
Note que na última forma desapareceu qualquer referência explícita ao espaço
amostral.



\section{A conveniência  de definir funções de $\Omega$ em $\mathbb{R}$.}

Em princípio, para cada pergunta que nós podemos formular sobre eventos e
probabilidades, é possível construir um espaço amostral $\Omega$ ``sob medida''
para respondê-la. Junto com esse espaço, é possível, também em princípio,
definir uma medida de probabilidade adequada.  Nesse caso, tudo o que é
necessário, sempre, é a formulação de uma tripla de probabilidade
$(\Omega,\mathscr{F},P)$ que nos permita medir a probabilidade dos eventos $A$
de nosso interesse.

Entretanto, isso não é \emph{prático}. O motivo é que, \emph{sempre}, as
perguntas que podemos formular a partir de uma dada tripla
$(\Omega,\mathscr{F},P)$ inicial, podem ser expressas em termos de
\emph{funções} cujo domínio é $\Omega$. Rapidamente, portanto, nós nos deparamos
com a conveniência, e quase que com a imposição, da definição de funções de
$\Omega$ em $\mathbb{R}$.  Tais funções são denominadas \emph{variáveis
  aleatórias}.

Considere, por exemplo, o lançamento de $n$ moedas do exemplo
\ref{exe:n-moedas}. Se ``cara'' significa $x_i = 0$ e ``coroa'' significa $x_i
= 1$, a pergunta: ``qual é o número de coroas obtidas em $n$ lançamentos?'' pode ser
respondida com o auxílio da função 
\begin{align*}
X : \Omega &\Rightarrow \mathbb{R}, \\
    \omega = (x_1, \ldots, x_n) &\mapsto \sum_{i=1}^n x_i.
\end{align*}
Neste exemplo, $X$ é uma função. A imagem de $X$ é $\text{Im} X = \left\{ 0, 1, \ldots, n\right\} \subset \mathbb{R}.$
$X$ não é sobrejetiva.

Perguntas similares podem ser respondidas com outras funções, sem que seja
necessário redefinir uma nova tripla $(\Omega,\mathscr{F},P)$ para cada
pergunta!  Por exemplo, se desejarmos calcular probabilidades associadas ao
número de caras obtidas em $n$ lançamentos, podemos usar:
\begin{align*}
X : \Omega &\Rightarrow \mathbb{R}, \\
    \omega = (x_1, \ldots, x_n) &\mapsto n - \sum_{i=1}^n x_i.
\end{align*}
Ou ainda poderíamos estar interessados no número médio de coroas em $n$
lançamentos (ou ainda no limite dessa quantidade quando $n\to\infty$), quando
então poderíamos usar a função
\begin{align*}
X : \Omega &\rightarrow \mathbb{R}, \\
    \omega = (x_1, \ldots, x_n) &\mapsto \frac{1}{n}\left[\sum_{i=1}^n x_i\right].
\end{align*}

Esses breves exemplos sugerem que é \emph{econômico} e \emph{útil} trabalhar com
funções definidas em $\Omega$, em vez de reformular, do zero, um novo $\Omega$
para cada pergunta relevante que possamos ter sobre eventos relacionados com o
$\Omega$ original. Sob esse ponto de vista, variáveis aleatórias não são, em
absoluto, uma necessidade. Elas são apenas uma forma cômoda de responder
perguntas sobre probabilidades.


A conveniência de trabalhar com variáveis aleatórias, entretanto, cria um novo
conjunto de ``problemas'' técnicos que agora precisam ser resolvidos. Grosso
modo, a questão é a seguinte:
\begin{quote}
Como é que o contradomínio $\mathbb{R}$ ``percebe'' a tripla de probabilidade $(\Omega,\mathscr{F},P)$?
\end{quote}

Sucede que o que faz sentido é calcular probabilidades dos subconjuntos de
$\mathbb{R}$ pertencentes à classe $\mathscr{B}$, onde $\mathscr{B}$ é a
$\sigma$-álgebra de Borel. 

Lembremo-nos de que $\mathscr{B}$ é a menor $\sigma$-álgebra que contém os
intervalos $(a,b]$, $a,b \in \mathbb{R}$, os intervalos $(-\infty,b]$,
    $(a,+\infty)$, e também os intervalos $[a,b]$, $(a,b)$, $[a,b)$ e suas
      uniões e interseções, e todos os conjuntos abertos e fechados.

\textbf{Não sei o que os conjuntos abertos e fechados estão fazendo aqui.  Seria
  bom explicar sua relação com os intervalos.}


Precisamos, portanto, ``ligar'', de alguma forma, $\mathscr{B}$ a $\mathscr{F}$,
onde esta última é a $\sigma$-álgebra da tripla de probabilidade ``original''. No fim, o
que vai funcionar é o seguinte: para qualquer $B \in \mathscr{B}$, vamos definir
a probabilidade de conjuntos mensuráveis em $\mathscr{B}$ como
\begin{equation}
\mathcal{P}(B) \equiv P\bigl(X^{-1}(B)\bigr).\label{eq:P-in-borel}
\end{equation}
É claro que é preciso ``garantir'' que $X^{-1}(B) \in \mathscr{F}$. Pode-se
mostrar que uma condição suficiente para isso é que 
\begin{equation}
X^{-1}\bigl( (-\infty,b]\bigr) \in \mathscr{F}.  \label{eq:X-mensuravel}
\end{equation}
\textbf{Seria bom enunciar o resultado na forma de um teorema, mesmo que sem demonstração.}
Dizemos que, se $X$ atende (\ref{eq:X-mensuravel}), $X$ é uma função
\emph{mensurável}. Portanto,


\begin{Def}
Dada uma tripla de probabilidade $(\Omega, \mathscr{F}, P)$, uma \emph{variável aleatória} é uma função
\begin{align*}
   X : \Omega &\rightarrow \mathbb{R}, \\
\omega        &\mapsto x = X(\omega),
\end{align*}
tal que 
\[
\forall b \in \mathbb{R}, \; X^{-1}\bigl((-\infty,b]\bigr) \in \mathscr{F}.
\]
\end{Def}

É interessante observar que definição de mensurabilidade de uma função é feita
em termos da relação (não necessariamente uma função) \emph{inversa} $X^{-1}$. 
O motivo é técnico: uniões, interseções e complementos \emph{arbitrários} de
conjuntos $B \in \mathscr{B}$ \emph{permanecem em $\mathscr{B}$}. Da mesma
forma, é preciso garantir que as pré-imagens dessas uniões, interseções e
complementos \emph{permaneçam em $\mathscr{F}$}. Dadas as propriedades de
fechamento de qualquer $\sigma$-álgebra sob essas operações, essa garantia é dada
pelas propriedades sempre válidas (dada uma função $X$ qualquer, não
necessariamente mensurável --- isso é outra parte de nossos requisitos!):
\begin{align}
X^{-1}\left(A \cup B\right) &= X^{-1}(A) \cup X^{-1}\left(B\right), \label{eq:permanencia-uniao}\\
X^{-1}\left(A \cap B\right) &= X^{-1}(A) \cap X^{-1}\left(B\right), \label{eq:permanencia-intersecao}\\
X^{-1}\left(\overline{A}\right) &= \overline{X^{-1}\left(A\right)}. \label{eq:permanencia-complemento}
\end{align}

\textbf{2014-03-28T10:07:30 --- aceito agradecidamente verificações se a prova abaixo está certa} Por exemplo:
\begin{align*}
X^{-1}(A \cap B) &= \left\{ \omega: X(\omega) \in A \cap B \right\}\\
                 &= \left\{ \omega: \left[ X(\omega) \in A \right] \wedge \left[ X(\omega) \in B \right] \right\}\\
                 &= \left\{ \omega: X(\omega) \in A \right\} \cap \left\{ \omega: X(\omega) \in B \right\} \\
                 &= X^{-1}(A) \cap X^{-1}(B)\blob
\end{align*}

As duas primeiras relações podem ser estendidas para uniões e
interseções arbitrárias (não necessariamente enumeráveis, embora isso
baste para nossas sigma-álgebras):
\begin{align*}
X^{-1}\left(\bigcup_{\lambda \in \Lambda} A_\lambda\right) &= \bigcup_{\lambda  \in \Lambda} X^{-1}(A_\lambda), \\
X^{-1}\left(\bigcap_{\lambda \in \Lambda} A_\lambda\right) &= \bigcap_{\lambda  \in \Lambda} X^{-1}(A_\lambda).
\end{align*}
A necessidade de definir mensurabilidade usando $X^{-1}$ decorre do
fato de que \emph{é falso que}:
\begin{align*}
X\left(A \cap B\right) &= X(A) \cap X\left(B\right), \\
X\left(\overline{A}\right) &= \overline{X\left(A\right)}. \\
\end{align*}
Para isso, bastam dois contra-exemplos.
\begin{Exe}
Sejam $A = (-\infty,0)$ e $B=[0,+\infty)$.  Então, $\overline{A} = B$
  e $\overline{B} = A$.  Dada a função
\begin{align*}
   f: \mathbb{R} &\rightarrow \mathbb{R}, \\
               x &\mapsto 1,
\end{align*}
Temos:
\[
A \cap B = \emptyset, \qquad f(A) = f(B) = \{ 1\},
\]
e
\[
f(A) \cap f(B) = \{ 1\} \ne \emptyset = f(A \cap B).
\]

\skipend

\end{Exe}
\begin{Exe}
Sejam $A = (-\infty,0)$ e $B=[0,+\infty)$.  Então, $\overline{A} = B$
  e $\overline{B} = A$.  Dada a função
\begin{align*}
   f: \mathbb{R} &\rightarrow \mathbb{R}, \\
               x &\mapsto x^2,
\end{align*}
Temos: 
\[
f(\overline{A}) = f(B) = [0,\infty) = B \ne [0,-\infty) = \overline{f(A)}.
\]

\skipend

\end{Exe}


Uma função mensurável em $\Omega$ tem o papel de transferir a estrutura
$(\Omega,\mathscr{F},P)$ para uma tripla equivalente
$(\mathbb{R},\mathscr{B},\mathcal{P})$. A probabilidade de sub-conjuntos de
$\mathbb{R}$ que ``fazem sentido'' está bem definida por (\ref{eq:P-in-borel})
(na verdade, nos sub-conjuntos que pertencem a $\mathscr{B}$ (a sigma-álgebra de
Borel) e também possivelmente mais alguns, que pertencem a $\mathscr{L}$ (a
sigma-álgebra de Lebesgue) --- mas a diferença entre ambos consiste em conjuntos
de medida zero).
Seguem-se
\begin{align*}
\mathcal{P}(\mathbb{R}) &= 1, \\
0 &\le \mathcal{P}(B) \le 1, \\
\mathcal{P}\left[ \bigsqcup_{i=1}^\infty B_i\right] &= \sum_{i=1}^\infty \mathcal{P}(B_i)\qquad\text{$\sigma$-aditividade}
\end{align*}

Cabe observar que nem toda função de $\Omega$ em $\mathbb{R}$ é uma variável
aleatória.
Considere por exemplo a função
\begin{align*}
\mathbbm{1}_{\overline{T}} : (0,1] &\rightarrow \mathbb{R}, \\
                             \omega &\mapsto \begin{cases} 1, & \omega \in
                               \overline{T}\cap(0,1], \\
                               0, & \omega \in T.\end{cases}
\end{align*}
onde $T$ é o conjunto de Vitali definido na seção \ref{sec:conj-vitali}. Sabemos
que $T$ é não-mensurável: $T \not\in \mathscr{F}$.  Segue-se que a função
$\mathbbm{1}_{\overline{T}}$ não é mensurável:
\begin{align*}
\mathbbm{1}_{\overline{T}}^{-1}\bigl( \left(-\infty,1/2\right]\bigr)
   &= \bigl\{ \omega \in (0,1] : \mathbbm{1}_{\overline{T}}(\omega) \in \left(-\infty,1/2\right]\bigr\}\\
   &= \bigl\{ \omega: \mathbbm{1}_{\overline{T}}(\omega) = 0\bigr\}\\
   &= T \not\in\mathscr{F}\blob
\end{align*}

\section{2014-03-19: Propriedades de variáveis aleatórias\label{sec:propva}}

Exemplos de variáveis aleatórias construídas a partir de outras:
\begin{enumerate}
\item Se $A \in \mathscr{F}$,
\begin{align*}
\mathbbm{1}_{A} : \Omega &\rightarrow \mathbb{R}, \\
                             \omega &\mapsto \begin{cases} 1, & \omega \in A, \\
                               0, & \omega \not\in A.
                               \end{cases}
\end{align*}
é uma variável aleatória em $(\Omega,\mathscr{F},P)$.
\item Se $X$,$Y$ são duas variáveis aleatórias em $(\Omega,\mathscr{F},P)$, então
      \begin{enumerate}[a)]
         \item $X + Y$ é uma variável aleatória;
         \item $cX$ é uma variável aleatória;
         \item $X + c$ é uma variável aleatória;
         \item $X^2$ é uma variável aleatória;
         \item $XY$ é uma variável aleatória.
      \end{enumerate}
\item Se $(X_1, X_2, \ldots, X_n, \ldots)$ é uma sequência de variáveis aleatórias e $\lim_{x\to\infty}X_n(\omega)$ existe para cada $\omega$, então:
\begin{align*}
   X : \Omega &\rightarrow \mathbb{R}, \\
       \omega &\mapsto \lim_{n\to\infty} X_n(\omega)
\end{align*}
satisfaz 
\[
X^{-1}\bigl( (-\infty,b]\bigr) \in \mathscr{F}.
\]
A prova é complicada!  Ela se baseia no seguinte fato
(Rosenthal \textbf{2014-03-25T09:44:36 --- Precisamos da referência completa}):
\begin{equation}
X^{-1}\bigl( (-\infty,b]\bigr) = 
\bigcap_{m=1}^\infty \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty X_k^{-1}\left(-\infty, x + \frac{1}{m}\right].\label{eq:mnk-capcupcap}
\end{equation}
\item $\max(X,Y)$, $\min(X,Y)$ e $|X|$ são variáveis aleatórias.
Notando que
\begin{align*}
\max(X,Y) &= \frac{1}{2}\left[ X + Y + |X-Y|\right], \\
\min(X,Y) &= (X+Y) - \max(X,Y), 
\end{align*}
basta provar para o $|X|$.
\item $\sup_n X_n$, $\inf_n X_n$ são variáveis aleatórias, desde que bem definidos. Vale lembrar que
\[
\sup_{n\in\mathbb{N}} r_n = 
\begin{cases}
\min\left\{ r: r_n \le r, \forall n \in \mathbb{N}\right\}, \\
+\infty, & \text{se a sequência não for limitada}.
\end{cases}
\]
\item $\limsup_n X_n$ e $\liminf_n X_n$ são variáveis aleatórias. 

Forme:
\[
Y_n \equiv \sup_{N\ge n} X_N. \qquad \text{\textbf{Confirmar índices!!!}}
\]
Note que $Y_n(\omega)$ é uma função monótona (não-crescente) de $n$, para cada $\omega$. Portanto,
\[
\exists \lim_{n\to\infty} Y_n \equiv \limsup_{n\to\infty} X_n.
\]

Forme:
\[
Z_n \equiv \inf_{N\ge n} X_N. \qquad \text{\textbf{Confirmar índices!!!}}
\]
Note que $Z_n(\omega)$ é uma função monótona (não-decrescente) de $n$, para cada $\omega$. Portanto,
\[
\exists \lim_{n\to\infty} Z_n \equiv \liminf_{n\to\infty} X_n.
\]

\item Seja $X: \Omega \rightarrow \mathbb{R}$ uma variável
  aleatória, tal que os abertos de $\Omega$ estão em $\mathscr{F}$, ou seja, $\mathscr{F}$ é a $\sigma$-álgebra de Borel
  de $\Omega$ ou seu completamento. Então:
   \begin{enumerate}[a)]
      \item Se $f: \mathbb{R} \to \mathbb{R}$ for contínua, $f \circ X : \Omega
        \to \mathbb{R}$ é uma variável aleatória
   \end{enumerate}
\item Se:
\begin{align*}
X : (\Omega,\mathscr{F},P) &\rightarrow (\mathbb{R},\mathscr{B},\mathcal{P}),\\
\omega &\mapsto x = X(\omega),
\end{align*}
e
\begin{align*}
f: (\mathbb{R},\mathscr{B},|\cdot|) &\rightarrow
(\mathbb{R},\mathscr{B},|\cdot|),\\
x &\mapsto y = f(x)
\end{align*}
(ou seja: $f$ é mensurável), então $f\circ X$ é uma variável aleatória.

\end{enumerate}

Finalmente, temos uma anotação um pouco solta que precisa ser esclarecida:
$B \in \mathscr{B}$, $|B|=0$, $D \subset B$, $D$ não necessariamente em
$\mathscr{B}$, $D\in\mathscr{L}$, a qual é a $\sigma$-álgebra de Lebesgue, que é
o completamento, por $|\cdot|$, da $\sigma$-álgebra de Borel.

\textbf{Como a prova de 2014-03-24 foi muito longa, não vou colocá-la dentro da lista
acima, mas depois.}

\subsection*{Um resultado auxiliar}

\begin{Def}
Se a sequência $X_k(\omega)$ converge para todo $\omega$, então, pela definição
de limite, $X_k(\omega) \to X(\omega)$ se, para todo $\epsilon = 1/m$, $\exists
K(m,\omega)$ tal que:
\begin{equation}
\bigl\vert X_k(\omega) - X(\omega)\bigr\vert < \frac{1}{m},\qquad \forall k \ge K(m,\omega).\label{eq:xk-conv}
\end{equation}
\end{Def}

\subsection*{Ante-sala da prova}

Vamos agora provar (\ref{eq:mnk-capcupcap}).
Comece observando que
\begin{align*}
\omega \in \bigcap_{m=1}^\infty \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty
X_k^{-1}\left(-\infty,b+\frac{1}{m}\right] &\Leftrightarrow \forall m \in
  \mathbb{N},\\
&\phantom{\Leftrightarrow} \omega \in \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty
X_k^{-1}\left(-\infty,b+\frac{1}{m}\right], \\
&\Leftrightarrow \forall m \in \mathbb{N}, \;\exists N(m,\omega) : \\
&\phantom{\Leftrightarrow} \omega \in \bigcap_{k=N(m,\omega)}^\infty
  X_k^{-1}\left(-\infty,b+\frac{1}{m}\right], \\
&\Leftrightarrow \forall m \in \mathbb{N}, \;\exists N(m,\omega) :\\
&\phantom{\Leftrightarrow}  X_k(\omega) \le b + \frac{1}{m}, \; \forall k \ge N(m,\omega).
\end{align*}
É bom parar um pouco e observar que tudo isso aí em cima \emph{ainda é o lado
  direito} de (\ref{eq:mnk-capcupcap})! Em outras palavras,
\begin{multline*}
\bigcap_{m=1}^\infty \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty
X_k^{-1}\left(-\infty,b+\frac{1}{m}\right] 
=\\
\left\{
\omega: \forall m \in \mathbb{N}, \;\exists N(m,\omega) :
X_k(\omega) \le b + \frac{1}{m}, \; \forall k \ge N(m,\omega)
\right\}.
\end{multline*}

\textbf{Eu gostaria de escrever essa última afirmativa com único ``tal que''
  ($:$), em vez de dois.}

Novamente, (\ref{eq:mnk-capcupcap}) é da forma
\[
D = E
\]
onde $D$ e $E$ são conjuntos.  A prova usual da igualdade de dois conjuntos
segue a lógica:
\begin{align*}
\left( \omega \in D \Rightarrow \omega \in E\right) &\Rightarrow D \subseteq E, \\
\left(\omega \in E \Rightarrow \omega \in D\right)  &\Rightarrow  E \subseteq D,
\end{align*}
e portanto $D = E$.


\subsection*{Prova}

Somente agora nós vamos realmente provar a primeira linha de implicaturas acima:
\[
\omega \in X^{-1}(-\infty,b] \Leftrightarrow X(\omega) \le b.
\]
Usando a equação (\ref{eq:xk-conv}), $\forall m \in \mathbb{N}, \exists
K(m,\omega)$:
\[
\bigl\vert X_k(\omega) - X(\omega)\bigr\vert < \frac{1}{m}, \forall k \ge
K(m,\omega).
\]
Em particular,
\[
X_k(\omega) < \frac{1}{m} + X(\omega) \le \frac{1}{m} + b,
\]
donde
\[
X^{-1}(-\infty,b] \subseteq \bigcap_{m=1}^\infty \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty
X_k^{-1}\left(-\infty,b+\frac{1}{m}\right].
\]

\textbf{OK, mas até aqui eu ainda acho que devíamos ter usado $N(m,\omega) = K(m,\omega)$ (um único símbolo) na prova.}

A ``segunda linha'' que precisa ser provada, ainda, é:
\begin{equation}
\omega \in \bigcap_{m=1}^\infty \bigcup_{n=1}^\infty \bigcap_{k=n}^\infty
X_k^{-1}\left(-\infty,b+\frac{1}{m}\right] \Rightarrow \omega \in X^{-1}(-\infty,b].\label{eq:segunda-linha}
\end{equation}
Já sabemos que o lado esquerdo acima significa que, $\forall m \in\mathbb{N}, \exists K(m,\omega)$:
\begin{equation}
X_k(m) \le b + \frac{1}{m}, \forall k \ge K(m,\omega). \label{eq:vai-contradizer}
\end{equation}
Por outro lado, suponha, por \textit{reductio ad absurdum}, que
$X(\omega) > b$, e faça $d = X(\omega) - b$. Mas $X(\omega)$ é o limite de uma
sequência, e portanto a partir de algum $k \ge N(\epsilon,\omega)$ \textbf{(preciso de ajuda para arrumar $N(m,\omega)$
  e $K(m,\omega)$)}
devemos ter
\[
X(\omega) - \epsilon < X_k(\omega) < X(\omega) + \epsilon.
\]
Escolha
\[
\epsilon = \frac{1}{m} < \frac{d}{2} \Leftrightarrow \frac{2}{m} < d;
\]
então,
\begin{align}
X(\omega) - \epsilon &< X_k(\omega),\nonumber\\
X(\omega) - b + \left( b - \frac{1}{m}\right) &< X_k(\omega), \nonumber\\
d + \left( b - \frac{1}{m}\right) &< X_k(\omega), \nonumber\\
\frac{2}{m} + \left( b - \frac{1}{m}\right) &< d + \left( b - \frac{1}{m}\right) < X_k(\omega),\nonumber\\
b + \frac{1}{m} &< X_k(\omega).\label{eq:contradisse}
\end{align}
Mas (\ref{eq:vai-contradizer}) e (\ref{eq:contradisse}) são contraditórios (um absurdo): a hipótese $X(\omega) > b$
levou a um absurdo, e portanto temos, como desejávamos
(\ref{eq:segunda-linha})\blob

\section{2014-03-28T09:49:31 revisão, e a FDA}

Tínhamos
\begin{align*} 
X : (\Omega,\mathscr{F}) &\rightarrow (\mathbb{R},\mathscr{B}), \\
         \omega          &\mapsto       X(\omega),
\end{align*}
de tal forma que $X^{-1}(-\infty,b] \in \Omega$, o que equivale a $X^{-1}(B) \in
  \mathscr{F}, \; \forall B \in \mathscr{B}$. Podemos agora definir:
\begin{align*}
\mathcal{P}(B) &= P\left(\underbrace{X^{-1}(B)}_{\in \mathscr{F}}\right)\\
\mathcal{P}(B) &\ge 0,\\
\mathcal{P}(\emptyset) &= 0,\\
\mathcal{P}(\mathbb{R}) &= P\left(X^{-1}(\mathbb{R})\right) = P(\Omega) = 1, \\
\mathcal{P}\left( \bigsqcup_{i=1}^\infty B_i\right) &= P\left(X^{-1}\left(\bigsqcup_{i=1}^\infty B_i\right)\right)\\
&= P\left(\bigsqcup_{i=1}^\infty X^{-1}(B_i)\right)\\
&= \bigsqcup_{i=1}^\infty P\left(X^{-1}(B)\right)\\
&= \sum_{i=1}^\infty \mathcal{P}(B_i).
\end{align*}
Portanto, vale a $\sigma$-aditividade.

Observe que se os $B_i$'s são disjuntos em $\mathscr{B}$, suas pré-imagens são disjuntas em $\mathscr{F}$ (ver (\ref{eq:permanencia-intersecao}):
\begin{align*}
X^{-1}(B_i) \cap X^{-1}(B_j) &= X^{-1}\left(B_i \cap B_j\right) \\
                                              &= \emptyset\blob
\end{align*}

$\mathcal{P}$ é uma nova medida de probabilidade. Temos uma nova
tripla, $(\mathbb{R},\mathscr{B},\mathcal{P})$, \emph{diferente} de
$(\mathbb{R}, \mathcal{B}, |\cdot|)$, onde $|\cdot|$ indica a medida
de Lebesgue. \textbf{2014-03-28T10:34:14 dúvida: nesta última tripla
  devemos ter: $\mathscr{B}$ ou $\mathscr{L}$?}

Mudemos agora de notação: os valores de $\mathcal{P}(-\infty,x]$
  determinam as probabilidades em todos os conjuntos restantes de
  $\mathscr{B}$. De fato, note que
\[
\mathcal{P}\bigl( (a,b]\bigr) = \mathcal{P}\bigl((-\infty,b]\bigr) -
    \mathcal{P}\bigl((-\infty,a]\bigr)
\]
trivialmente (por aditividade finita). A partir de agora, basta gerar
novos conjuntos $B$ a partir dos intervalos $(a,b]$ usando a estrutura
  de semi-anel. \textbf{2014-03-28T10:37:42 eu acho que isso poderia
    ser melhor dito}

Defina agora a FDA:
\[
F_X(x) \equiv \mathcal{P}\bigl((-\infty,x]\bigr).
\]
Temos que 
\begin{align*}
F_X : \mathbb{R} &\rightarrow \mathbb{R}, \\
             x   &\mapsto \mathcal{P}\bigl((-\infty,x]\bigr) \in
               [0,1], \forall x \in \mathbb{R}.\\
F_X(x) &\ge 0, 
\end{align*}
$F_X(x)$ é monótona não-decrescente.

\begin{Exe}\label{exe:dist-binom}
A distribuição binomial é
\[
P(X = k) = \binom{n}{k}\left(\frac{1}{2}\right)^k.
\]
Um espaço amostral possível é o conjunto das ($2^n$) enuplas
$(\omega_1, \ldots, \omega_n)$, com $\omega_i = 1$ ou $\omega_i = 0$.
A variável aleatória associada à distribuição Bernoulli neste caso
será 
\begin{align*}
X : \{ 0,1\} \times \ldots \times \{ 0, 1\} &\rightarrow \mathbb{R},\\
\omega = (\omega_1, \ldots, \omega_n) &\mapsto X(\omega) =
\sum_{i=1}^n \omega_i.
\end{align*}
A figura \ref{fig:fdafact} mostra a $F_X(x)$ para $n=6$.

\skipend
\end{Exe}

\begin{figure}\centering
\includegraphics[width=0.8\textwidth]{fdafact}
\caption{Função distribuição acumulada da distribuição binomial, $n=6$.\label{fig:fdafact}}
\end{figure}

São propriedades da FDA:
\begin{enumerate}
\item $F_X(x)$ é monótona não-decrescente.
\item 
\[
\lim_{x \to -\infty} F_X(x) = 0.
\]
\item 
\[
\lim_{x \to +\infty} F_X(x) = 1.
\]
\end{enumerate}
Reciprocamente, se uma função $F_X(x)$ possui as propriedades acima,
então $F_X(x)$ é a FDA de \emph{alguma} variável aleatória. Assim, 
\begin{quote}
Qualquer função $F(x)$ com as propriedades acima define uma medida de
probabilidade $\mathcal{P}$ em $(\mathbb{R},\mathscr{B})$
\end{quote}

\begin{Exe}
Se $\Omega = \{\omega_0, \omega_1, \ldots, \}$ é um conjunto
enumerável e cada evento $\{\omega_i\}$ é um átomo de $\Omega$ com
$P\{\omega_i\} = p_i$, então
\[
F_X(x) = \sum_{X(\omega_i)\le x} p_i,
\]
pois 
\[
X^{-1}(-\infty,x] = \{ \omega_i : X(\omega_i) \le x\}.
\]
\skipend
\end{Exe}

\begin{Def} \textbf{Mas isto é mesmo uma definição???}
A tripla $(\mathbb{R}, \mathscr{B}, \mathcal{P})$ é absolutamente
contínua em relação a $(\mathbb{R},\mathscr{B},|\cdot|)$ quando
\[
|B| = 0 \Rightarrow \mathcal{P}(B) = 0, \; \forall B \in \mathscr{B}.
\]
\end{Def}

\begin{Exe} Se $f: \mathbb{R} \rightarrow \mathbb{R}_+$ for integrável segundo
  Lebesgue, e 
\[
   \int_{\mathbb{R}} f(x)\,\md_L{x} = 1,
\]
então
\[
\mathcal{P}(B) = \int_B f(x)\,\md_L{x} =
                 \int_\mathbb{R} \mathbb{1}_B(x)f(x)\,\md_L{x}
\]
é uma medida de probabilidade, com 
\[
F_x(x) = \int_{\infty}^x f(x)\,\md_L{x},
\]
e
\[
F_x(b) - F_X(a) = \int_a^b f(x)\,\md_L{x}.
\]
\textbf{2014-03-30T09:04:06 Por que precisamos escrever explicitamente essa
  última equação?}.

$f(x)$ é a \emph{função densidade de probabilidade}.

\end{Exe}

\begin{Teo}\label{teo:descont-enum}
Seja $F_X(x)$ a FDA da variável aleatória $X$.  O conjunto de descontinuidades
de $F_X(x)$ é enumerável (ou finito). As descontinuidades são de tipo ``salto''.
\end{Teo}
\textbf{Ver seção 2.3 de Bartle --- precisamos da referência bibliográfica
  completa!}

Seja agora $\{ x_1, \ldots, x_n, \ldots \} \subset \mathbb{R}$ o conjunto das
descontinuidades. Definimos, em cada um desses pontos,
\[
p_i \equiv F_X(x_i) - F_X({x_i}_{-})
\]
Definimos agora uma função cuja aparência é similar à que obtivemos no exemplo
\ref{exe:dist-binom}, ilustrada na figura \ref{fig:fdafact}:
\[
F_d(x) \equiv \sum_{i: x_i \le x} p_i.
\]

É importante entendermos o que se está fazendo aqui.  Estamos ``construindo'' a
parte não-contínua da FDA. Qualquer variável aleatória possui uma FDA que pode
ser decomposta em 3 componentes.  A parte descontínua é uma delas.  O teorema
(\ref{teo:descont-enum}) e a definição acima provêem a definição da parte
descontínua. 

Continuando, o que dizer sobre a parte contínua?  Temos o seguinte fato
\textbf{(Um outro teorema??  Creio que sim)}

Toda função monótona possui derivada em quase todos os pontos (existe a derivada
exceto em um subconjunto de medida nula, segundo Lebesgue). Podemos portanto,
dada uma $F$ com tais características, definir sua FDP:
\[
f(x) = \begin{cases} F'(x), & \text{onde ela existe},\\
         0, & \text{nos demais pontos}
\end{cases}
\]

Curiosamente (e estranhamente para mim!), isso não é tudo.   De fato, se
definirmos
\[
F_{ac}(x) \equiv \int_{-\infty}^x f(x)\,\md{x}
\]
ainda sobra a ``parte singular'', que definimos:
\[
F_S(x) \equiv F_X(x) - F_d(x) - F_{ac}(x).
\]

O final da aula me deixou em dúvida: por que fazemos o seguinte?

\begin{description}
\item[Teste discreto] $\exists$ um subconjunto enumerável com probabilidade 1
  \textbf{(???)}
\item[Teste contínuo] 
\[
|B| = 0 \Rightarrow \mathcal{P}(B) = 0.
\]
\textbf{(???)}
\item[Teste singular] $\mathcal{P}$ é singular em relação a $|\cdot|$ se existe
$B_0 \in \mathscr{B}$, $|B_0| =0$, mas com 
$\mathcal{P}(B) = \mathcal{P}(B \cap B_0)$, 
$\mathcal{P}(B_0) = 1$.
\end{description}

\textbf{2014-03-30T09:21:14 Vá agora para o final do arquivo, onde eu preparei a
aula de 2014-03-31}

\section{A FDA}

Nós agora vamos definir a função distribuição acumulada (FDA) de probabilidade de uma variável
aleatória $X$:
\begin{equation}
   F_X(x) \equiv P(\{ X \le x\}).\label{eq:def-fda}
\end{equation}
A notação da equação \eqref{eq:def-fda} é normalmente simplificada para $F_X(x) \equiv P\{X \le
x\}$. A FDA nos permite calcular facilmente probabilidade relacionadas a $X$.  Por exemplo,
para obter a probabilidade de que $X$ ocorra em um intervalo $[a,b]$:
\begin{align}
   P\{ a \le X \le b \} &= P\{ X \le b\} - P\{ X \le a\}\\
		        &= F(b) - F(a).
\end{align}
As propriedades da função distribuição acumulada são:
\begin{align}
   F(-\infty) &= 0,\\
   F(+\infty) &= 1,\\
F(b) - F(a)   &\ge 0, \;\;\text{para}\;\; a < b.
\end{align}

A função densidade de probabilidade (FDP), $f_X$, é
\begin{equation}
   f_X(x) \equiv \deriva{F_X}{x},
\end{equation}
com $f_X(x) \ge 0$ e 
\begin{equation}
   \int_{-\infty}^{+\infty} f_X(x)\,\md{x} = 1.
\end{equation}

\section{Média e momentos}

A média de uma variável aleatória, ou valor esperado de uma variável aleatória, é
\begin{equation}
   \tavg{X} \equiv \int_{-\infty}^{+\infty} xf_X(x)\,\md{x}.
\end{equation}

De maneira mais geral, seja $y = q(x)$ uma função de $x$; então para cada sorteio de $X$
corresponderá um $Y = q(X)$, ou seja: $Y$ será (também) uma variável aleatória.  A média de $Y$
será dada por
\begin{equation}
   \tavg{Y} = \tavg{q(X)} = \int_{-\infty}^{+\infty} q(x)f_X(x)\,\md{x}.
\end{equation}


Momentos centrais desempenham um papel importante em Teoria de Probabilidade. A
definição do momento central de ordem $n$ é
\begin{equation}
c_{Xn} \equiv \tavg{\left( x - \tavg{X}\right)^n} 
= \int_{-\infty}^{+\infty} \left( x - \tavg{X}\right)^n\, f_X(x)\,\md{x}.\label{eq:def-cxn}
\end{equation}

\section{Distribuições conjuntas}

Para definirmos distribuições conjuntas de probabilidade, precisamos estender as
definições da seções \ref{sec:random-var}.

No $\mathbb{R}^2$, uma variável aleatória é uma função $\vet{X} = (X,Y)$ função
de $\omega \in \Omega$:
\begin{align*}
\vet{X} : \Omega \rightarrow \mathbb{R}^2, \\
        \omega   \mapsto     \vet{x} = \vet{X}(\omega).
\end{align*}

A função densidade acumulada conjunta será 
\begin{equation}
F_{X,Y}(x,y) \equiv P\left\{ X \le x \wedge Y \le y\right\},\label{eq:defFXY}
\end{equation}
e a função densidade de probabilidade será
\begin{equation}
f_{X,Y}(x,y) \equiv \parpar{F_{X,y}}{x}{y} = \parpar{F_{X,y}}{y}{x}.
\end{equation}

As funções densidade de probabilidade  \emph{marginais} são
\begin{align}
f_X(x) \equiv \int_{y=-\infty}^{+\infty} f_{X,Y}(x,y)\,\md{y}, \\
f_Y(y) \equiv \int_{x=-\infty}^{+\infty} f_{X,Y}(x,y)\,\md{x}.
\end{align}
Naturalmente,
\begin{equation}
\iint_{x,y} f_{X,Y}(x,y)\,\md{x}\,\md{y} = 1.
\end{equation}

O \emph{valor esperado} de uma função de $X$ e $Y$ é
\begin{equation}
\tavg{g(X,Y)} = \iint_{x,y} g(x,y)f_{X,Y}(x,y)\,\md{x}\,\md{y}.
\end{equation}

Com os resultados acima, nós podemos agora deduzir o seguinte fato: se $X$ e $Y$
são duas variáveis aleatórias quaisquer,
\begin{equation}
\tavg{X+Y} = \tavg{X} + \tavg{Y}.
\end{equation}

\begin{enumerate}[a)]
\item \textit{Insight} com matemática finita: seja $(x_i,y_i), \; i =
  0,\ldots,n-1$ uma amostra qualquer de $n$ pares de observações.  Então, a
  \emph{média amostral} da soma é
\begin{align*}
\overline{x+y} &= \frac{1}{n}\sum_{i=0}^{n-1} \left( x_i + y_i\right) \\
               &= \frac{1}{n}\sum_{i=0}^{n-1} x_i + \frac{1}{n}\sum_{i=0}^{n-1}y_i\\
               &= \overline{x} + \overline{y}.
\end{align*}
Note como não foi necessária nenhuma hipótese adicional sobre a natureza dos
$x$'s e $y$'s ou sobre qualquer relação entre eles.
\item com Teoria de Probabilidade.  Seja $g(x,y) = x+y$. Então,
\begin{align*}
\tavg{g(X,Y)} = \tavg{X + Y} &= \iint_{x,y} (x+y)f_{X,Y}(x,y)\,\md{y}\,\md{x} \\ 
&= \iint_{x,y} x f_{X,Y}(x,y)\,\md{y}\,\md{x} + \iint_{x,y} y f_{X,Y}(x,y)\,\md{y}\,\md{x} \\
&= \iint_{x,y} x \underbrace{\left[f_{X,Y}(x,y)\,\md{y}\right]}_{f_X(x)}\,\md{x} +
   \iint_{x,y} y \underbrace{\left[f_{X,Y}(x,y)\,\md{x}\right]}_{f_Y(y)}\,\md{y}\\
&= \int_{-\infty}^{+\infty} xf_X(x)\,\md{x} + \int_{-\infty}^{+\infty} y f_Y(y)\,\md{y}\\
&= \tavg{X} + \tavg{Y}.
\end{align*}
\end{enumerate}



Já que estamos falando de distribuições conjuntas, devemos tocar no conceito
fundamental de independência/dependência. Dados dois eventos $A$ e $B$, a
probabilidade de $B$ condicionada a $A$ é
\begin{equation}
   P(B|A) \equiv \frac{P(A \cap B)}{P(A)}\label{eq:def-probcond}
\end{equation}

\textbf{Definição:} $B$ e $A$ são independentes quando
\begin{equation} 
P(B|A) = P(B).
\end{equation}
\textbf{Corolário:} Se $A$ e $B$ são independentes,
\begin{equation}
P(B|A) = \frac{P(A \cap B)}{P(A)} = P(B) \Rightarrow P(A \cap B) = P(A)P(B).
\end{equation}

Isso nos leva imediatamente à definição de independenência de variáveis
aleatórias: $X$ e $Y$ são independentes quando os \emph{eventos}
\[
A = \left\{ \omega | X(\omega) \le x\right\} \; \text{e} \;
B = \left\{ \omega | Y(\omega) \le y\right\} 
\]
são independentes, ou seja:
\begin{align*}
P(A \cap B) &= P(A)P(B), \\
P\left( X(\omega) \le x  \wedge Y(\omega) \le y\right) &= P\left( X(\omega) \le x \right)P\left( Y(\omega) \le y\right),\\
F_{X,Y}(x,y) &= F_X(x)F_Y(y).
\end{align*}

Portanto, se $X$ e $Y$ são independentes, então a FDA conjunto é igual ao
produto das FDA's marginais. Fazendo a 2\ira\ derivada cruzada,
\begin{align*}
f_{X,Y}(x,y) &= \parpar{F_{X,Y}(x,y)}{y}{x} \\
             &= \parpar{F_{X}(x) F_{Y}(y)}{y}{x} \\
             &= \parder{}{y}\left[ \parder{F_X}{x} F_Y(y)\right]\\
             &= f_X(x)\parder{F_Y}{y}\\
             &= f_X(x)f_Y(x).
\end{align*}

A  próxima definição é a densidade de probabilidade de $y$ \emph{condicionada} à
ocorrência de $x$:
\begin{equation}
   f_{Y|x}(y) \equiv \frac{f_{X,Y}(x,y)}{f_X(x)}.\label{eq:dens-cond}
\end{equation}
Embora deva ser possível deduzir rigorosamente (\ref{eq:dens-cond}) a partir de
(\ref{eq:def-probcond}), não vou fazê-lo (ainda).  Em vez disto, vou procurar um caso particular
muito interessante.  Primeiramente, note que, por definição, a densidade marginal de $y$ é dada
por
\begin{align}
   f_Y(y) &= \int_{x=-\infty}^{+\infty} f_{X,Y}(x,y)\,\md{x} \nonumber \\
          &= \int_{x=-\infty}^{+\infty} f_{Y|x}(y)f_X(x)\,\md{x} \label{eq:y-dens-marg}.
\end{align}
Considere agora o caso  em que $y = g(x)$, ou seja: em que $Y$ está
deterministicamente determinado a partir da observação de $x$.  A função densidade de
probabilidade condicionada é então, simplesmente, 
\begin{equation}
   f_{Y|x}(y) = \delta(g(x)-y),\label{eq:delta-y-gx}
\end{equation}
ou seja: dado $x$, a probabilidade de que $Y = g(x)$ é 1 (note as letras maiúscula e
minúscula). Note também que (\ref{eq:delta-y-gx}) é uma densidade de probabilidade legítima, já
que sua integral em $y$ é igual a 1.  O primeiro resultado que vamos obter a partir daqui é uma
fórmula para $f_Y(y)$:
\begin{align}
   f_{Y}(y) &= \int_{x = -\infty}^{+\infty} f_{Y|x}(y)f_X(x)\,\md{x} \nonumber \\
            &= \int_{x = -\infty}^{+\infty} \delta(g(x)-y)f_X(x)\,\md{x}. \label{eq:gx-marginal}
\end{align}
Essa é uma equação totalmente geral, que permite o cálculo da densidade de
probabilidade de \emph{qualquer} variável aleatória definida por uma função, $Y
= g(X)$, independentemente de ela ser biunívoca ou não!  A equação
(\ref{eq:gx-marginal}) pode ser prontamente generalizada para funções de várias
variáveis.  Em particular, se $Z = g(X,Y)$, tem-se
\begin{equation}
   f_Z(z) = \int_{x = -\infty}^{+\infty}
               \int_{y = -\infty}^{+\infty}
                  \delta(g(x,y)-z) f_{X,Y}(x,y)\,\md{y}\md{x}. \label{eq:gxy-marginal}
\end{equation}

Considere agora o seguinte exemplo: $y = x^2, \; -1 \le X \le +1$, com $f_X(x) =
1/2$. Essa função \emph{não} é biunívoca.  A densidade de probabilidade de $y$ é
\begin{align}
   f_Y(y) = \int_{-1}^{+1} \delta(x^2-y)\frac{1}{2} \,\md{x}. \label{eq:first-integral}
\end{align}
Para calcular a integral acima, é preciso um pouco de cuidado.  Primeiramente, note que 
\begin{equation}
   y = x^2 \Rightarrow x = \pm \sqrt{y}:
\end{equation}
existem duas raízes, e isto precisa ser levado em consideração pelo ser humano que está
resolvendo o problema: a fórmula (\ref{eq:gx-marginal}) \emph{em si} não vai dizer isso para
você! 
O caminho mais rápido, aparentemente, é recorrer à seguinte propriedade da delta \citep[Cap. 6,
  p. 231]{butkov:fisica}:
\begin{equation}
   \delta(x^2 - a^2) = (1/2a)\left[ \delta(x+a) + \delta(x-a)\right] \qquad (a>0);
\end{equation}
então,
\begin{equation}
   f_Y(y) = \int_{-1}^{+1} \frac{1}{2\sqrt{y}}
   \left[ \delta(x+\sqrt{y}) + \delta(x-\sqrt{y})\right]\frac{1}{2}\,\md{x} 
   = \frac{1}{4\sqrt{y}}\left[ 1 + 1\right] 
   = \frac{1}{2\sqrt{y}}\blob
\end{equation}

Esse é um exemplo simples, porém muito rico.  O valor esperado de $Y$, para o qual nós vamos
usar a notação $\tavg{Y}$, agora é facilmente obtido:
\begin{equation}
\tavg{Y} = \int_0^1 yf_Y(y)\,\md{y} = \int_0^1 y \frac{1}{2\sqrt{y}}\,\md{y} = 
\int_0^1 \frac{\sqrt{y}}{2}\,\md{y} = \frac{1}{3},
\end{equation}
enquanto que, devido à simetria de $f_X(x)$, $\tavg{X} = 0$.


Mais interessante ainda é a seguinte questão: se $X$ é a variável aleatória com distribuição
uniforme entre $-1/2$ e $+1/2$, como acima, e $Y = X^2$, qual é a covariância entre $X$ e $Y$?
Por definição, a covariância entre duas variáveis aleatórias é
\begin{equation}
\Cov\{X,Y\} = 
\int_{x\in \mathbb{R}}\int_{y \in \mathbb{R}} (x - \tavg{X})(y - \tavg{Y})f_{X,Y}(x,y)\,\md{y}\md{x}.
\end{equation}


Quando duas variáveis aleatórias são independentes, sua covariância é nula:
\begin{align*}
\Cov\{X,Y\} &= \iint_{x\in \mathbb{R}, y \in \mathbb{R}}(x - \tavg{X})(y - \tavg{Y})f_{X,Y}(x,y)\,\md{y}\md{x}\\
            &= \iint_{x\in \mathbb{R}, y \in \mathbb{R}}(x - \tavg{X})(y - \tavg{Y}) f_X(x)f_Y(y)\,\md{y}\md{x}\\
            &= \left[
                  \int_{x\in\mathbb{R}}(x - \tavg{X})f_X(x)\,\md{x}
               \right]
               \left[
                  \int_{y\in\mathbb{R}}(y-\tavg{Y})f_Y(y)\,\md{y}
               \right]\\
             &= 0.
\end{align*}



No nosso caso particular, $y=x^2$, a covariância é
\begin{align}
\Cov\{X,Y\} &=
\int_{x=-1}^{1} \int_{y=0}^{1}
   x(y - \frac{1}{3})\delta(x^2 - y)f_X(x)\,\md{y}\md{x} \nonumber \\
&= \int_{x=-1}^{1} \int_{y=0}^{1}
   x(x^2 - \frac{1}{3})\delta(x^2 - y)\frac{1}{2}\,\md{y}\md{x} \nonumber \\
&= \int_{x=-1}^{1} x(x^2 - \frac{1}{3})\int_{y=0}^{1}
   \delta(x^2 - y)\frac{1}{2}\,\md{y}\md{x} \nonumber \\
&= \frac{1}{2}\int_{x=-1}^{1} x(x^2 - \frac{1}{3})
    \underbrace{\int_{y=0}^{1}\left[ \delta(x^2 - y)\,\md{y}\right]}_{=1}\md{x} \nonumber \\
&= \frac{1}{2}\int_{x=-1}^{1} x(x^2 - \frac{1}{3})\,\md{x} = 0.\label{eq:covxy-nula}
\end{align}


Na linha acima de (\ref{eq:covxy-nula}), note a utilização simultânea de duas propriedades da delta:
\begin{align}
   \int_{-\infty}^{+\infty} \delta(x-a)\,\md{x} &= 1,\\
   \delta(x) &= \delta(-x).
\end{align}
O resultado (\ref{eq:covxy-nula}) é admirável: ele mostra que, mesmo que a dependência entre
duas variáveis aleatórias seja \emph{total}; mesmo que $Y$ seja \emph{totalmente} dependente de
$X$ na forma $Y = g(X)$, é possível que $\Cov\{X,Y\} = 0$.  Moral da história: a covariância é
uma medida de dependência \emph{linear}, e \emph{não} uma medida universal de dependência.

Além da covariância, é usual encontrar o coeficiente de correlação,
\[
\varrho_{XY} = \frac{\Cov\{X,Y\}}{\left[ \Var\{X\}\Var\{Y\}\right]^{1/2}}.
\]
Com a desigualdade de Schwarz,
\[
-1 \le \varrho_{XY} \le +1
\]


Considere agora o cálculo da função densidade de probabilidade da variável aleatória $Z = X +
Y$, \emph{soma} de duas variáveis aleatórias $X$ e $Y$ cuja distribuição conjunta de
probabilidade, $f_{X,Y}(x,y)$, é conhecida.  A função densidade de probabilidade de $Z$ dada a
ocorrência de $x,y$ é
\begin{equation}
   f_{Z|x,y} = \frac{f_{Z,X,Y}(z,x,y)}{f_{X,Y}(x,y)} = \delta(z - [x+y])
\end{equation}
Segue-se que a função densidade de probabilidade marginal de $Z$ é
\begin{align}
   f_{Z}(z) &= \int_{x=-\infty}^{+\infty}\int_{y=-\infty}^{+\infty}f_{Z,X,Y}(z,x,y)\,\md{y}\,\md{x}
   \nonumber \\
            &= \int_{x=-\infty}^{+\infty}\int_{y=-\infty}^{+\infty}\delta(z - x - y)f_{X,Y}(x,y)\,\md{y}\,\md{x}
\end{align}
Lembrando das propriedades da Delta de Dirac,
\begin{align}
   \int_{-\infty}^{+\infty} \delta(y-a)f(y)\,\md{y} &= f(a),\\
   \delta(y-a) &= \delta(a-y),
\end{align}
tem-se
\begin{equation}
f_{Z}(z) = \int_{x=-\infty}^{+\infty}
            f_{X,Y}(x,z-x)\,\md{x} = \int_{y=-\infty}^{+\infty} f_{X,Y}(z-y,y)\,\md{y}\blob
\end{equation}
Finalmente, no caso de variáveis aleatórias $X$ e $Y$ independentes, as integrais acima
tornam-se integrais de convolução:
\begin{equation}
f_{Z}(z) = \int_{x=-\infty}^{+\infty} f_X(x)f_Y(z-x)\,\md{x}.
\end{equation}

Note que esta é uma convolução no sentido da Teoria de Transformadas de Fourier, e não no
sentido da Teoria de Transformadas de Laplace.

Quando, por outro lado, a relação $Y=g(X)$ é biunívoca, as coisas ficam mais
fáceis:
\begin{align*}
P\left\{ Y \le y \right\} & P\left\{ X \le x \right\}, \\
P\left\{ Y \le g(x) \right\} & P\left\{ X \le x \right\}, \\
F_Y(g(x)) &= F_X(x),\\
\mderiva{}{x} F_Y(g(x)) &= \mderiva{}{x} F_X(x), \\
\mderiva{}{y} F_Y(g(x))\mderiva{g}{x} &= f_X(x),\\
f_Y(y)\mderiva{g}{x} &= f_X(x).
\end{align*}
Mudando ligeiramente a notação, $y = y(x)$ produz
\[
f_Y(y)\md{y} = f_X(x)\md{x}
\]
cuja interpretação gráfica é óbvia.

Um caso particularmente útil e interessante é o de geração de uma variável
aleatória no computador com uma distribuição dada. A resposta é o uso da própria
FDA $F_X(x)$ no lugar de $g(x)$. Seja $U = F_X(X)$ a variável aleatória assim
gerada. Nesse caso,
\begin{align*}
f_U(u)\md{u} &= f_X(x) \md{x}, \\
f_U(u)\mderiva{u}{x} &= f_X(x).
\end{align*}
mas
\[
\mderiva{u}{x} = \mderiva{F_X(x)}{x} = f_X(x);
\]
portanto,
\begin{equation}
f_U(u) = 1, \qquad 0 \le u \le 1.
\end{equation}

A ``receita'' para gerar uma variável aleatória com FDA $F_x(x)$ é a seguinte:
\begin{enumerate}[a)]
\item gere uma variável $u$ uniforme em $[0,1]$.
\item calcule $x = F_X^{-1}(u)$.
\end{enumerate}

Quando existe uma dependência linear, do tipo $Y = aX + b$, a \emph{forma} da
distribuição não muda:
\begin{align*}
x &= \frac{y-b}{a}, \\
\mderiva{y}{x} &= a,\\
f_Y(y) \md{y} &= f_X(x)\md{x},\\
f_Y(y) \mderiva{y}{x} &= f_X(x), \\
f_Y(y) a &= f_X(x),\\
f_Y(y) &= \frac{1}{a}f_X\left( \frac{y-b}{a}\right).
\end{align*}




Seja $Y$ o estimador de uma variável cujo valor verdadeiro (de população) é $y$.  No
caso mais geral,
\begin{equation}
\tavg{Y} = y' \ne y.
\end{equation}
A diferença entre o valor médio previsto pelo modelo ($y'$) e o valor verdadeiro ($y$) é
denominada o \emph{viés} do modelo.

A figura \ref{fig:duasfdps} dá uma visão dessas relações.

\begin{figure}\centering
\includegraphics[width=0.6\textwidth]{duasfdps}
\caption{Relação entre as distribuições de probabilidade de $X$ e $Y$ quando a
  relação entre ambos é biunívoca.\label{fig:duasfdps}}
\end{figure}

\textbf{Exemplo: soma de exponenciais}

Sejam
\begin{align*}
f_X(x) = \frac{1}{\beta}\exp\left(-\frac{x}{\beta}\right),\\
f_Y(y) = \frac{1}{\beta}\exp\left(-\frac{y}{\beta}\right),
\end{align*}
ou seja: duas variáveis aleatórias $X$ e $Y$ independentes e igualmente
distribuídas com distribuição exponencial. Se $Z = X+Y$,
\begin{align*}
P\{ Z \le z \} &= P\{ X + Y \le z\}\\
               &= P\{ (X,Y) \in \mathscr{D}\}\\
               &= P(\mathscr{D}).
\end{align*}
Veja a figura \ref{fig:duasexps}

\begin{figure}\centering
\includegraphics[width=0.5\textwidth]{duasexps}
\caption{Região de integração para cálculo da distribuição da soma de duas
  variáveis aleatórias exponenciais.\label{fig:duasexps}}
\end{figure}

Agora,
\begin{align*}
P\{ X + Y \le z\} &= \int_{x=0}^z\int_{y=0}^{z-x}
\frac{1}{\beta}\exp\left(-\frac{x}{\beta}\right)
\frac{1}{\beta}\exp\left(-\frac{y}{\beta}\right)\,\md{y}\md{x} \\
&= \int_{x=0}^z \exp\left(-\frac{x}{\beta}\right)
\left[
\int_{y=0}^{z-x} \exp\left(-\frac{y}{\beta}\right)\,\md{\left(\frac{y}{\beta}\right)}
\right]
\md\left( \frac{x}{\beta}\right)\\
&= \int_{x=0}^z \exp\left(-\frac{x}{\beta}\right)\left[ 1 -
  \exp\left(-\frac{z-x}{\beta}\right)\right]\md\left( \frac{x}{\beta}\right)\\
&= \int_0^z \left( \me^{-x/\beta} - \me^{-z/\beta}\right)\md{\frac{x}{\beta}}\\
&= 1 - \me^{-z/\beta} - \frac{z}{\beta}\me^{-z/\beta}.
\end{align*}
Portanto,
\begin{align*}
F_Z(z) &= 1 - \me^{-z/\beta} - \frac{z}{\beta}\me^{-z/\beta},\\
f_Z(z) &= \frac{z}{\beta^2}\me^{-z/\beta}.
\end{align*}
A fdp tem a forma de distribuição gama, cuja fórmula geral é
\begin{equation}
f_X(x) = \frac{1}{\beta\Gamma(\alpha)}\left(\frac{x}{\beta}\right)^{\alpha-1}\me^{-\frac{x}{\beta}}.
\end{equation}
Para $\alpha=2$, $\Gamma(\alpha) = 1$, e a fórmula coincide. Esse é uma caso
particular do seguinte resultado, mais geral:
\[
X_1, \ldots X_n \sim \text{EXP}(\beta) \Rightarrow Z = \sum_{i=1}^n X_i \sim
\text{GAMA}(n,\beta).
\]

\chapter{Modelos e erros}


\begin{Exe}\label{exe:modtemp}
Seja $M$ um modelo de previsão da temperatura da água de um rio.  O modelo funciona de acordo com
o seguinte esquema:
\[
   \begin{bmatrix}
     x_1 \\
     x_2 \\
     \vdots \\
     x_n
   \end{bmatrix} \longrightarrow \fbox{$\displaystyle M(\vet{x}; \vet{\theta})$} \longrightarrow y' \ne y.
\]
Aqui, o vetor $\vet{x} = (x_1, x_2, \ldots, x_n)$ representa os \emph{dados de entrada}; eles
podem ser, por exemplo, a radiação solar incidente, a vazão do rio, a temperatura do ar, etc..
O modelo $M$ em si é composto de elementos tais como a geometria rio (largura, profundidade,
comprimento), pelas as equações utilizadas para calcular ou estimar a temperatura $y$, etc..  A
\emph{natureza} de M pode ser qualquer.  Por exemplo, M pode ser simplesmente uma regressão
linear múltipla
\begin{equation}
    y = a_0 + a_1x_1 + a_2x_2 + \ldots + a_nx_n\label{eq:Maix}
\end{equation}
mas também pode ser um modelo físico de balanço de entalpia cuja incógnita seja a temperatura da
água \citep{dias:obtencao.sol,dias.gobbi.ea:formulacao}.  Finalmente note que existe um vetor de
\emph{parâmetros} $\veg{\theta}$ de $M$.  No caso da regressão múltipla (\ref{eq:Maix}), os
parâmetros são $a_0, a_1, \ldots, a_n$.
\skipend
\end{Exe}

A partir do esquema geral representado pelo Exemplo \ref{exe:modtemp}, é fácil identificar que
numerosos erros podem ocorrer no processo de modelagem.  Em geral, nós classificamos os erros em
3 tipos
\begin{enumerate}[A)]
   \item Erro dos dados: os dados de entrada do modelo geralmente contêm erros. Só isto já faz
     com que os dados de entrada devam ser considerados como variáveis aleatórias $X_1, X_2,
     \ldots, X_n$ e consequentemente a saída do modelo, $Y$, também.
   \item Erro do modelo: todo modelo contém imperfeições e limitações, e muitas vezes é
     extremamente difícil até mesmo identificar inequivocamente um único modelo (por exemplo, é
     comum que diversas distribuições diferentes de probabilidade representem ``igualmente bem''
     um determinado conjunto de observações). 
   \item Erro dos parâmetros.  Mesmo que o modelo seja perfeito, a aleatoriedade seja dos dados
     de entrada seja das próprias observações $y$ nas quais nos baseamos para ``calibrar'' $M$
     --- o processo de estimativa dos parâmetros $\veg{\theta}$ --- faz com que estes últimos
     também carreguem incerteza.  
\end{enumerate}

Algumas estatísticas básicas de erros são definidas a seguir.

O víes do modelo é 
\begin{equation}
v \equiv \tavg{Y} - y = y' - y.  \label{eq:def-vies}
\end{equation}

O erro médio quadrático do modelo é
\begin{equation}
\EMQ\{Y\} \equiv \tavg{(Y - y)^2}
\end{equation}
e sua raiz quadrada, que tem as mesmas dimensões de $Y$, é
\begin{equation}
   \REMQ\{Y\} = \sqrt{\EMQ\{Y\}}.
\end{equation}

A variância de $Y$ é
\begin{equation}
\Var\{Y\} = \tavg{(Y - \tavg{Y})^2}.
\end{equation}

Muito importante: como em geral $\tavg{Y} \ne y$, $\EMQ\{Y\} \ne \Var\{Y\}$.  A relação entre
ambas as estatísticas pode ser obtida muito facilmente:
\begin{align}
\EMQ\{Y\} &= \tavg{(Y - y)^2} \nonumber \\
          &= \tavg{ [ (Y - y') + (y' - y) ]^2} \nonumber \\
          &= \tavg{ (Y - y')^2 + 2(Y- y')(y'-y) + (y'- y)^2} \nonumber \\
          &= \tavg{ (Y - y')^2}  + 2(y'-y)\underbrace{\tavg{(Y- y')}}_{=0} + \tavg{(y'- y)^2}
\nonumber \\
          &= \Var\{Y\} + v^2\blob
\end{align}

Um bom modelo deve combinar duas virtudes:
\begin{itemize}
   \item ser acurado: $v \rightarrow 0$;
   \item ser preciso: $\Var\{Y\} \rightarrow 0$.
\end{itemize}



\chapter{A difusão de um ponto de vista probabilístico}




\section{Um passeio aleatório}\label{sec:passeio}

Na figura \ref{fig:passale}, uma partícula move-se a partir da origem (com certeza) em passos de tempo $n$, dando ``saltos''
de 1 unidade a cada tempo.  A posição da partícula no tempo $n$ é $X(n)$.   A
\emph{probabilidade} de a partícula estar na posição $k$ no instante $n$ é
\begin{equation}
p_k(n) \equiv P\{ X(n) = k \}.\label{eq:pkn}
\end{equation}
Suponha que uma transição para cima ou para baixo seja igualmente provável, e
\emph{independente} do estado atual $X(n)$:
\begin{align}
P\{ X(n+1) = X(n) + 1\} &= 1/2, \\
P\{X(n+1) = X(n) -1 \} &= 1/2.
\end{align}
Então o estado $k$ só pode ser alcançado a partir de $k+1$ ou de $k-1$, e
\begin{equation}
p_k(n+1) = \frac{1}{2}p_{k+1}(n) + \frac{1}{2}p_{k-1}(n).\label{eq:midpk}
\end{equation}


\begin{figure}\centering
   \includegraphics[width=0.6\textwidth]{passale}
   \caption{Um passeio aleatório simples, começando sempre em $X = 0$.\label{fig:passale}}
\end{figure}

\begin{figure}\centering
   \includegraphics[width=0.6\textwidth]{derivadasnum}
   \caption{Derivadas numéricas de ordem 1 e 2.\label{fig:derivadasnum}}
\end{figure}

Para prosseguirmos, nós vamos necessitar de derivadas numéricas. Veja a figura
\ref{fig:derivadasnum}: as derivadas numéricas \emph{centradas} em $x = (i+1/2)\Delta x$, e $x =
(i-1/2)\Delta x$ são
\begin{align}
f'_{i+1/2} &\approx \frac{f_{i+1} - f_i}{\Delta x}, \\
f'_{i-1/2} &\approx \frac{f_i - f_{i-1}}{\Delta x}.
\end{align}
A derivada numérica é o coeficiente angular da secante entre 2 pontos; a derivada \emph{exata} é
o coeficiente angular da tangente geométrica.  Na figura \ref{fig:derivadasnum}, ambas são
mostradas: se você possuir uma vista suficientemente boa, procure identificar visualmente a
diferença entre elas.


A derivada segunda é a derivada da derivada:
\begin{align}
f''_i &\approx \frac{f'_{i+1/2} - f'_{i-1/2}}{\Delta x} \nonumber \\
      &= \frac{\frac{f_{i+1} - f_i}{\Delta x} - \frac{f_i - f_{i-1}}{\Delta x}}{\Delta
  x}\nonumber \\
      &= \frac{f_{i+1} - 2f_i + f_{i-1}}{\Delta x^2}.
\end{align}
Com isto, nós podemos agora manipular a equação (\ref{eq:midpk}):
\begin{align}
p_k(n+1) &= \frac{1}{2}\,\left( p_{k+1}(n) + p_{k-1}(n) \right) \nonumber \\
2p_k(n+1) &=   p_{k+1}(n) + p_{k-1}(n) \nonumber \\
2(p_k(n+1) - p_k(n)) &=   p_{k+1}(n) -2 p_k(n) + p_{k-1}(n)  \nonumber \\
\frac{p_k(n+1) - p_k(n)}{\Delta x^2} &= \frac{1}{2} \,\frac{p_{k+1}(n) -2 p_k(n) +
  p_{k-1}(n)}{\Delta x^2}\nonumber \\
\frac{p_k(n+1) - p_k(n)}{\Delta t} &= \frac{\Delta x^2}{2\Delta t}\, \frac{p_{k+1}(n) -2 p_k(n) +
  p_{k-1}(n)}{\Delta x^2}\label{eq:era-pkn}
\end{align}
Faça agora 
\[
p_k(n) = p(k\Delta x, n\Delta t) = p(x,t)
\]
e mantenha
\begin{equation}
\mathscr{D} = \frac{\Delta x^2}{2\Delta t} \label{eq:Dconst}
\end{equation}
constante, enquanto $\Delta x \to 0$. (\ref{eq:era-pkn}) torna-se
\begin{align}
\frac{p(x,t+\Delta t) - p(x,t)}{\Delta t} &= \mathscr{D}\, \frac{p(x+\Delta x,t) - 2p(x,t) +
  p(x-\Delta x,t)}{\Delta x^2} \nonumber \; \to \\
\parder{p}{t} &= \mathscr{D}\,\parn{p}{x}{2}.\label{eq:governing-pt}
\end{align}
Esta é a mesma equação de difusão que nós resolvemos no capítulo \ref{cap:edp}! Isto significa
que nós podemos dar à concentração de uma substância uma interpretação \emph{probabilística}:
ela é (também) a probabilidade de encontrarmos em $(x,t)$ uma partícula emitida em uma certa
posição (digamos, $\xi$) no instante $t = 0$.  Mas será $\mathscr{D} = \Delta x^2/(2\Delta t)$
realmente constante?  Esta pergunta possui uma resposta \emph{estatística}, encontrada por
Albert Einstein em 1905

\section{A solução de Einstein para o movimento Browniano}\label{sec:brown-einstein}

Suponha que existem partículas movendo-se aleatoriamente dentro de um fluido de viscosidade
dinâmica $\mu$ e com temperatura termodinâmica $T$.  A força de resistência ao movimento de uma
partícula é dada pela lei de Stokes:
\begin{equation}
F_R = -6\pi \mu a \deriva{X}{t},\label{eq:fr-stokes}
\end{equation}
onde $X$ é a posição aleatória da partícula, e $a$ é o seu raio.  Em (\ref{eq:fr-stokes}), note
que $X$ é um escalar: nossa abordagem aqui será \emph{unidimensional}, porque isto é mais fácil
algebricamente. Quando fazemos isto, perdemos um pouco do realismo da situação, e muitas pessoas
têm dificuldade em raciocinar com situações que, embora matematicamente mais simples, não
possuem uma representação concreta no mundo real.  Entretanto, esta é uma \emph{excelente}
maneira de abordar aquele mundo real: aos poucos, introduzindo as dificuldades matemáticas
apenas quando não é mais possível escamoteá-las.

As velocidades das partículas, $V$, dependem da temperatura do fluido (e delas mesmas), segundo
a Mecânica Estatística, via
\begin{equation}
\tavg{\frac{mV^2}{2}} = \frac{1}{2} k T,
\end{equation}
onde $k$ é a constante de Boltzmann.

Além de $F_R$, as partículas sofrem a ação de forças aleatórias $F$, que são produzidas pelos
choques com as moléculas do fluido.  A equação de movimento (unidimensional, é claro) de um
partícula é
\begin{equation}
m\mdern{X}{t}{2} = - 6\pi \mu a \deriva{X}{t} + F. \label{eq:eq-mov-brown}
\end{equation}
Volte agora ao coeficiente de difusão dado por (\ref{eq:Dconst}): se partirmos de $x=0$, $t=0$,
teremos (para cada partícula)
\[
X^2 = 2\mathscr{D}t.
\]
Suponha que esta relação seja válida na média de todas as partículas; então,
\begin{align}
\tavg{X^2} &= 2\mathscr{D}t,\label{eq:difu-media-1}\\
\deriva{}{t}\tavg{X^2} &= 2\mathscr{D},\label{eq:difu-media-2}\\
\mdern{}{t}{2}\tavg{X^2} &= 0.\label{eq:difu-media-3}
\end{align}
Lembre-se de que por enquanto (\ref{eq:difu-media-1}) é apenas uma suposição, que nós devemos
ser capazes de provar.  Agora,
\begin{align}
\deriva{}{t}\tavg{X^2} &= \tavg{\deriva{}{t} X^2} =
\tavg{2X\deriva{X}{t}}, \label{eq:so-first}\\
\mdern{}{t}{2}\tavg{X^2} &= 2\left[ \tavg{\deriva{X}{t}}^2 + \tavg{X\mdern{X}{t}{2}}\right].
\end{align}
Invocando agora (\ref{eq:difu-media-3}) (que ainda é apenas uma hipótese que precisa ser
provada), 
\begin{equation}
\tavg{X\mdern{X}{t}{2}} = - \tavg{\deriva{X}{t}}^2.\label{eq:just-fit-difu}
\end{equation}
A equação (\ref{eq:just-fit-difu}) será útil em (\ref{eq:eq-mov-brown}); multiplicando esta
última por $X$ e utilizando (\ref{eq:just-fit-difu}):
\begin{align}
   m\tavg{X\mdern{X}{t}{2}} &= -6\pi a \mu \tavg{X\deriva{X}{t}} + \tavg{XF}, \nonumber \\
 -m\tavg{\deriva{X}{t}}^2  &= -6\pi a \mu \tavg{X\deriva{X}{t}} + \tavg{XF}.
\end{align}
Raciocine agora probabilisticamente: $X$ é a posição de uma partícula qualquer, com
$\tavg{X}=0$.  $F$ é a força aleatória sobre uma partícula, com $\tavg{F} = 0$.  $X$ e $F$
\emph{devem} ser variáveis aleatórias independentes:
\begin{equation}
\Cov\{X,F\} = 
\tavg{(X - \tavg{X})(F- \tavg{F})} = \tavg{XF} = 0.
\end{equation}
Segue-se que
\begin{align}
6\pi a \mu \tavg{X\deriva{X}{t}} &= m\tavg{\deriva{X}{t}^2} = kT, \nonumber \\
6\pi a \mu \tavg{2X\deriva{X}{t}} &= 2kT, \nonumber \\
6\pi a \mu \deriva{}{t}\tavg{X^2} &= 2kT, \nonumber \\
\deriva{}{t}\tavg{X^2} &= \frac{kT}{3\pi a \mu} = 2\mathscr{D}, \label{eq:eunaodisse} \\
\mathscr{D} &= \frac{kT}{6\pi a \mu}.
\end{align}
Observe que (\ref{eq:eunaodisse}) é a mesma que (\ref{eq:difu-media-2}): a hipótese
(\ref{eq:difu-media-1}) é \emph{consistente} com o resultado que obtivemos, e o justifica
\textit{a posteriori}.

A relação entre $k$, o número de Avogadro $N_A$, e a constante universal dos gases pode ser
encontrada nos bons livros do ramo: $R = kN_A$, ou seja:
\begin{equation}
\deriva{}{t}\tavg{X^2} = \frac{RT}{3\pi a \mu N_A};
\end{equation}
esta é uma forma de determinar experimentalmente o número de Avogadro \textcolor{red}{\maltese You should
  re-read Abraham Pais}!

Uma maneira mais formal de deduzir que $\mdern{}{t}{2}\tavg{X^2} = 0$ é a seguinte.  Suponha que
$X$ seja um processo estocástico com incrementos estacionários:
\begin{align}
\deriva{}{t}\tavg{ \left( X(t) - X(s)\right)^2} &= 0, \qquad \forall t,s, \; t > s, \nonumber \\
\deriva{}{t}\tavg{ \frac{\left( X(t) - X(s)\right)^2}{t-s} } &= 0, \nonumber \\
\deriva{}{t}\tavg{ \frac{(\Delta X)^2}{\Delta t}} &= 0, \nonumber \\
\tavg{ \frac{(\Delta X)^2}{\Delta t}} &= 2\mathscr{D}.
\end{align}

Como vimos, o distribuição de probabilidade da posição de uma partícula no passeio aleatório
descrito na seção \ref{sec:passeio} possui equação governante (\ref{eq:governing-pt}),
com
\begin{align}
   p(x,0) &= \delta(x), \label{eq:always-from-zero}\\
   \int_{-\infty}^{+\infty} p(x,t)\,\md{x} &= 1, \; \forall t.\label{eq:normalized-p}
\end{align}
É fácil interpretar estas duas últimas equações.  (\ref{eq:always-from-zero}) nos informa que
$X(0) = 0$ \emph{com probabilidade 1}: a partícula \emph{sempre} sai de $x = 0$.
(\ref{eq:normalized-p}) requer que a densidade de probabilidade possua integral unitária, o que
é óbvio. Note que (\ref{eq:governing-pt}) juntamente com as condições
(\ref{eq:always-from-zero})--(\ref{eq:normalized-p}) é um problema clássico \emph{que nós já
  resolvemos}, utilizando transformada de Fourier.  A solução que obtivemos é
\begin{equation}
p(x,t) = \frac{1}{\sqrt{4\pi D t}}\exp\left[ - \frac{x^2}{4DT}\right].\label{eq:is-p-a-sol}
\end{equation}
Se fizermos, de acordo com a teoria do movimento Browniano de Einstein da seção \ref{sec:brown-einstein} 
\begin{equation}
\sigma^2 \equiv \tavg{X^2} = 2\mathscr{D}t \label{eq:sigma-enters-scene}
\end{equation}
e substituirmos em (\ref{eq:is-p-a-sol}), teremos
\begin{equation}
p(x,t) = \frac{1}{\sqrt{2\pi}\sigma}\exp\left[ -\frac{1}{2}\left(\frac{x}{\sigma}\right)^2\right].
\end{equation}
Esta é uma velha conhecida nossa: trata-se da distribuição normal, ou gaussiana, de
probabilidade.  Neste contexto, o \emph{desvio-padrão} da posição da partícula, $\sigma$, cresce
com a raiz quadrada do tempo $t$.

Equações do tipo (\ref{eq:sigma-enters-scene}) aparecem com frequência em problemas de difusão,
e seu surgimento agora deve estar mais claro para você.


\section{Uma introdução informal a processos estocásticos}



%% Em seguida, vamos definir o conceito, importantíssimo, de \emph{escala integral}.  De forma
%% muito grosseira, mas certamente evocativa, \emph{a escala integral é a metade do tempo que um
%% processo estocástico leva para se esquecer de si mesmo}. 
%% Na verdade ainda não definimos o que é um \emph{processo estocástico}, mas tenha
%% calma. 

Primeiro, alguns exemplos: as condições de tempo (tempo bom --- sol, ou tempo ruim ---
chuva), o total de milímetros de chuva precipitados a cada 24 horas, e a vazão em um rio a cada
dia, são todos exemplos de fenômenos que podem ser \emph{modelados} como processos estocásticos.

Note o cuidado com as palavras: estes fenômenos podem ser \emph{modelados} como processos estocásticos;
eles não \emph{são} processos estocásticos. Tanto quanto sabemos, a natureza não ``sabe'' o que
ela mesma é; somos nós que lhe atribuímos certas propriedades, e a ``enfeitamos'' com hipóteses
e modelos.  

{\itshape  De fato, é totalmente irrelevante o que a natureza realmente ``é'': tudo o que
  devemos nos perguntar é se os modelos que utilizamos são uma boa descrição daqueles aspectos
  da natureza que consideramos importante modelar, para efeito de compreensão e de previsão}

De volta aos fenômenos que identificamos como passíveis de serem modelados como processos
estocásticos, observe que
\begin{enumerate}
\item O tempo amanhã é muito parecido com o tempo hoje: se hoje o tempo está bom, é grande a
  chance de o tempo também estar bom amanhã.  Uma boa variável para testar isto é a pressão
  atmosférica.
\item Uma coisa semelhante acontece --- não por coincidência, é claro --- com a chuva: se hoje
  está chovendo, é grande a chance de ainda estar chovendo amanhã. 
\item Idem para a vazão de um rio --- de novo você deve notar que estes 3 fenômenos estão
  intimamente ligados --- se hoje a vazão de um rio está baixa (porque não chove na bacia há
  muitos dias), então é grande a chance de que ela continue baixa amanhã.
\end{enumerate}
Por outro lado, a relação entre o tempo (ou a chuva, ou a vazão) hoje e daqui a 3 meses é
praticamente nula: a persistência destes fenômenos não dura --- normalmente --- mais do alguns
dias.  Figurativamente, depois de um certo número de dias a natureza ``se esquece'' de si
mesma. A idéia aqui é que muitos fenômenos possuem uma memória ``finita''.  Nosso trabalho agora
é obter uma caracterização matemática razoável do que são processos estocásticos, e do que é a
sua ``memória''.

\begin{Def}
Um processo estocástico $X(t,\omega)$ é uma função que leva cada $\omega \in \Omega$ de um
\emph{espaço} amostral em uma função $x(t) = X(t,\omega)$.
\end{Def}


\begin{figure}
   \includegraphics[width=0.9\textwidth]{procest}
   \caption{Ilustração de um processo estocástico.\label{fig:procest}}
\end{figure}

Uma figura vale mais do que mil palavras.  A figura \ref{fig:procest} ilustra a definição de
processo estocástico.  Nesta figura, 3 valores diferentes de $\omega$ geram 3 funções $x(t)$
distintas. Mas não se engane!  A \emph{estocasticidade} --- isto é, a aleatoriedade --- do
processo está no sorteio dos $\omega$'s, e não na aparência ``aleatória'' de $x(t)$!  De fato,
cada um dos 3 gráficos de $X(t,\omega)$ na figura \ref{fig:procest} poderia ser uma função
perfeitamente suave, e ainda assim o ``processo'' seria estocástico.  A aparência de
aleatoriedade de cada um dos gráficos está ligada a propriedades \emph{adicionais} --- e muito
úteis na prática --- de alguns processos estocásticos.  Estas propriedades são a memória finita,
e a ergodicidade.  Nós agora passamos a descrevê-las.

\begin{Def} A função de autocovariância de um processo estocástico $X(t)$ é
\begin{equation}
C(r,s) \equiv \tavg{ (X(r)-\tavg{X(r)})(X(s)-\tavg{X(s)}) }\label{eq:def-crs}
\end{equation}
\end{Def}
Quando $X(t)$ é estacionário, (\ref{eq:def-crs}) simplifica-se consideravelmente. Em processos
estacionários, estatísticas calculadas em um instante $t$ qualquer não dependem do mesmo. Então,
\begin{align}
\tavg{X(r)} &= \tavg{X(s)} = \mu_X,\label{eq:mu-x-cte}\\
\tavg{(X(t)-\mu_X)^2} &= \sigma_X^2\label{eq:sigma-x-cte},
\end{align}
sendo que $\mu_X$ e $\sigma_X^2$ são \emph{constantes} ao longo do tempo.

Em segundo lugar, se $X(t)$ é estacionário, estatísticas que dependem de \emph{mais de um
  instante} permanecem inalteradas sob uma translação no tempo.  Então,
\begin{equation}
C(r,s) = C(r-s,0).\label{eq:crs0}
\end{equation}
Em outras palavras, \emph{a função de autocovariância de um processo estocástico estacionário
  depende apenas da diferença entre os instantes $r$ e $s$}.
Isto nos dá, agora, uma definição mais simples (porém também mais restrita, porque só vale para
processos estocásticos estacionários) para a função de autocovariância:
\begin{equation}
C(\tau) = \tavg{ (X(t) - \mu_X)(X(t + \tau) - \mu_X)}.\label{eq:ctau}
\end{equation}
Com $C(\tau)$ é possível definir uma 

Vamos seguir agora para uma introdução informal à Teoria de Difusão Turbulenta de Taylor.  Não
custa repetir, nossa versão é unidimensional (e portanto demasiadamente simplificada para
algumas aplicações).  


Vamos agora começar a descrição de uma outra teoria de difusão, que deve muito à de Einstein, e
que tentar analisar a difusão turbulenta sob um ponto de vista lagrangeano, ou seja: sob o ponto
de vista do passeio aleatório de uma partícula em um fluido em escoamento turbulento.

Da mesma maneira que na seção \ref{sec:brown-einstein}, nós vamos estudar o problema em uma
dimensão, para simplificar a matemática.

Em primeiro lugar, note que a posição $X$ de uma partícula no instante $t$ pode ser interpretada
como uma soma de incrementos, como se segue:
\begin{equation}
X(t) = \int_0^t U(\tau)\,d\tau \nonumber = \lim_{\Delta \tau \to 0} \sum_k U(\tau_k)\Delta \tau.\label{eq:XisSum}
\end{equation}
Em (\ref{eq:XisSum}), $U$ é a velocidade da partícula em cada instante, e a integral foi
re-interpretada como (o limite de) uma soma de Riemman.  É muito razoável agora supor que todos
os $U(\tau_k)$'s são indenticamente distribuídos, e invocar o Teorema Central do Limite. Nós
concluímos então, imediatamente, que $X$ é distribuído normalmente.


Nosso ponto de partida --- que já foi dado --- é a integral
(\ref{eq:XisSum}).  Vamos supor que o campo de velocidade $U$ que transporta a partícula possui
média zero: $\tavg{U} = 0$.  Segue-se de (\ref{eq:XisSum}) que 
\begin{equation}
\tavg{X(t)} = \tavg{\int_0^t U(\tau)\,d\tau} = \int_0^t \tavg{U(\tau)}\,d\tau = 0.
\end{equation}
A função de autocovariância simplifica-se ainda mais:
\[
C(\tau) = \tavg{X(t)X(t+\tau)}.\label{eq:ctau0}
\]


\begin{Proj}
Um processo estocástico ``clássico'' é o modelo AR-2 dado por
\begin{equation}
X_{n} = a_1X_{n-1} + a_2X_{n-2} + E
\end{equation}
onde $E$ é um ruído branco de média zero e variância $\sigma^2$. Os parâmetros $a_1$ e
$a_2$ devem obedecer a \citep[eq. 2.54]{bras-rodriguez-iturbe--random}:
\begin{align*}
   a_1 + a_2 &< 1,\\
   a_2 - a_1 &< 1,\\
-1 < a_2 &< 1.
\end{align*}
Por exemplo, podemos ter $a_1 = 0{,}8$, e $a_2 = -0{,}2$.
\end{Proj}

\section{2014-03-31 Moving on to stochastic processes and dynamical systems}

\cite[][Teorema 6.1.1]{rosenthal--first.look}: para qualquer função mensurável $g: \mathbb{R} \rightarrow \mathbb{R}$, 
\[
\int_\Omega g(X(\omega))\,\md{P}(\omega) = \int_{\mathbb{R}} g(t) \md{F}_X(t).
\]

De \cite{todorovic--introduction.stochastic.processes}: Um processso
estocástico é uma família de variáveis aleatórias $X(t)$, $t \in T$,
definidas em um espaço \emph{comum} de probabilidade
$(\Omega,\mathscr{F},P)$, $T \subset \mathbb{R}$:
\begin{align*}
X : \Omega \times T &\to \mathbb{R},\\
    (\omega,t) &\mapsto x = X(\omega,t)
\end{align*}

Um ponto muito importante é o seguinte:
\begin{quote}
Uma vez que $\omega$ tenha sido escolhido, $X(t)$ é
\emph{determinístico}, ou seja: é uma função ordinária (de $t$) como
qualquer outra!
\end{quote}



\begin{center}
   \includegraphics[width=0.6\textwidth]{/home/nldias/work/graduacao/matap/aulas/procest}
   \colorbox{yellow}{A single $\omega$ for each $x(t)$!}
\end{center}

\textbf{I will now try to re-write my presentation at Santa Maria
  using only $\omega$ and $\Omega$.  The objective is to work on
  notation to clean it up as much as possible. I believe that notation
is important, indeed fundamental: does that make me a formalist?}

Vamos construir funções

\begin{align*}
   \phi_t : \Omega &\rightarrow \Omega, \\
             \omega_0 &\mapsto \omega(t) = \phi_t(\omega_0)
\end{align*}
O índice $t$ acima é  $t \in T \subset \mathbb{R}$. Ele pode
representar um sistema discreto ou contínuo. 

Já nesse ponto, a similaridade com a definição de processo estocástico
é impressionante!  Isso não pode ser coincidência!

Defina
\[
\phi_{t+s} = \phi_s \circ \phi_t.
\]

Um sistema dinâmico agora é a tripla $(\Omega, \mathscr{F}, P)$ com
$\phi_t$.  Uma coisa importante prá caramba é que $\phi_t$ induz uma
nova medida de probabilidade em $\Omega$ (desde que $\phi_t$ seja
mensurável, é claro).  Essa nova medida é definida por
\[
P^*(A) \equiv P(\phi_{-t}(A)).
\]
O motivo para fazermos a definição ``de trás para frente'' está, como
sabemos, no conjunto de propriedades 
(\ref{eq:permanencia-uniao})--(\ref{eq:permanencia-complemento}).

\begin{Def}
Se
\begin{equation}
P(A) = P(\phi_{-t}(A)), \; \forall A \in \mathscr{F}, \label{eq:medida-invariante}
\end{equation}
dizemos que $P$ é \emph{invariante} sob $\phi_t$.
\end{Def}


From:
\begin{center}
Dynamical Systems and Stochastic Processes

(P. Collet, 2010)

\url{http://escuelainvierno.cimfav.cl/documentos/pdf/NotesP_Collet.pdf}
\end{center}

\begin{quote}\small
{Given a probability measure $\mu$ (read $P$) on the phase space $\Omega$ and the time evolution map
$T$ (or a (semi)-flow) (read $\phi_t$), we are \textbf{exactly} in the setting of stochastic processes.}
\end{quote}
This is because, given the dynamical system $\phi_t$, and a measurable function
$g$ on $\Omega$, we can define a stochastic
process $X(t)$ by means of
\[
X(\omega,t) \equiv g \left(\phi_t(\omega)\right).
\]

\textbf{Minhas observações: nós precisamos entender direitinho por que
  precisamos, neste ponto, de $g$ para ``fazer a ponte'' entre
  sistemas dinâmicos e processos estocásticos}

Yes!

\cite{collet--dynsys.valparaiso}:
\begin{quote}\small
The fact which may look a little unusual for a Probabilist is that the
probability is given on the initial condition, \textbf{and there is no
  randomness appearing in the time evolution} (my emphasis). However
the points on the phase space completely characterize the orbits, and
we can think of $\mu$ (read $P$) as a probability measure on the
orbits, the time evolution being the shift.

\emph{In that sense, any stochastic process is a dynamical system (a not very useful
remark in practice).}
\end{quote}

\chapter{Processos estocásticos a partir de sistemas dinâmicos}

Este capítulo formaliza as observações de Collet coletadas ao fim do capítulo
anterior.

\section{Definições}

Seja $\Omega$ o espaço de fase, ou espaço amostral.  A partir de agora, esses
dois termos devem ser sinônimos. Seja
\begin{align*}
\phi_t : \Omega &\rightarrow \Omega \\
                 \omega &\mapsto \phi_t(\omega)
\end{align*}
o \emph{fluxo}, com $t \in \mathscr{T}$, onde $\mathscr{T} = \mathbb{R}$ ou $\mathbb{R}^+$ ou
$\mathbb{Z}$ ou $\mathbb{Z}^+$. Como sabemos, $\mathscr{T}$ é o domínio
``temporal'' de evolução do fluxo. Nada impede que se generalize $\phi_t$ para
funções do tempo e do espaço físico, ou para funções de frequência e número de
onda, etc..

O fluxo deve atender a 
\begin{align}
\phi_t \circ \phi_s &= \phi_{t+s}, \\
\phi_0 &= \mathbbm{I_d},
\end{align}
onde $\mathbbm{I_d}$ é a identidade.

Se $\mathscr{T} = \mathbb{R}$ ou $\mathbb{R}^+$, temos um sistema dinâmico
contínuo. Se $\mathscr{T} = \mathbb{Z}$ ou $\mathbb{Z}^+$, temos um sistema
dinâmico discreto.

Dado um sistema dinâmico contínuo, podemos obter, a partir dele, um sistema
dinâmico discreto restringindo $\mathscr{T}$ a $\mathbb{R} \cap \mathbb{Z}$
\textbf{(não entendo $\mathbb{R} \cap h\mathbb{Z}$)} (ou $\mathbb{R}^+ \cap
\mathbb{Z}^+$) e redefinindo o fluxo: dado $h > 0 \in \mathbb{R}$ constante, fazemos
\begin{equation}
T^k(\omega) \equiv \phi_{hk}(\omega), \; k \in \mathbb{Z} \, \text{ou} \,
\mathbb{Z}^+.
\end{equation}

\begin{Def}
O conjunto $\{\phi_t(\omega_0)\}_{t\in\mathscr{T}}$  é a trajetória, ou a
órbita, de $\omega_0$.
\end{Def}

Outra forma de obter um sistema dinâmico discreto a partir de um sistema
dinâmico contínuo é via mapa de Poincaré: obtém-se a interseção da órbita com
uma superfície (variedade) transversal a ela e os pontos de interseção formam o
mapa na superfície. \textbf{Não tive disposição de fazer a figura em pstricks!
  voluntários?}

\section{Medidas invariantes}\label{sec:medidas-invariantes}

\begin{Def}
O suporte de uma medida não identicamente nula é o menor conjunto fechado cujo
complemento tem medida zero.
\end{Def}

\begin{Exe}
A medida de probabilidade do exemplo \ref{exe:dist-binom} tem suporte
$\{0,1,2,3,4,5,6\}$
\skipend
\end{Exe}

\textbf{Pergunta: nós precisamos \emph{mesmo} da definição de suporte aqui? O
  que isso contribui para conceitualizarmos e entendermos medidas invariantes?}

\begin{Exe}
Dado o intervalo $[0,1]$ e a medida de Lebesgue: $\exists A$ fechado, $A \ne
[0,1]$, tal que $\overline{A}$ (aberto) possui medida de Lebesgue nula?

\skipsol

Dado $\overline{A}$ aberto contido em $[0,1]$, $\overline{A} \ne \emptyset$, deve
haver algum intervalo não vazio contido nele. Como os intervalos possuem medida
de Lebesgue diferente de zero, $|\overline{A}| \ne 0$, e portanto $A$ não pode
ser o suporte.  Segue-se que o suporte da medida de Lebesgue em $[0,1]$ é o
próprio $[0,1]$.
\skipend

\end{Exe}

Considere agora o espaço de fase do sistema dinâmico no instante $t =
0$. Suponha que, nesse instante, haja uma \emph{distribuição de probabilidade} $\mu$
associada, ou seja: suponha que haja uma \emph{configuração} inicial. A pergunta
óbvia é: qual é a distribuição de probabilidade após um avanço $t$ do sistema?

\textbf{Em toda a aula, usamos $\mu$ e não $P$.  Acho que devemos tentar
  uniformizar para $P$ (ou $\mu$) em todo o texto.}

É mais ou menos óbvio que, para responder a essa pergunta, é necessário que
$\phi_t$ seja \emph{mensurável} segundo $\mu$: lembremo-nos do que isso
significa: dada a tripla $(\Omega,\mathscr{B},\mu)$, 
\[
\forall A \in \mathscr{B} \Rightarrow \phi_t^{-1}(A) \in \mathscr{B}.
\]
Se $\mathscr{T} = \mathbb{R} \,\text{ou}\, \mathbb{Z}$, podemos substituir por
\[
\forall A \in \mathscr{B} \Rightarrow \phi_{-t}(A) \in \mathscr{B}.
\]

Note que $\phi_t$ deve fazer a medida $\mu$ da configuração inicial ``evoluir''
até uma medida $\nu$ no instante $t_0$. Isso significa que $\nu$ precisa ser
definida a partir de $\mu$.  A maneira natural de fazer isso é
\[
\nu_{t_0}(A) \equiv \mu(\phi_{t_0}^{-1}(A)).
\]

A notação $\phi_{t_0}^{-1}(A)$ denota a \emph{imagem inversa}. Nem sempre isso
significa uma função inversa.  No entanto, quando $\mathscr{T}=\mathbb{R}$ ou
$\mathscr{T}=\mathbb{Z}$, temos
\begin{align*}
\phi_{t_0}^{-1} &= \phi_{-t_0}, \\
\phi_{-t}\circ\phi_{t} &= \phi_{-t + t} = \phi_0 = \mathbbm{I_d}
\end{align*}
e, nesses casos, $\phi_{t_0}^{-1}$ de fato é a função inversa.

\textbf{Favor confirmar a afirmação acima.}

\section{\textit{Push-forward}, \textit{Pull-back}}\label{sec:push-pull}

É conveniente, notacionalmente, escrever:
\[
\md{\nu}_{t_0} = \md {\phi_{t_0}}_*\mu
\]
e chamar o resultado de \textit{push-forward} de $\mu$ por $\phi_{t_0}$.

O que precisamos aqui é a definição
\[
\md f_*\mu(A) \equiv \md \mu\bigl( f^{-1}(A)\bigr).
\]

Tentemos:
\begin{align*}
\nu_{t_0}(A) &= \int_A \md\nu_{t_0}(A) \\
             &= \int_A \md\mu\bigl(\phi_{t_0}^{-1}(A)\bigr)\\
             &= \int_A \md {\phi_{t_0}}_* \mu\\
             &= \int_A \phi_{t_0}(\omega)\md{\mu} \; \text{\textbf{Não entendo isso!}}\\
\end{align*}

Para entender a última linha:
\[
\{ \omega: \phi_{t_0}(\omega) \in A \} \equiv \{\omega: \omega \in \phi_{t_0}^{-1}(A) \}
\]

Segue-se que (\textbf{isso é difícil!}):

\[
\int_{\omega \in A} \phi_{t_0}(\omega)\md\mu = \int_{\phi_{t_0}^{-1}(A)}\md\mu =
\mu(\phi_{t_0}^{-1}(A)) = \nu_{t_0}(A).
\]

\textbf{Sinceramente, eu copiei, mas não entendi: isso precisa ser revisto.  Em
  particular, preciso confirmar o índice da primeira integral acima, à esquerda.}

\begin{Def}
Uma medida $\mu$ definida na $\sigma$-álgebra $\mathscr{B}$ é invariante sob o
fluxo $\phi_t$, $t \in \mathscr{T}$ se, para todo $A\in\mathscr{B}$ vale
\begin{equation}
\mu\bigl(\phi_t^{-1}(A)\bigr) = \mu(A).
\end{equation}
\end{Def}

Estamos agora prontos para definirmos (mais uma vez?) um processo estocástico:
\begin{Def}
Seja $g: \Omega \rightarrow \mathbb{R}$ uma função mensurável (por exemplo, $g =
\mathbbm{1}_A$, ou uma componente de uma grandeza física, etc.).  Dado o ssitema
dinâmico $(\Omega, \phi_t, t\in\mathscr{T},\mathscr{B},\mu)$, um \emph{processo
  estocástico} $X_t$ é
\[
   X_t(\omega) \equiv g\circ\phi_t(\omega).
\]
Vemos que $X_t$ é uma família de variáveis aleatórias no parâmetro $t$
\end{Def}

Seja agora $\mu$ uma medida invariante sob o fluxo $\phi_t$.  Então,

\begin{Teo}
Se $(\Omega, \phi_t, t\in\mathscr{T},\mathscr{B},\mu)$ é um sistema dinâmico com
$\Omega \in \mathbb{R}^n$ compacto com interior não vazio, e se $\phi(\omega,t)$
é uma função contínua em $\Omega \times \mathscr{T}$, então 
$\mu$ é invariante sob o fluxo $\phi_t$ se e somente se para qualquer $g$
contínua e limitada vale
\[
\int_{??} g\circ\phi_t\md\mu = \int_{??} g\md\mu.
\]
\end{Teo}

\textbf{Aparentemente, não vamos provar esse teorema, certo?. Mas seria bom
  explicar a sua função no texto.}

\begin{Teo}
Se $\mu$ é uma medida invariante sob $\phi_t$, $X_t$ é um processo estocástico estacionário.
\end{Teo}

Prova: considere o conjunto de instantes $p_0, p_1, \ldots, p_n$ e a defasagem
$t_0 = 0, t_1 = p_1 - p_0, \ldots, t_n = p_n - p_0$. 
Acho que é preciso deixar explícitos os resultados
\begin{align*}
\left[ g \circ \phi\right]^{-1}(A) &= \phi^{-1} \left( g^{-1}\left(A\right)\right) , \\
\left[ \phi_t \circ \phi_p\right]^{-1}(g^{-1}(A)) &= \phi_p^{-1}\left( \phi_t^{-1}\left(g^{-1}(A)\right)\right).
\end{align*}


\textbf{(ESTÁ CERTO AGORA???)}

\textbf{MAIS UMA DÚVIDA}

Em Probabilidades, a sentença ``probabilidade de A e B'' é interpretada como uma interseção:
\begin{align*}
P\left( \left[X_{t_1} \in A_1\right] \wedge \left[ X_{t_2}(\omega) \in A_2 \right] \right) &= 
P\left( \left[X_{t_1} \in A_1\right] \cap \left[X_{t_2} \in A_2\right]\right).
\end{align*}
No entanto, na dedução a seguir nós usamos uniões: está certo mesmo??

Agora,

\begin{multline*}
P\bigl( X_{p_0} \in A_0, X_{p_1} \in A_1, \ldots, X_{p_n} \in A_n\bigr) = \\
P\bigl( g\circ\phi_{p_0}\in A_0, g\circ\phi_{p_1}\in A_1, \ldots, g\circ\phi_{p_n}\in
A_n\bigr) =\\
\mu\left( \left[g\circ\phi_{p_0}\right]^{-1}(A_0) \cup \left[g\circ\phi_{p_1}\right]^{-1}(A_1) \cup \ldots
\cup \left[g\circ\phi_{p_n}\right]^{-1}(A_n)\right)=\\
\mu\left( \phi_{p_0}^{-1}\left( g^{-1}\left( A_0\right)\right)\cup
          \phi_{p_1}^{-1}\left( g^{-1}\left( A_1\right)\right)\cup 
                                                       \ldots \cup 
          \phi_{p_n}^{-1}\left( g^{-1}\left( A_n\right)\right)\right).
\end{multline*}
Mas:
\begin{align*}
\phi_{p_k} &= \phi_{t_k + p_0} = \phi_{t_k} \circ \phi_{p_0};\\
\phi_{p_k}^{-1}\left(g^{-1}\left(A_k\right)\right) &= \phi_{p_0}^{-1}\left( \phi_{t_k}^{-1}\left(g^{-1}\left( A_k\right)\right)\right).
\end{align*}
Portanto, agora temos:
\begin{multline*}
P\bigl( X_{p_0} \in A_0, X_{p_1} \in A_1, \ldots, X_{p_n} \in A_n\bigr) = \\
\mu\left( \phi_{p_0}^{-1}\left(                     g^{-1}\left(A_0\right)\right)\cup
          \phi_{p_0}^{-1}\left(\phi_{t_1}^{-1}\left(g^{-1}\left(A_1\right)\right)\right)\cup
                                                                           \ldots\cup
          \phi_{p_0}^{-1}\left(\phi_{t_n}^{-1}\left(g^{-1}\left(A_n\right)\right)\right)\right)=\\
\mu\left(                      g^{-1}\left(A_0\right)\cup
          \phi_{t_1}^{-1}\left(g^{-1}\left(A_1\right)\right)\cup
                                                                           \ldots\cup
          \phi_{t_n}^{-1}\left(g^{-1}\left(A_n\right)\right)\right)=\\
P\bigl( X_{t_0=0} \in A_0, X_{t_1} \in A_1, \ldots, X_{t_n} \in A_n\bigr)\blob
\end{multline*}
A penúltima igualdade acima é uma decorrência da invariância de $\mu$ sob $\phi$. O que nós provamos é que, quando
fazemos uma defasagem $p_0$, a probabilidade conjunta não se altera.  Isso é \emph{exatamente} a definição de
estacionariedade estrita de um processo estocástico usada por \cite[][Definição
  1.5.6]{todorovic--introduction.stochastic.processes}.



Usando uma notação mais ``minha'':
\[
P\bigl(X_{t_0} \in A_0, \ldots , X_{t_n} \in A_n\bigr)=
P\bigl(X_{t_0+\Delta} \in A_0, \ldots , X_{t_n+\Delta} \in A_n\bigr).
\]

\chapter{2014-04-28: O Teorema Ergódico de von Neumann}


Agora nós precisamos introduzir a idéia de normas, e de espaços
normados. Em geral, a norma $L_p$ de uma função $f(\omega)$ é definida por 
\begin{equation}
\Vert f \Vert_p \equiv \left[ \int_\Omega \bigl|f(\omega)\bigr|^p \,\md{\mu} \right]^{1/p}.\label{eq:norma-p}
\end{equation}
A melhor norma do mundo é a $L_2$, que é obtida da definição
(\ref{eq:norma-p}) para $p = 2$, obviamente. O que $L_2$ traz de
diferente é a definição do produto interno:
\begin{equation}
\tavg{f,g} \equiv \int_\Omega f^*(\omega) g(\omega)\,\md{\mu}.\label{eq:def-prod-interno}
\end{equation}
O conjunto das $f$ (mensuráveis) em $\Omega$ com o produto interno
(\ref{eq:def-prod-interno}), denotado $(\Omega, \Vert \cdot\Vert_2)$,
é um espaço de Hilbert.

Em resumo, o Teorema Ergódico de von Neumann vai afirmar que:
\[
\frac{1}{N}\sum_{k=0}^{N-1}f\circ T^k \xrightarrow[N\to\infty]{L_2} \overline{f}(\omega).
\]
O lado esquerdo é uma média temporal no parâmetro $k$ ($k$ é o tempo
discreto). A convergência acima deve ser entendida como uma
convergência na média quadrática:
\begin{equation}
\lim_{N\to\infty} \left\Vert \frac{1}{N}\sum_{k=0}^{N-1}f\circ T^k -
\overline{f}\right\Vert_2 = 0. \label{eq:pre-teoerg}
\end{equation}

A idéia da demonstração é considerar 3 ``grupos'' de funções:
\begin{enumerate}[i)]
\item O conjunto das funções 
\[
\mathscr{C} = \left\{ f_{\text{i}}(\omega) = g  - g\circ T, g \in L_2\right\}.
\]
\item O \emph{fecho} do grupo i, denominado $\overline{\mathscr{C}}$.
\item O conjunto \emph{ortogonal} a $\overline{\mathscr{C}}$,
  denominado $\overline{\mathscr{C}}^\perp$.
\end{enumerate}

Lembremo-nos do que é uma variável aleatória:
\begin{align*}
   g: (\Omega,\mathscr{F},\mu) &\rightarrow (\mathbb{R},\mathscr{B},P)\\
   \omega                      &\mapsto g(\omega).
\end{align*}


\textbf{Observação:} Claramente, a notação está uma bagunça. Minha
visão ingênua continua a ser a de que a função mensurável $g$ induz a
sigma-álgebra $\mathscr{B}$ em $\mathbb{R}$ a partir da sigma-álgebra
$\mathscr{F}$ no espaço
``original''. \textbf{Correct me!}

Juntamente com o sistema dinâmico $\phi_t$,
\begin{align*}
   \phi_t: (\Omega,\mathscr{F}\mu) &\rightarrow (\Omega,\mathscr{F}\mu),\\
            \omega &\mapsto \phi_t(\omega),
\end{align*}
já sabemos que isso produz o processso estocástico 
\[
X_t(\omega) \equiv g \circ \phi_t(\omega).
\]

Considere a tripla usual $(\Omega,\mathscr{F},\mu)$ e um fluxo discreto $T$, onde $\mu$ é invariante sob $T$. O
significado disso já deve ter sido explicado anteriormente:
\[
\mu\left(T^{-1}\left(A\right)\right) = \mu\left(A\right), \; \forall A \in \mathscr{F}.
\]

Isso significa, para mim, tão-somente que:
\[
\int_{T^{-1}(A)} \md{\mu} = \int_{A} \md{\mu}
\]
Uma coisa totalmente diferente, e nova, é a afirmativa: 

\begin{Teo}\label{teo:ginv-mu}
Se $\mu$ é invariante sob $T$, então, para qualquer função $g(\omega)$ contínua e limitada,
\[
\int_{\Omega} g(T(\omega))\,\md{\mu} = \int_\Omega g(\omega)\,\md{\mu}.
\]
\end{Teo}

\textbf{A prova não está clara para mim: onde está a prova?} 

De qualquer modo, o teorema \ref{teo:ginv-mu} será crucial
na prova da validade do Teorema ergódico para as funções do grupo i. Sejam então as $f$'s de $L_2$ tais que
$ f = g - g\circ T$. Adivinhando, façamos $\overline{f} = 0$ em quase todos os pontos (qtp) de $\Omega$. Agora, observe
que:


\newlength{\somespc}
\settowidth{\somespc}{$\displaystyle = {\big(}$\hspace*{4pt}}
\newlength{\zomespc}
\settowidth{\zomespc}{$\displaystyle\lim_{\Delta x, \Delta y, \Delta z \to 0}\biggl[$}



\begin{align*}
\sum_{k=0}^{N-1} f\circ T^k &= \sum_{k=0}^{N-1} \left( g - g\circ T\right)\circ T^k \\
                            &= \big( g - g\circ T + \\
                            &\mbox{\hspace*{\somespc}} g\circ T  - g\circ T^2 + \\
                            &\mbox{\hspace*{\somespc}} g\circ T^2 - g\circ T^3 + \ldots \\
                            &\mbox{\hspace*{\somespc}} \vdots\\
                            &\mbox{\hspace*{\somespc}} g\circ T^{N-1} - g\circ T^N \big)\\
                            &= \left( g - g\circ T^N \right).
\end{align*}

Segue-se que
\begin{align*}
\left\Vert \frac{1}{N} \sum_{k=0}^{N-1} f\circ T^k - 0\right\Vert_2 &=
   \left\Vert \frac{1}{N}\left( g - g\circ T^N\right)\right\Vert_2 \\
&= \frac{1}{N} \left\Vert g - g\circ T^N\right\Vert_2 \\
&\le \frac{1}{N} \left[ \left\Vert g \right\Vert_2 + \left\Vert g\circ T^N\right\Vert_2\right]\\
&= \frac{2}{N} \left\Vert g \right\Vert_2 \xrightarrow{N\to\infty} 0.
\end{align*}

A demonstração de que o Teorema Ergódico vale para as funções do grupo
ii é a mais técnica de todas. Observe que a afirmativa $f \in
\overline{C}$ significa que $f$ deve estar ``próxima'' de $g - g\circ
T$.  Em linguagem de epsilons:
\[
f \in \overline{\mathscr{C}} \Rightarrow \forall \epsilon > 0, \exists h_\epsilon \in \mathscr{C} : \Vert f -
h_\epsilon \Vert_2 < \epsilon.
\]
Em particular, o teorema é válido para $h_\epsilon$:
\[
\lim_{N\to\infty} \left\Vert \frac{1}{N}\sum_{k=0}^N h_\epsilon \circ
T^k\right\Vert_2 = 0.
\]
Mas isso é o mesmo que dizer que, $\forall \epsilon > 0$, $\exists
N_\epsilon$ tal que
\[
N > N_\epsilon \Rightarrow \left\Vert \frac{1}{N}\sum_{k=0}^N h_\epsilon \circ
T^k\right\Vert_2 < \epsilon.
\]
Portanto, para qualquer $f \in \overline{\mathscr{C}}$, fixado um
$\epsilon > 0$, existem $h_\epsilon \in \mathscr{C}$ e $N_\epsilon$ tais que, para
todo $N > N_\epsilon$, valem ambas as desigualdades abaixo:
\begin{align}
\left\Vert f - h_\epsilon \right\Vert_2 &< \epsilon, \label{eq:ineq-f-h}\\
\left\Vert \frac{1}{N}\sum_{k=0}^{N-1} h_\epsilon \circ
T^k\right\Vert_2 &< \epsilon.\label{eq:ineq-h-T}
\end{align}
Se $\overline{f} = 0$ também para as funções $f$ do grupo ii (o que é uma
suposição razoável), desejamos provar que
\[
\left\Vert \frac{1}{N}\sum_{k=0}^{N-1} f \circ
T^k - 0\right\Vert_2 \rightarrow 0.
\]

Segue-se um longo e tenebroso inverno:
\begin{align*}
\left\Vert \frac{1}{N}\sum_{k=0}^N f \circ
T^k \right\Vert_2  &= \left\Vert \frac{1}{N}\sum_{k=0}^N \left(f -
h_\epsilon + h_\epsilon\right) \circ
T^k \right\Vert_2 \\
&= \frac{1}{N} \left\Vert \sum_{k=0}^{N-1} \left[ \left(f -
h_\epsilon\right)\circ T^k  + h_\epsilon \circ T^k
\right]\right\Vert_2\\
&\le \frac{1}{N} 
\left\Vert \sum_{k=0}^{N-1} \left(f - h_\epsilon\right)\circ T^k \right\Vert_2 + \frac{1}{N}\left\Vert \sum_{k=0}^{N-1} h_\epsilon \circ T^k
\right\Vert_2
\\
&\le \frac{1}{N} 
\sum_{k=0}^{N-1} \left\Vert \left(f - h_\epsilon\right)\circ T^k \right\Vert_2 + \frac{1}{N}\left\Vert \sum_{k=0}^{N-1} h_\epsilon \circ T^k
\right\Vert_2\\
&= \frac{1}{N} 
\sum_{k=0}^{N-1} \left\Vert \left(f - h_\epsilon\right) \right\Vert_2 + \left\Vert \frac{1}{N}\sum_{k=0}^{N-1} h_\epsilon \circ T^k
\right\Vert_2\\
&\le \frac{1}{N} N\epsilon + \epsilon \; \text{(devido a (\ref{eq:ineq-f-h}) e (\ref{eq:ineq-h-T}))}\\
&= 2\epsilon
\end{align*}

Portanto, dado $\epsilon_0 > 0$, existe $M = N_{\epsilon_0/2}$ tal
que, para todo $N > M$, e para toda $f \in \overline{\mathscr{C}}$,
\[
\left\Vert \frac{1}{N}\sum_{k=0}^N f \circ
T^k \right\Vert_2 < \epsilon_0.
\]
Isso prova o teorema também para as funções pertencentes a $\overline{\mathscr{C}}$.

A prova para o grupo iii é mais clássica, e menos
demandante. Considere o conjunto ortogonal a $\overline{\mathscr{C}}$:
\[
\overline{\mathscr{C}}^\perp = 
\left\{
f: \tavg{f,w}= 0, \forall w \in \overline{\mathscr{C}} 
\right\}.
\]
Provemos agora o seguinte:
\begin{equation}
f \in \overline{\mathscr{C}}^\perp \Leftrightarrow \left\Vert f - f\circ T
\right\Vert_2 = 0.\label{eq:feqfoT}
\end{equation}

Por simplicidade, suporemos $f(\omega) \in \mathbb{R}$:

\begin{align*}
\left\Vert f - f\circ T
\right\Vert_2 &= \tavg{f - f\circ T,f-f\circ T}\\
&= \tavg{f,f} - \tavg{f\circ T,f} - \tavg{f,f\circ T} + \tavg{f\circ
  T,f\circ T}\\
&= \left\Vert f\right\Vert_2^2 - 2 \tavg{f,f\circ T} + \left\Vert
f\circ T\right\Vert_2^2\\
&= \left\Vert f\right\Vert_2^2 - 2 \tavg{f,f\circ T} + \left\Vert
f\right\Vert_2^2.
\end{align*}
Na última linha acima, usamos mais uma vez a invariância de $\mu$ sob
$T$. O termo central do lado direito é
\begin{align*}
\tavg{f, f\circ T} &= \tavg{f, f - f + f\circ T}\\
                   &= \tavg{f, f + \underbrace{\left[ f\circ T -
      f\right]}_{\perp f}}\\
                   &= \tavg{f,f} + \tavg{f, f\circ T - f}\\
                   &= \left\Vert f\right\Vert_2^2 + 0.
\end{align*}

Na chave horizontal acima, observe que $\left[f\circ T - f \right] \in
\mathscr{C}$, e que portanto é perpendicular à própria $f$. Juntando
tudo:
\[
\left\Vert f - f\circ T
\right\Vert_2 = 0.
\]

A demonstração é uma sequência de igualdades: vale portanto
$\Leftrightarrow$ em (\ref{eq:feqfoT}).

Com esse resultado auxiliar, faça agora $\overline{f} = f$ para o
grupo iii ($f \in \overline{\mathscr{C}}^\perp$).  Precisamos também
do fato 
\begin{equation}
f \circ T^k = f, \; \forall k \in \mathbb{N}. \label{eq:foTback}
\end{equation}
Isso pode ser feito por indução. (\ref{eq:foTback}) é trivial para $k
= 0$, e foi provado em (\ref{eq:feqfoT}) (na média quadrática) para $k=1$. Suponha que seja verdade para $k-1$; então,
\[
f \circ T^k = f \circ T^{k-1}\circ T = f \circ T = f;
\]
e o resultado também vale para $k$, o que completa a prova por indução finita\blob

O teorema ergódico para as funções do grupo iii será:
\begin{align*}
\lim_{N\to\infty}
   \left\Vert \frac{1}{N}\sum_{k=0}^{N-1} f\circ T^k -
   \overline{f}\right\Vert_2 &= \lim_{N\to\infty}\left\Vert \frac{1}{N}\sum_{k=0}^{N-1}
   f\circ T^k - f\right\Vert_2\\
&= \lim_{N\to\infty}\frac{1}{N}\left\Vert \sum_{k=0}^{N-1}   \left[f\circ T^k -
     f\right]\right\Vert_2\\
&\le \lim_{N\to\infty}\frac{1}{N} \sum_{k=0}^{N-1} \left\Vert f\circ T^k -
   f\right\Vert_2 = 0.
\end{align*}

\textbf{Atenção: as funções do grupo iii parecem dispensar o limite!
  Isso tem alguma utilidade???}

\textbf{2014-04-30}

Infelizmente, ainda não definimos ergodicidade!

\begin{Def}
O sistema dinâmico $(\Omega, \mathscr{F}, \mu, T)$ (onde $\mu$ é
invariante sob $T$) é ergódico se, para todo $A \in \mathscr{F}$,
\[
\mu(A) = 0 \qquad \text{ou} \qquad \mu(\overline{A}) = 0.
\]
\end{Def}

Nós não conseguimos ainda provar:
\begin{Teo} (O Teorema Ergódico de von Neumann) \label{teo:teoerg}
Se $(\Omega, \mathscr{F}, \mu, T)$ é ergódico, então, em (\ref{eq:pre-teoerg}),
\[
\overline{f}(\omega) = \int_\Omega f(\omega)\,\md{\mu} = \text{constante}.
\]
\end{Teo}


\chapter{Ergodicity}



\subsection*{Ergodicity, and Birkhoff's theorem}

\[
\lim_{T\to\infty} \frac{1}{T} \int_0^T g(\phi_t(\omega_0))\,\md{t} = L
\stackrel{\text{if ergodic}}{=} \int_\Omega
g(\omega)\,\md{\omega}
\]

Remark: $X(x_0,t) = g(\phi_t(\omega_0)) $ is a single realization of a stochastic process from
  the initial condition $\omega_0$. The rightmost expression is \emph{independent of
    $\omega_0$, and only then is the process ergodic}.

Moreover, \citep{lebowitz.penrose--modern.ergodic}:
\begin{quote}\small
Stated precisely, this means that a system is ergodic on $S$ (read $\Omega$) if
and only if \emph{all} regions $R$ of $S$ (read $\Omega$) left invariant by the
time evolution, $\phi_t(R) = R$ either have zero area or have an area equal to
the area of $S$ (read either have zero probability measure, or have $P(R) = 1$).
\end{quote}

\subsection*{Being more accurate,}

However, the equality $\phi_t(R) = R$ in \cite{lebowitz.penrose--modern.ergodic}'s statement is somewhat
\emph{imprecise}!
Given the \emph{symmetric difference} between two sets, 
\[
A \;\triangle\; B \equiv (A \cup B)  - ( A \cap B),
\]
then, in terms of probability measure, the corresponding statement is.
\[
P\left(A \;\triangle\; \phi_{-t}(A)\right) = 0 \Leftrightarrow P(A) = 0 \; \text{or}
\; P(A) = 1.
\]
My simple-minded interpretation: in an ergodic system, the map $\phi_t$ makes
any realization eventually wander over \emph{almost all} of $\Omega$ ($P(A)=1$),
or \emph{almost none} of it at all ($P(A)=0$).

\subsection*{A word of caution on the terminology}

\cite[p. 40]{collet--dynsys.valparaiso}:
\begin{quote}
Birkhoff's ergodic theorem does not prove ergodicity .
It may be a very useful tool in proving ergodicity but as such it does not
claim it. In particular it applies in non-ergodic cases. Birkhoff's ergodic applies
as soon as you have an invariant measure. You have to work more to decide
whether or not the measure is ergodic.
\end{quote}

(I want to remove this remark for the final version for Santa Maria)


\subsection*{The mixing condition}

implies (is a sufficient condition for) ergodicity:
\[
\lim_{\tau\to\infty} \int_\Omega f(x) g(\phi_{\tau}(x))\,\md{P}(x) = \int_\Omega f(x)\,\md{P}(x)
                                                                   \int_\Omega g(x)\,\md{P}(x)
\]
But
\[
C_{fg}(\tau) \equiv \tavg{f(x)g(\phi_\tau(x))} - \tavg{f(x)}\tavg{g(x)}
\]
is the $\tau$-covariance function; therefore,
\begin{quote}
If the $\tau$-covariance function goes go to zero, the process is ergodic.
\end{quote}
But this does not even guarantee that the process has finite variance.  For more
regularity, more conditions are needed.  

The most common is the existence of
integral scales.


\bibliography{all}
\bibliographystyle{belllike}

\end{document}
